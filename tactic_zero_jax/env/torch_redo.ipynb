{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "considerable-sandwich",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "import optax\n",
    "\n",
    "from jax import random\n",
    "import sys\n",
    "from time import sleep\n",
    "import json\n",
    "import pexpect\n",
    "import re\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import timeit\n",
    "import torch\n",
    "\n",
    "import seq2seq\n",
    "from batch_predictor import BatchPredictor\n",
    "from checkpoint import Checkpoint\n",
    "\n",
    "from policy_networks import *\n",
    "import policy_networks\n",
    "\n",
    "from new_env import *\n",
    "\n",
    "from jax.config import config\n",
    "config.update(\"jax_debug_nans\", True) \n",
    "import numpy as np\n",
    "#jax.config.update(\"jax_enable_x64\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intelligent-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "path_dir = \"/home/sean/Documents/PhD/tactic_zero_jax/env/model_params\"\n",
    "\n",
    "def save(params, path):\n",
    "    with open(path, 'wb') as fp:\n",
    "        pickle.dump(params, fp)\n",
    "\n",
    "def load(path):\n",
    "    with open(path, 'rb') as fp:\n",
    "        return pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "necessary-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOLPATH = \"/home/sean/Documents/hol/HOL/bin/hol --maxheap=256\"\n",
    "HOLPATH = \"/home/sean/Documents/PhD/HOL4/HOL/bin/hol --maxheap=256\"\n",
    "\n",
    "#tactic_zero_path = \"/home/sean/Documents/PhD/git/repo/PhD/tacticzero/holgym/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "desperate-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"typed_database.json\") as f:\n",
    "    database = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "liked-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "MORE_TACTICS = True\n",
    "if not MORE_TACTICS:\n",
    "    thms_tactic = [\"simp\", \"fs\", \"metis_tac\"]\n",
    "    thm_tactic = [\"irule\"]\n",
    "    term_tactic = [\"Induct_on\"]\n",
    "    no_arg_tactic = [\"strip_tac\"]\n",
    "else:\n",
    "    thms_tactic = [\"simp\", \"fs\", \"metis_tac\", \"rw\"]\n",
    "    thm_tactic = [\"irule\", \"drule\"]\n",
    "    term_tactic = [\"Induct_on\"]\n",
    "    no_arg_tactic = [\"strip_tac\", \"EQ_TAC\"]\n",
    "    \n",
    "tactic_pool = thms_tactic + thm_tactic + term_tactic + no_arg_tactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "textile-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Move to another file \n",
    "\n",
    "def get_polish(raw_goal):\n",
    "        goal = construct_goal(raw_goal)\n",
    "        process.sendline(goal.encode(\"utf-8\"))\n",
    "        process.expect(\"\\r\\n>\")\n",
    "        process.sendline(\"val _ = set_term_printer (HOLPP.add_string o pt);\".encode(\"utf-8\"))\n",
    "        process.expect(\"\\r\\n>\")\n",
    "        process.sendline(\"top_goals();\".encode(\"utf-8\"))\n",
    "        process.expect(\"val it =\")\n",
    "        process.expect([\": goal list\", \":\\r\\n +goal list\"])\n",
    "\n",
    "        polished_raw = process.before.decode(\"utf-8\")\n",
    "        polished_subgoals = re.sub(\"“|”\",\"\\\"\", polished_raw)\n",
    "        polished_subgoals = re.sub(\"\\r\\n +\",\" \", polished_subgoals)\n",
    "\n",
    "        pd = eval(polished_subgoals)\n",
    "        \n",
    "        process.expect(\"\\r\\n>\")\n",
    "        process.sendline(\"drop();\".encode(\"utf-8\"))\n",
    "        process.expect(\"\\r\\n>\")\n",
    "        process.sendline(\"val _ = set_term_printer default_pt;\".encode(\"utf-8\"))\n",
    "        process.expect(\"\\r\\n>\")\n",
    "\n",
    "        data = [{\"polished\":{\"assumptions\": e[0][0], \"goal\":e[0][1]},\n",
    "                 \"plain\":{\"assumptions\": e[1][0], \"goal\":e[1][1]}}\n",
    "                for e in zip(pd, [([], raw_goal)])]\n",
    "        return data \n",
    "    \n",
    "def construct_goal(goal):\n",
    "    s = \"g \" + \"`\" + goal + \"`;\"\n",
    "    return s\n",
    "\n",
    "def gather_encoded_content_(history, encoder):\n",
    "    fringe_sizes = []\n",
    "    contexts = []\n",
    "    reverted = []\n",
    "    for i in history:\n",
    "        c = i[\"content\"]\n",
    "        contexts.extend(c)\n",
    "        fringe_sizes.append(len(c))\n",
    "    for e in contexts:\n",
    "        g = revert_with_polish(e)\n",
    "        reverted.append(g.strip().split())\n",
    "    out = []\n",
    "    sizes = []\n",
    "    for goal in reverted:\n",
    "        out_, sizes_ = encoder.encode([goal])\n",
    "        out.append(torch.cat(out_.split(1), dim=2).squeeze(0))\n",
    "        sizes.append(sizes_)\n",
    "\n",
    "    representations = out\n",
    "\n",
    "    return representations, contexts, fringe_sizes\n",
    "\n",
    "def parse_theory(pg):\n",
    "    theories = re.findall(r'C\\$(\\w+)\\$ ', pg)\n",
    "    theories = set(theories)\n",
    "    for th in EXCLUDED_THEORIES:\n",
    "        theories.discard(th)\n",
    "    return list(theories)\n",
    "\n",
    "def revert_with_polish(context):\n",
    "    target = context[\"polished\"]\n",
    "    assumptions = target[\"assumptions\"]\n",
    "    goal = target[\"goal\"]\n",
    "    for i in reversed(assumptions): \n",
    "        #goal = \"@ @ D$min$==> {} {}\".format(i, goal)\n",
    "        goal = \"@ @ C$min$ ==> {} {}\".format(i, goal)\n",
    "\n",
    "    return goal \n",
    "\n",
    "def split_by_fringe(goal_set, goal_scores, fringe_sizes):\n",
    "    # group the scores by fringe\n",
    "    fs = []\n",
    "    gs = []\n",
    "    counter = 0\n",
    "    for i in fringe_sizes:\n",
    "        end = counter + i\n",
    "        fs.append(goal_scores[counter:end])\n",
    "        gs.append(goal_set[counter:end])\n",
    "        counter = end\n",
    "    return gs, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "capital-major",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIST_REL (R :α -> β -> bool) (l1 :α list) (l2 :β list) ∧ LIST_REL R (l3 :α list) (l4 :β list) ⇒ LIST_REL R (l1 ++ l3) (l2 ++ l4)\n"
     ]
    }
   ],
   "source": [
    "with open(\"include_probability.json\") as f:\n",
    "    database = json.load(f)\n",
    "\n",
    "with open(\"polished_def_dict.json\") as f:\n",
    "    defs = json.load(f)\n",
    "\n",
    "fact_pool = list(defs.keys())\n",
    "\n",
    "encoded_database = torch.load('encoded_include_probability.pt')\n",
    "\n",
    "TARGET_THEORIES = [\"bool\", \"min\", \"list\"]\n",
    "GOALS = [(key, value[4]) for key, value in database.items() if value[3] == \"thm\" and value[0] in TARGET_THEORIES]\n",
    "\n",
    "print (GOALS[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "forbidden-norfolk",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'seq2seq.models.EncoderRNN.EncoderRNN' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.GRU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'seq2seq.models.DecoderRNN.DecoderRNN' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "#checkpoint_path = \"models/2020_04_22_20_36_50\" # 91% accuracy model, only core theories\n",
    "#checkpoint_path = \"models/2020_04_26_20_11_28\" # 95% accuracy model, core theories + integer + sorting\n",
    "#checkpoint_path = \"models/2020_09_24_23_38_06\" # 98% accuracy model, core theories + integer + sorting | separate theory tokens\n",
    "#checkpoint_path = \"models/2020_11_28_16_45_10\" # 96-98% accuracy model, core theories + integer + sorting + real | separate theory tokens\n",
    "#checkpoint_path = \"models/2020_12_04_03_47_22\" # 97% accuracy model, core theories + integer + sorting + real + bag | separate theory tokens\n",
    "\n",
    "#checkpoint_path = \"models/2021_02_21_15_46_04\" # 98% accuracy model, up to probability theory\n",
    "\n",
    "checkpoint_path = \"models/2021_02_22_16_07_03\" # 97-98% accuracy model, up to and include probability theory\n",
    "\n",
    "checkpoint = Checkpoint.load(checkpoint_path)\n",
    "seq2seq = checkpoint.model\n",
    "input_vocab = checkpoint.input_vocab\n",
    "output_vocab = checkpoint.output_vocab\n",
    "\n",
    "batch_encoder_ = BatchPredictor(seq2seq, input_vocab, output_vocab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "virtual-activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to give the log probability of pi(f | s) so gradient can be computed directly\n",
    "#also returns sampled index and contexts to determine goal to give tactic network\n",
    "def sample_fringe(context_params, context_net, rng_key, jax_reps, context_set, fringe_sizes):\n",
    "    context_scores = context_net(context_params, rng_key, jax_reps)\n",
    "    contexts_by_fringe, scores_by_fringe = split_by_fringe(context_set, context_scores, fringe_sizes)\n",
    "    fringe_scores = []\n",
    "    for s in scores_by_fringe:\n",
    "        fringe_score = jnp.sum(s)\n",
    "        fringe_scores.append(fringe_score)\n",
    "    #TODO some fringes can be empty, but still give value 0 which assigns nonzero probability?\n",
    "    fringe_scores = jnp.stack(fringe_scores)\n",
    "    fringe_probs = jax.nn.log_softmax(fringe_scores)\n",
    "\n",
    "    #samples, gives an index (looks like it does gumbel softmax under the hood to keep differentiability?)\n",
    "    sampled_idx = jax.random.categorical(rng_key,fringe_probs)\n",
    "\n",
    "    log_prob = fringe_probs[sampled_idx]\n",
    "    #log_prob = jnp.log(prob)\n",
    "    return log_prob, (sampled_idx, contexts_by_fringe)\n",
    "                                                           \n",
    "#grad_log_context, (fringe_idx, contexts_by_fringe) = jax.grad(sample_fringe, has_aux=True)(context_params, apply_context, rng_key, jax_reps, context_set, fringe_sizes)\n",
    "\n",
    "#takes a goal encoding and samples tactic from network, and returns log prob for gradient \n",
    "def sample_tactic(tactic_params, tac_net, rng_key, goal_endcoding, action_size=len(tactic_pool)):\n",
    "    tac_scores = tac_net(tactic_params, rng_key, goal_endcoding, action_size)\n",
    "    tac_scores = jnp.ravel(tac_scores)\n",
    "    #tac_scores = tac_scores - max(tac_scores)\n",
    "    #print (tac_scores)\n",
    "    #subtract max element for numerical stability \n",
    "    tac_probs = jax.nn.log_softmax(tac_scores)\n",
    "    tac_idx = jax.random.categorical(rng_key, tac_probs)\n",
    "    log_prob = tac_probs[tac_idx]#jnp.log(tac_probs[tac_idx])\n",
    "    #print (jnp.exp(log_prob).primal)#, jnp.exp(tac_probs), rng_key)\n",
    "    return log_prob, tac_idx\n",
    "\n",
    "#grad_log_tac, tac_idx = jax.grad(sample_tactic, has_aux=True)(tactic_params, apply_tac, rng_key, jnp.expand_dims(target_representation,0), len(tactic_pool))\n",
    "\n",
    "#sampled_tac = tactic_pool[tac_idx]\n",
    "\n",
    "def sample_term(term_params, term_net, rng_key, candidates):\n",
    "    term_scores = term_net(term_params, rng_key, candidates)\n",
    "    term_scores = jnp.ravel(term_scores)\n",
    "    term_probs = jax.nn.log_softmax(term_scores)\n",
    "    term_idx = jax.random.categorical(rng_key, term_probs)\n",
    "    log_prob = term_probs[term_idx]#jnp.log(term_probs[term_idx])\n",
    "    return log_prob, term_idx\n",
    "\n",
    "#grad_log_term, term_idx = jax.grad(sample_term, has_aux=True)(term_params, apply_term, rng_key, candidates)#, tac_idx, len(tactic_pool), candidates.shape[1])\n",
    "\n",
    "#function for sampling single argument given previous arguments, \n",
    "def sample_arg(arg_params, arg_net, rng_key, input_, candidates, hidden, tactic_size, embedding_dim):\n",
    "    hidden, arg_scores = arg_net(arg_params, rng_key, input_, candidates, hidden, tactic_size, embedding_dim)\n",
    "    arg_scores = jnp.ravel(arg_scores)\n",
    "    arg_probs = jax.nn.log_softmax(arg_scores)\n",
    "    arg_idx = jax.random.categorical(rng_key, arg_probs)\n",
    "    log_prob = arg_probs[arg_idx]#jnp.log(arg_probs[arg_idx])\n",
    "    return log_prob, (arg_idx, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "german-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def episode_loss(context_params, tactic_params, term_params, arg_params, apply_context, apply_tac, apply_term, apply_arg, rng_key, env, encoded_fact_pool, candidate_args):\n",
    "    log_list = []\n",
    "    discounted_reward_list = []\n",
    "    trace = []\n",
    "    gamma = 0.99\n",
    "    for i in range(2):\n",
    "        _, rng_key = jax.random.split(rng_key)\n",
    "        \n",
    "        #print (\"Proof step {} of 50\\n\".format(i+1))\n",
    "        \n",
    "        try:\n",
    "            jax_reps, context_set, fringe_sizes = gather_encoded_content_(env.history, batch_encoder_)\n",
    "            #convert to jax\n",
    "        except:\n",
    "            print (\"Encoder error\")\n",
    "            if len(log_list) > 0:\n",
    "                return sum([i[0] * i[1] for i in zip(log_list, discounted_reward_list)])\n",
    "            else:\n",
    "                return 0\n",
    "            \n",
    "        jax_reps = jnp.stack([jnp.array(jax_reps[i][0].cpu()) for i in range(len(jax_reps))])\n",
    "        logs, reward, action = run_iter(context_params, tactic_params, term_params, arg_params, apply_context, apply_tac, apply_term, apply_arg, jax_reps, context_set, fringe_sizes, rng_key, env, encoded_fact_pool, candidate_args)\n",
    "\n",
    "        log_list.append(logs)\n",
    "        discounted_reward_list.append(reward * (gamma ** i))\n",
    "        \n",
    "        trace.append((env.history, action))\n",
    "\n",
    "                \n",
    "        #if goal proven\n",
    "        if reward == 5:\n",
    "            print (\"Goal proved in {} steps\".format(i+1))\n",
    "            return sum([i[0] * i[1] for i in zip(log_list, discounted_reward_list)]), trace\n",
    "        \n",
    "        #timeout\n",
    "        if i == 49:\n",
    "            discounted_reward_list[-1] = -5.\n",
    "            \n",
    "    loss = sum([i[0] * i[1] for i in zip(log_list, discounted_reward_list)])\n",
    "    \n",
    "    return loss, trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "powerful-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iter(context_params, tactic_params, term_params, arg_params, context_net, tactic_net, term_net, arg_net, jax_reps, context_set, fringe_sizes, rng_key, env, encoded_fact_pool, candidate_args):\n",
    "    \n",
    "    log_context, (fringe_idx, contexts_by_fringe) = sample_fringe(context_params, context_net, rng_key, jax_reps, context_set, fringe_sizes)\n",
    "    \n",
    "    try:\n",
    "        target_context = contexts_by_fringe[fringe_idx][0]\n",
    "    except:\n",
    "        print (\"error {} {}\".format(contexts_by_fringe), fringe_idx)\n",
    "    target_goal = target_context[\"polished\"][\"goal\"]\n",
    "    target_representation = jax_reps[context_set.index(target_context)]\n",
    "    \n",
    "    log_tac, tac_idx = sample_tactic(tactic_params, tactic_net, rng_key, jnp.expand_dims(target_representation,0), len(tactic_pool))\n",
    "    \n",
    "    sampled_tac = tactic_pool[tac_idx]\n",
    "    arg_logs = []\n",
    "\n",
    "    tactic = sampled_tac\n",
    "    #for testing\n",
    "    \n",
    "    #sampled_tac = \"Induct_on\"\n",
    "\n",
    "    #if tactic requires no argument\n",
    "    if sampled_tac in no_arg_tactic:\n",
    "        full_tactic = sampled_tac #tactic_pool[tac]\n",
    "\n",
    "\n",
    "    #Induct_on case; use term policy to find which term to induct on \n",
    "    elif sampled_tac in term_tactic:\n",
    "\n",
    "        goal_tokens = target_goal.split()\n",
    "        term_tokens = [[t] for t in set(goal_tokens) if t[0] == \"V\"]\n",
    "        #add conditional if tokens is empty \n",
    "\n",
    "        #now want encodings for terms from AE\n",
    "\n",
    "        term_reps = []\n",
    "\n",
    "        for term in term_tokens:\n",
    "            term_rep, _ = batch_encoder_.encode([term])\n",
    "            #output is bidirectional so concat vectors\n",
    "            term_reps.append(torch.cat(term_rep.split(1), dim=2).squeeze(0))\n",
    "        \n",
    "        #no terms in expression, only contains literals (e.g. induct_on `0`)\n",
    "        if len(term_reps) == 0:\n",
    "            print (\"No variables to induct on for goal {}\".format(target_goal))\n",
    "            #return negative loss for now (positive overall as negative of log prob is positive)\n",
    "            return 1., -1., \"Induct no vars\"\n",
    "            \n",
    "            \n",
    "        # convert to jax\n",
    "        term_reps = jnp.stack([jnp.array(term_reps[i][0].cpu()) for i in range(len(term_reps))])\n",
    "\n",
    "        # now want inputs to term_net to be target_representation (i.e. goal) concatenated with terms\n",
    "        # models the policies conditional dependence of the term given the goal\n",
    "\n",
    "        #stack goal representation for each token\n",
    "        goal_stack = jnp.concatenate([jnp.expand_dims(target_representation,0) for _ in term_tokens])\n",
    "\n",
    "        #concat with term encodings to give candidate matrix\n",
    "        candidates = jnp.concatenate([goal_stack, term_reps], 1)\n",
    "\n",
    "        log_term, term_idx = sample_term(term_params, term_net, rng_key, candidates)\n",
    "\n",
    "        sampled_term = term_tokens[term_idx]\n",
    "\n",
    "        tm = sampled_term[0][1:] # remove headers, e.g., \"V\" / \"C\" / ...\n",
    "    \n",
    "        arg_logs = [log_term]\n",
    "        \n",
    "        if tm:\n",
    "            tactic = \"Induct_on `{}`\".format(tm)\n",
    "        else:\n",
    "            # only to raise an error\n",
    "            tactic = \"Induct_on\"\n",
    "        \n",
    "    #argument tactic\n",
    "    else:\n",
    "        #stack goals to possible arguments to feed into FFN\n",
    "        goal_stack = jnp.concatenate([jnp.expand_dims(target_representation,0) for _ in encoded_fact_pool])\n",
    "        candidates = jnp.concatenate([encoded_fact_pool, goal_stack], 1)\n",
    "        \n",
    "        #initial state set as goal\n",
    "        hidden = jnp.expand_dims(target_representation,0)\n",
    "        init_state = hk.LSTMState(hidden,hidden)\n",
    "    \n",
    "        # run through first with tac_idx to initialise state with tactic as c_0\n",
    "        hidden, _ = arg_net(arg_params, rng_key, tac_idx, candidates, init_state, len(tactic_pool), 256)\n",
    "        \n",
    "        ARG_LEN = 5\n",
    "        arg_inds = []\n",
    "        arg_logs = []\n",
    "        input_ = tac_idx\n",
    "        for _ in range(ARG_LEN):\n",
    "            log_arg, (arg_idx, hidden) = sample_arg(arg_params, arg_net, rng_key, input_, candidates, hidden, len(tactic_pool), 256)\n",
    "            arg_logs.append(log_arg)\n",
    "            arg_inds.append(arg_idx)\n",
    "            input_ = jnp.expand_dims(encoded_fact_pool[arg_idx], 0)\n",
    "        \n",
    "        arg = [candidate_args[i] for i in arg_inds]\n",
    "\n",
    "        tactic = env.assemble_tactic(sampled_tac, arg)\n",
    "        \n",
    "    \n",
    "    \n",
    "    action = (int(fringe_idx), 0, tactic)\n",
    "    #print (\"Action {}:\\n\".format(action))\n",
    "    \n",
    "    try:\n",
    "        reward, done = env.step(action)\n",
    "\n",
    "    except:\n",
    "        print(\"Step exception raised.\")\n",
    "        # print(\"Fringe: {}\".format(env.history))\n",
    "        print(\"Handling: {}\".format(env.handling))\n",
    "        print(\"Using: {}\".format(env.using))\n",
    "        # try again\n",
    "        # counter = env.counter\n",
    "        frequency = env.frequency\n",
    "        env.close()\n",
    "        print(\"Aborting current game ...\")\n",
    "        print(\"Restarting environment ...\")\n",
    "        print(env.goal)\n",
    "        env = HolEnv(env.goal)\n",
    "        flag = False\n",
    "        return \n",
    "        \n",
    "    #print (\"Result: Reward {}\".format(reward))#, env.history[-1]))\n",
    "\n",
    "    \n",
    "    #negative as we want gradient ascent \n",
    "    \n",
    "    logs = (-log_tac - log_context  - sum(arg_logs))\n",
    "\n",
    "    return logs, reward, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "published-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(goals):\n",
    "\n",
    "    rng_key = jax.random.PRNGKey(11)\n",
    "\n",
    "    init_context, apply_context = hk.transform(policy_networks._context_forward)\n",
    "    apply_context = jax.jit(apply_context)\n",
    "\n",
    "    init_tac, apply_tac = hk.transform(policy_networks._tac_forward)\n",
    "    apply_tac = partial(jax.jit, static_argnums=3)(apply_tac)\n",
    "\n",
    "    init_term, apply_term = hk.transform(policy_networks._term_no_tac_forward)\n",
    "    apply_term = jax.jit(apply_term)\n",
    "\n",
    "    init_arg, apply_arg = hk.transform(policy_networks._arg_forward)\n",
    "    apply_arg = partial(jax.jit, static_argnums=(5,6))(apply_arg)\n",
    "\n",
    "    #initialise these with e.g. random uniform, glorot, He etc. should exist outside function for action selection \n",
    "    context_params = init_context(rng_key, jax.random.normal(rng_key, (1,256)))\n",
    "\n",
    "    tactic_params = init_tac(rng_key, jax.random.normal(rng_key, (1,256)), len(tactic_pool))\n",
    "\n",
    "    #term_policy for now is only considering variables for induction, hence does not need any arguments \n",
    "    term_params = init_term(rng_key, jax.random.normal(rng_key, (1,512)))\n",
    "\n",
    "    hidden = jax.random.normal(rng_key, (1,256))\n",
    "\n",
    "    init_state = hk.LSTMState(hidden, hidden)\n",
    "\n",
    "    arg_params = init_arg(rng_key, jax.random.randint(rng_key, (), 0, len(tactic_pool)), jax.random.normal(rng_key, (1,512)), init_state, len(tactic_pool), 256)\n",
    "\n",
    "        \n",
    "    context_lr = 1e-4\n",
    "    tactic_lr = 1e-4\n",
    "    arg_lr = 1e-4\n",
    "    term_lr = 1e-4\n",
    "\n",
    "    context_optimiser = optax.rmsprop(context_lr)\n",
    "    tactic_optimiser = optax.rmsprop(tactic_lr)\n",
    "    arg_optimiser = optax.rmsprop(arg_lr)\n",
    "    term_optimiser = optax.rmsprop(term_lr)\n",
    "\n",
    "    opt_state_context = context_optimiser.init(context_params)\n",
    "    opt_state_tactic = tactic_optimiser.init(tactic_params)\n",
    "    opt_state_arg = arg_optimiser.init(arg_params)\n",
    "    opt_state_term = term_optimiser.init(term_params)\n",
    "    \n",
    "    proof_dict = {}\n",
    "    \n",
    "\n",
    "    for goal in goals:\n",
    "        g = goal[1]\n",
    "            \n",
    "        env = HolEnv(g)\n",
    "\n",
    "        theories = re.findall(r'C\\$(\\w+)\\$ ', goal[0])\n",
    "        theories = set(theories)\n",
    "        theories = list(theories)\n",
    "\n",
    "        allowed_theories = theories\n",
    "\n",
    "        goal_theory = g\n",
    "\n",
    "        #print (\"Target goal: {}\".format(g))\n",
    "        \n",
    "        try:\n",
    "            allowed_arguments_ids = []\n",
    "            candidate_args = []\n",
    "            goal_theory = g#database[polished_goal][0] # plain_database[goal][0]\n",
    "            for i,t in enumerate(database):\n",
    "                if database[t][0] in allowed_theories and (database[t][0] != goal_theory or int(database[t][2]) < int(database[polished_goal][2])):\n",
    "                    allowed_arguments_ids.append(i)\n",
    "                    candidate_args.append(t)\n",
    "\n",
    "            env.toggle_simpset(\"diminish\", goal_theory)\n",
    "            #print(\"Removed simpset of {}\".format(goal_theory))\n",
    "\n",
    "        except:\n",
    "            allowed_arguments_ids = []\n",
    "            candidate_args = []\n",
    "            for i,t in enumerate(database):\n",
    "                if database[t][0] in allowed_theories:\n",
    "                    allowed_arguments_ids.append(i)\n",
    "                    candidate_args.append(t)\n",
    "            #print(\"Theorem not found in database.\")\n",
    "\n",
    "        #print (\"Number of candidate facts to use: {}\".format(len(candidate_args)))\n",
    "\n",
    "        encoded_database = torch.load('encoded_include_probability.pt')\n",
    "\n",
    "        encoded_fact_pool = torch.index_select(encoded_database, 0, torch.tensor(allowed_arguments_ids))\n",
    "        \n",
    "        encoded_fact_pool = jnp.array(encoded_fact_pool)\n",
    "        \n",
    "        try:\n",
    "            gradients, trace = jax.grad(episode_loss, argnums=(0,1,2,3), has_aux=True)(context_params, tactic_params, term_params, arg_params, apply_context, apply_tac, apply_term, apply_arg,  rng_key, env, encoded_fact_pool, candidate_args)\n",
    "        except:\n",
    "            print (\"error\")\n",
    "            continue\n",
    "        \n",
    "        proof_dict[goal] = trace\n",
    "            \n",
    "\n",
    "        #update parameters\n",
    "        context_updates, opt_state_context = context_optimiser.update(gradients[0], opt_state_context)\n",
    "        context_params = optax.apply_updates(context_params, context_updates)\n",
    "\n",
    "        tactic_updates, opt_state_tactic = tactic_optimiser.update(gradients[1], opt_state_tactic)\n",
    "        tactic_params = optax.apply_updates(tactic_params, tactic_updates)\n",
    "\n",
    "        term_updates, opt_state_term = term_optimiser.update(gradients[2], opt_state_term)\n",
    "        term_params = optax.apply_updates(term_params, term_updates)\n",
    "\n",
    "        arg_updates, opt_state_arg = arg_optimiser.update(gradients[3], opt_state_arg)\n",
    "        arg_params = optax.apply_updates(arg_params, arg_updates)\n",
    "        break\n",
    "        #save trace \n",
    "#         save(proof_dict, path_dir + \"/trace\")\n",
    "        \n",
    "#         #save params after each proof attempt\n",
    "#         save(context_params, path_dir + \"/context_params\")\n",
    "#         save(opt_state_context, path_dir+\"/context_state\")\n",
    "#         save(tactic_params, path_dir+\"/tactic_params\")\n",
    "#         save(opt_state_tactic, path_dir+\"/tactic_state\")\n",
    "#         save(term_params, path_dir+\"/term_params\")\n",
    "#         save(opt_state_term, path_dir+\"/term_state\")\n",
    "#         save(arg_params, path_dir+\"/arg_params\")\n",
    "#         save(opt_state_arg, path_dir+\"/arg_state\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "occupational-dancing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 12:41:10.043147: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing theories...\n",
      "Loading modules...\n",
      "Configuration done.\n",
      "Removing simp lemmas from LIST_REL (R :α -> β -> bool) (l1 :α list) (l2 :β list) ∧ LIST_REL R (l3 :α list) (l4 :β list) ⇒ LIST_REL R (l1 ++ l3) (l2 ++ l4)\n"
     ]
    }
   ],
   "source": [
    "TARGET_THEORIES = [\"list\"]\n",
    "GOALS = [(key, value[4]) for key, value in database.items() if value[3] == \"thm\" and value[0] in TARGET_THEORIES]\n",
    "\n",
    "train(GOALS[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "electronic-cannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_encoded_content(history, encoder):\n",
    "    # figure out why this is slower than tests\n",
    "    # figured out: remember to do strip().split()\n",
    "    fringe_sizes = []\n",
    "    contexts = []\n",
    "    reverted = []\n",
    "    for i in history:\n",
    "        c = i[\"content\"]\n",
    "        contexts.extend(c)\n",
    "        fringe_sizes.append(len(c))\n",
    "    for e in contexts:\n",
    "        g = revert_with_polish(e)\n",
    "        reverted.append(g.strip().split())\n",
    "    # print(reverted)\n",
    "    # s1 = timeit.default_timer()\n",
    "    out, sizes = encoder.encode(reverted)\n",
    "    # merge two hidden variables\n",
    "    representations = torch.cat(out.split(1), dim=2).squeeze(0)\n",
    "    # print(representations.shape)\n",
    "    # s2 = timeit.default_timer()    \n",
    "    # print(s2-s1)\n",
    "\n",
    "    return representations, contexts, fringe_sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "following-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utp_model\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def run_iteration(goals, mode=\"training\", ARG_LEN=5):\n",
    "    \n",
    "\n",
    "    learning_rate = 1e-5\n",
    "\n",
    "    context_rate = 5e-5\n",
    "    tac_rate = 5e-5\n",
    "    arg_rate = 5e-5\n",
    "    term_rate = 5e-5\n",
    "\n",
    "    gamma = 0.99 # 0.9\n",
    "\n",
    "    # for entropy regularization\n",
    "    trade_off = 1e-2\n",
    "\n",
    "    context_net = utp_model.ContextPolicy()\n",
    "\n",
    "    tac_net = utp_model.TacPolicy(len(tactic_pool))\n",
    "\n",
    "    arg_net = utp_model.ArgPolicy(len(tactic_pool), 256)\n",
    "\n",
    "    term_net = utp_model.TermPolicy(len(tactic_pool), 256)\n",
    "\n",
    "    context_net = context_net.to(device)\n",
    "    tac_net = tac_net.to(device)\n",
    "    arg_net = arg_net.to(device)\n",
    "    term_net = term_net.to(device)\n",
    "\n",
    "    optimizer_context = torch.optim.RMSprop(list(context_net.parameters()), lr=context_rate)\n",
    "\n",
    "    optimizer_tac = torch.optim.RMSprop(list(tac_net.parameters()), lr=tac_rate)\n",
    "\n",
    "    optimizer_arg = torch.optim.RMSprop(list(arg_net.parameters()), lr=arg_rate)\n",
    "\n",
    "    optimizer_term = torch.optim.RMSprop(list(term_net.parameters()), lr=term_rate)\n",
    "\n",
    "\n",
    "    torch.set_grad_enabled(mode==\"training\" or mode==\"subgoals\")\n",
    "    global iteration_counter\n",
    "    # state_pool = []\n",
    "    fringe_pool = []\n",
    "    tac_pool = []\n",
    "    arg_pool = []\n",
    "    reward_pool = []\n",
    "    reward_print = []\n",
    "    action_pool = []\n",
    "    steps = 0\n",
    "    flag = True\n",
    "    replay_flag = False\n",
    "    tac_print = []\n",
    "\n",
    "    induct_arg = []\n",
    "    proved = 0\n",
    "    iteration_rewards = []\n",
    "\n",
    "    for goal in goals:\n",
    "        start_t = time.time()\n",
    "        g = goal[1]\n",
    "            \n",
    "        print (g)\n",
    "        env = HolEnv(g)\n",
    "\n",
    "        theories = re.findall(r'C\\$(\\w+)\\$ ', goal[0])\n",
    "        theories = set(theories)\n",
    "        theories = list(theories)\n",
    "\n",
    "        allowed_theories = theories\n",
    "\n",
    "        goal_theory = g\n",
    "\n",
    "        #print (\"Target goal: {}\".format(g))\n",
    "        \n",
    "        try:\n",
    "            allowed_arguments_ids = []\n",
    "            candidate_args = []\n",
    "            goal_theory = g#database[polished_goal][0] # plain_database[goal][0]\n",
    "            for i,t in enumerate(database):\n",
    "                if database[t][0] in allowed_theories and (database[t][0] != goal_theory or int(database[t][2]) < int(database[polished_goal][2])):\n",
    "                    allowed_arguments_ids.append(i)\n",
    "                    candidate_args.append(t)\n",
    "\n",
    "            env.toggle_simpset(\"diminish\", goal_theory)\n",
    "            #print(\"Removed simpset of {}\".format(goal_theory))\n",
    "\n",
    "        except:\n",
    "            allowed_arguments_ids = []\n",
    "            candidate_args = []\n",
    "            for i,t in enumerate(database):\n",
    "                if database[t][0] in allowed_theories:\n",
    "                    allowed_arguments_ids.append(i)\n",
    "                    candidate_args.append(t)\n",
    "            #print(\"Theorem not found in database.\")\n",
    "\n",
    "        #print (\"Number of candidate facts to use: {}\".format(len(candidate_args)))\n",
    "\n",
    "        encoded_database = torch.load('encoded_include_probability.pt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        encoded_fact_pool = torch.index_select(encoded_database, 0, torch.tensor(allowed_arguments_ids, device=device))\n",
    "\n",
    "\n",
    "        for i in range(50):\n",
    "\n",
    "            # gather all the goals in the history\n",
    "            try:\n",
    "                representations, context_set, fringe_sizes = gather_encoded_content(env.history, batch_encoder_)\n",
    "            except Exception as e:\n",
    "                print (e)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            representations = representations.to(device)\n",
    "            context_scores = context_net(representations)\n",
    "            contexts_by_fringe, scores_by_fringe = split_by_fringe(context_set, context_scores, fringe_sizes)\n",
    "            fringe_scores = []\n",
    "            for s in scores_by_fringe:\n",
    "                # fringe_score = torch.prod(s) # TODO: make it sum\n",
    "                fringe_score = torch.sum(s) # TODO: make it sum\n",
    "                fringe_scores.append(fringe_score)\n",
    "            fringe_scores = torch.stack(fringe_scores)\n",
    "            fringe_probs = F.softmax(fringe_scores, dim=0)\n",
    "            fringe_m = Categorical(fringe_probs)\n",
    "            fringe = fringe_m.sample()\n",
    "            fringe_pool.append(fringe_m.log_prob(fringe))\n",
    "\n",
    "            # take the first context in the chosen fringe for now\n",
    "            try:\n",
    "                target_context = contexts_by_fringe[fringe][0]\n",
    "            except:\n",
    "                print (\"error {} {}\".format(contexts_by_fringe, fringe))\n",
    "\n",
    "           # target_context = contexts_by_fringe[fringe][0]\n",
    "            target_goal = target_context[\"polished\"][\"goal\"]\n",
    "            target_representation = representations[context_set.index(target_context)]\n",
    "            # print(target_representation.shape)\n",
    "            # exit()\n",
    "\n",
    "            # size: (1, max_contexts, max_assumptions+1, max_len)\n",
    "            tac_input = target_representation.unsqueeze(0)\n",
    "            tac_input = tac_input.to(device)\n",
    "\n",
    "            # compute scores of tactics\n",
    "            tac_probs = tac_net(tac_input)\n",
    "            # print(tac_probs)\n",
    "            tac_m = Categorical(tac_probs)\n",
    "            tac = tac_m.sample()\n",
    "            # log directly the log probability\n",
    "            tac_pool.append(tac_m.log_prob(tac))\n",
    "            action_pool.append(tactic_pool[tac])\n",
    "            tac_print.append(tac_probs.detach())\n",
    "            # print(len(fact_pool[0].strip().split()))\n",
    "            # exit()\n",
    "\n",
    "            tac_tensor = tac.to(device)\n",
    "\n",
    "\n",
    "            if tactic_pool[tac] in no_arg_tactic:\n",
    "                tactic = tactic_pool[tac]\n",
    "                arg_probs = []\n",
    "                arg_probs.append(torch.tensor(0))\n",
    "                arg_pool.append(arg_probs)\n",
    "            elif tactic_pool[tac] == \"Induct_on\":\n",
    "                arg_probs = []\n",
    "                candidates = []\n",
    "                # input = torch.cat([target_representation, tac_tensor], dim=1)\n",
    "                tokens = target_goal.split()\n",
    "                tokens = list(dict.fromkeys(tokens))\n",
    "                tokens = [[t] for t in tokens if t[0] == \"V\"]\n",
    "                if tokens:\n",
    "                    # concatenate target_representation to token\n",
    "                    # use seq2seq to compute the representation of a token\n",
    "                    # also we don't need to split an element in tokens because they are singletons\n",
    "                    # but we need to make it a list containing a singleton list, i.e., [['Vl']]\n",
    "\n",
    "                    token_representations, _ = batch_encoder_.encode(tokens)\n",
    "                    # reshaping\n",
    "                    encoded_tokens = torch.cat(token_representations.split(1), dim=2).squeeze(0)\n",
    "                    target_representation_list = [target_representation.unsqueeze(0) for _ in tokens]\n",
    "\n",
    "                    target_representations = torch.cat(target_representation_list)\n",
    "                    # size: (len(tokens), 512)\n",
    "                    candidates = torch.cat([encoded_tokens, target_representations], dim=1)\n",
    "                    candidates = candidates.to(device)\n",
    "\n",
    "                    # concat = [torch.cat([torch.tensor([input_vocab.stoi[i] for _ in range(256)], dtype=torch.float), target_representation]) for i in tokens]\n",
    "\n",
    "                    # candidates = torch.stack(concat)\n",
    "                    # candidates = candidates.to(device)\n",
    "\n",
    "                    scores = term_net(candidates, tac_tensor)\n",
    "                    term_probs = F.softmax(scores, dim=0)\n",
    "                    try:\n",
    "                        term_m = Categorical(term_probs.squeeze(1))\n",
    "                    except:\n",
    "                        print(\"probs: {}\".format(term_probs))                                          \n",
    "                        print(\"candidates: {}\".format(candidates.shape))\n",
    "                        print(\"scores: {}\".format(scores))\n",
    "                        print(\"tokens: {}\".format(tokens))\n",
    "                        exit()\n",
    "                    term = term_m.sample()\n",
    "                    arg_probs.append(term_m.log_prob(term))\n",
    "                    induct_arg.append(tokens[term])                \n",
    "                    tm = tokens[term][0][1:] # remove headers, e.g., \"V\" / \"C\" / ...\n",
    "                    arg_pool.append(arg_probs)\n",
    "                    if tm:\n",
    "                        tactic = \"Induct_on `{}`\".format(tm)\n",
    "                    else:\n",
    "                        print(\"tm is empty\")\n",
    "                        print(tokens)\n",
    "                        # only to raise an error\n",
    "                        tactic = \"Induct_on\"\n",
    "                else:\n",
    "                    arg_probs.append(torch.tensor(0))\n",
    "                    induct_arg.append(\"No variables\")\n",
    "                    arg_pool.append(arg_probs)\n",
    "                    tactic = \"Induct_on\"\n",
    "            else:\n",
    "                hidden0 = hidden1 = target_representation.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "                hidden0 = hidden0.to(device)\n",
    "                hidden1 = hidden1.to(device)\n",
    "\n",
    "                hidden = (hidden0, hidden1)\n",
    "\n",
    "                # concatenate the candidates with hidden states.\n",
    "\n",
    "                hc = torch.cat([hidden0.squeeze(), hidden1.squeeze()])\n",
    "                hiddenl = [hc.unsqueeze(0) for _ in allowed_arguments_ids]\n",
    "\n",
    "                hiddenl = torch.cat(hiddenl)\n",
    "\n",
    "                # size: (len(fact_pool), 512)\n",
    "                candidates = torch.cat([encoded_fact_pool, hiddenl], dim=1)\n",
    "                candidates = candidates.to(device)\n",
    "\n",
    "                input = tac_tensor\n",
    "                # run it once before predicting the first argument\n",
    "                hidden, _ = arg_net(input, candidates, hidden)\n",
    "\n",
    "                # the indices of chosen args\n",
    "                arg_step = []\n",
    "                arg_step_probs = []\n",
    "                if tactic_pool[tac] in thm_tactic:\n",
    "                    arg_len = 1\n",
    "                else:\n",
    "                    arg_len = ARG_LEN\n",
    "\n",
    "                    \n",
    "                for _ in range(arg_len):\n",
    "                    hidden, scores = arg_net(input, candidates, hidden)\n",
    "                    arg_probs = F.softmax(scores, dim=0)\n",
    "                    arg_m = Categorical(arg_probs.squeeze(1))\n",
    "                    arg = arg_m.sample()\n",
    "                    arg_step.append(arg)\n",
    "                    arg_step_probs.append(arg_m.log_prob(arg))\n",
    "\n",
    "                    hidden0 = hidden[0].squeeze().repeat(1, 1, 1)\n",
    "                    hidden1 = hidden[1].squeeze().repeat(1, 1, 1)\n",
    "                    # encoded chosen argument\n",
    "                    input = encoded_fact_pool[arg].unsqueeze(0).unsqueeze(0)\n",
    "                    # print(input.shape)\n",
    "\n",
    "                    # renew candidates                \n",
    "                    hc = torch.cat([hidden0.squeeze(), hidden1.squeeze()])\n",
    "                    hiddenl = [hc.unsqueeze(0) for _ in allowed_arguments_ids]\n",
    "\n",
    "                    hiddenl = torch.cat(hiddenl)\n",
    "\n",
    "                    # size: (len(fact_pool), 512)\n",
    "                    candidates = torch.cat([encoded_fact_pool, hiddenl], dim=1)\n",
    "                    candidates = candidates.to(device)\n",
    "\n",
    "                arg_pool.append(arg_step_probs)\n",
    "\n",
    "                tac = tactic_pool[tac]\n",
    "                arg = [candidate_args[j] for j in arg_step]\n",
    "\n",
    "                tactic = env.assemble_tactic(tac, arg)\n",
    "\n",
    "            action = (fringe.item(), 0, tactic)\n",
    "\n",
    "\n",
    "            print (action)\n",
    "            # reward, done = env.step(action)\n",
    "            try:\n",
    "                # when step is performed, env.history (probably) changes\n",
    "                # if goal_index == 0:\n",
    "                #     raise \"boom\"\n",
    "                reward, done = env.step(action)\n",
    "\n",
    "            except:\n",
    "                print(\"Step exception raised.\")\n",
    "                # print(\"Fringe: {}\".format(env.history))\n",
    "                print(\"Handling: {}\".format(env.handling))\n",
    "                print(\"Using: {}\".format(env.using))\n",
    "                # try again\n",
    "                # counter = env.counter\n",
    "                frequency = env.frequency\n",
    "                env.close()\n",
    "                print(\"Aborting current game ...\")\n",
    "                print(\"Restarting environment ...\")\n",
    "                print(env.goal)\n",
    "                env = HolEnv(env.goal)\n",
    "                flag = False\n",
    "                break\n",
    "\n",
    "            if t == 49:\n",
    "                reward = -5\n",
    "            # state_pool.append(state)\n",
    "            reward_print.append(reward)\n",
    "            # reward_pool.append(reward+trade_off*entropy)\n",
    "            reward_pool.append(reward)\n",
    "\n",
    "                # pg = ng\n",
    "\n",
    "            steps += 1\n",
    "            total_reward = float(np.sum(reward_print))\n",
    "\n",
    "            if done == True:\n",
    "                print (\"Goal Proved in {} steps\".format(i+1))\n",
    "                break\n",
    "                \n",
    "            if t == 49:\n",
    "                print(\"Failed.\")\n",
    "                print(\"Rewards: {}\".format(reward_print))\n",
    "                # print(\"Rewards: {}\".format(reward_pool))\n",
    "                print(\"Tactics: {}\".format(action_pool))\n",
    "                # print(\"Mean reward: {}\\n\".format(np.mean(reward_pool)))\n",
    "                print(\"Total: {}\".format(total_reward))\n",
    "                iteration_rewards.append(total_reward)\n",
    "\n",
    "        # Update policy\n",
    "        # Discount reward\n",
    "        print(\"Updating parameters ... \")\n",
    "        running_add = 0\n",
    "        for i in reversed(range(steps)):\n",
    "            if reward_pool[i] == 0:\n",
    "                running_add = 0\n",
    "            else:\n",
    "                running_add = running_add * gamma + reward_pool[i]\n",
    "                reward_pool[i] = running_add\n",
    "\n",
    "        optimizer_context.zero_grad()\n",
    "        optimizer_tac.zero_grad()\n",
    "        optimizer_arg.zero_grad()\n",
    "        optimizer_term.zero_grad()\n",
    "\n",
    "        for i in range(steps):\n",
    "            # size : (1,1,4,128)\n",
    "            total_loss = 0\n",
    "\n",
    "            # state = state_pool[i]\n",
    "            reward = reward_pool[i]\n",
    "\n",
    "            fringe_loss = -fringe_pool[i] * (reward)\n",
    "            arg_loss = -torch.sum(torch.stack(arg_pool[i])) * (reward)\n",
    "\n",
    "            tac_loss = -tac_pool[i] * (reward)\n",
    "\n",
    "            # entropy = fringe_pool[i] + torch.sum(torch.stack(arg_pool[i])) + tac_pool[i]\n",
    "\n",
    "            # loss = fringe_loss + tac_loss + arg_loss + trade_off*entropy\n",
    "            loss = fringe_loss + tac_loss + arg_loss\n",
    "            total_loss += loss\n",
    "            #loss.backward()\n",
    "\n",
    "        total_loss.backward()\n",
    "\n",
    "        # optimizer.step()\n",
    "\n",
    "        optimizer_context.step()\n",
    "        optimizer_tac.step()\n",
    "        optimizer_arg.step()\n",
    "        optimizer_term.step()\n",
    "\n",
    "        fringe_pool = []\n",
    "        tac_pool = []\n",
    "        arg_pool = []\n",
    "        action_pool = []\n",
    "        reward_pool = []\n",
    "        reward_print = []\n",
    "        steps = 0\n",
    "        elapsed = time.time() - start_t\n",
    "\n",
    "        print (elapsed)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "entertaining-paint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIST_REL (R :α -> β -> bool) (l1 :α list) (l2 :β list) ∧ LIST_REL R (l3 :α list) (l4 :β list) ⇒ LIST_REL R (l1 ++ l3) (l2 ++ l4)\n",
      "Importing theories...\n",
      "Loading modules...\n",
      "Configuration done.\n",
      "Removing simp lemmas from LIST_REL (R :α -> β -> bool) (l1 :α list) (l2 :β list) ∧ LIST_REL R (l3 :α list) (l4 :β list) ⇒ LIST_REL R (l1 ++ l3) (l2 ++ l4)\n",
      "(0, 0, 'simp[boolTheory.EQ_EXPAND, boolTheory.EXISTS_REFL, listTheory.list_Axiom, listTheory.LLEX_total, listTheory.EXISTS_MEM]')\n",
      "(0, 0, 'simp[boolTheory.FORALL_DEF, listTheory.SNOC_11, listTheory.LLEX_EL_THM, listTheory.MAP2_APPEND, boolTheory.NOT_EXISTS_THM]')\n",
      "(0, 0, 'drule listTheory.adjacent_cases')\n",
      "(0, 0, 'metis_tac[boolTheory.COND_RATOR, listTheory.LIST_TO_SET, listTheory.EXISTS_SIMP, listTheory.LLEX_THM, boolTheory.BOTH_FORALL_IMP_THM]')\n",
      "(1, 0, 'rw[listTheory.ZIP_MAP, boolTheory.OR_INTRO_THM1, listTheory.DROP_def, listTheory.LIST_REL_APPEND_EQ, listTheory.APPEND_FRONT_LAST]')\n",
      "(0, 0, 'Induct_on `l4`')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(2, 0, 'drule boolTheory.RIGHT_AND_FORALL_THM')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'rw[listTheory.SHORTLEX_THM, listTheory.MEM_APPEND, boolTheory.ITSELF_UNIQUE, listTheory.CARD_LIST_TO_SET, listTheory.ALL_DISTINCT_ZIP_SWAP]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'metis_tac[listTheory.TAKE1_DROP, listTheory.LIST_REL_CONS1, listTheory.LENGTH_TL, listTheory.FOLDL_SNOC, listTheory.MAP_FLAT]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'Induct_on `l1`')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(2, 0, 'drule listTheory.MAP_DROP')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'metis_tac[listTheory.INJ_MAP_EQ, listTheory.GENLIST, listTheory.EVERY2_mono, listTheory.GENLIST_APPEND, boolTheory.BOTH_FORALL_IMP_THM]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'drule listTheory.REVERSE_EQ_SING')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(2, 0, 'drule listTheory.LUPDATE_def')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'rw[listTheory.MAP_ID, listTheory.TAKE_compute, listTheory.SET_TO_LIST_IND, listTheory.MAP_EQ_APPEND, boolTheory.OR_CONG]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'drule listTheory.LENGTH_DROP')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(2, 0, 'drule listTheory.FILTER_EQ_CONS')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(2, 0, 'drule listTheory.FILTER_EQ_APPEND')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(2, 0, 'drule listTheory.INDEX_FIND_def')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'drule listTheory.NOT_NIL_EQ_LENGTH_NOT_0')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'rw[boolTheory.NOT_FORALL_THM, listTheory.list_CASES, listTheory.NULL_FILTER, listTheory.FOLDL_SNOC, listTheory.TAKE_cons]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'metis_tac[listTheory.MEM_ZIP, boolTheory.EXISTS_SIMP, listTheory.LAST_CONS, listTheory.ALL_DISTINCT_SET_TO_LIST, listTheory.MAP_ID]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'metis_tac[boolTheory.BOTH_EXISTS_IMP_THM, listTheory.TAKE_LENGTH_ID, listTheory.LLEX_def, listTheory.FOLDL_UNION_BIGUNION, listTheory.FOLDR_CONG]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'simp[listTheory.DROP_EQ_NIL, listTheory.ALL_DISTINCT_SNOC, listTheory.EVERY_FLAT, boolTheory.OR_INTRO_THM2, boolTheory.EQ_SYM]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'drule listTheory.WF_SHORTLEX_same_lengths')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'simp[listTheory.SNOC, listTheory.MEM_GENLIST, listTheory.EQ_LIST, boolTheory.LEFT_OR_OVER_AND, listTheory.LIST_REL_O]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(2, 0, 'simp[listTheory.LENGTH_EQ_SUM, listTheory.LENGTH_TAKE_EQ, boolTheory.MONO_COND, boolTheory.MONO_NOT, listTheory.REVERSE_APPEND]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'EQ_TAC')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(2, 0, 'irule listTheory.FOLDL2_FOLDL')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'irule listTheory.FOLDL_ZIP_SAME')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'Induct_on `l2`')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'metis_tac[listTheory.EVERY_SIMP, listTheory.oEL_LUPDATE, listTheory.MAP2_CONG, listTheory.datatype_list, listTheory.list_CASES]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'drule listTheory.UNZIP_MAP')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(2, 0, 'irule listTheory.FILTER_EQ_ID')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'EQ_TAC')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'drule boolTheory.LEFT_OR_EXISTS_THM')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'simp[listTheory.LIST_REL_MAP1, listTheory.ZIP_GENLIST, boolTheory.UNWIND_THM1, listTheory.LIST_REL_eq, listTheory.nub_append]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'EQ_TAC')\n",
      "same action\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'strip_tac')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'metis_tac[listTheory.ALL_DISTINCT_MAP_INJ, listTheory.MAP_DROP, listTheory.MEM_MAP_f, listTheory.SET_TO_LIST_primitive_def, listTheory.LIST_REL_LENGTH]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'metis_tac[listTheory.LENGTH_ZIP, boolTheory.COND_RATOR, listTheory.NOT_CONS_NIL, listTheory.TAKE_compute, listTheory.BIGUNION_IMAGE_set_SUBSET]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'simp[listTheory.MEM_LUPDATE_E, listTheory.oEL_LUPDATE, boolTheory.FUN_EQ_THM, boolTheory.EQ_REFL, listTheory.REVERSE_EQ_NIL]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'Induct_on `R`')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'strip_tac')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(2, 0, 'drule listTheory.EVERY2_EVERY')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(2, 0, 'simp[listTheory.EL_DROP, listTheory.TAKE1, listTheory.ZIP_MAP, listTheory.EXISTS_MAP, listTheory.SWAP_REVERSE_SYM]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(2, 0, 'fs[boolTheory.literal_case_RAND, listTheory.SUM_IMAGE_LIST_TO_SET_upper_bound, listTheory.MEM_APPEND, listTheory.LUPDATE_SOME_MAP, listTheory.dropWhile_APPEND_EXISTS]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(2, 0, 'fs[boolTheory.AND_CONG, listTheory.LIST_REL_SPLIT1, listTheory.APPEND_EQ_APPEND_MID, listTheory.REVERSE_REVERSE, listTheory.LENGTH_TAKE]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'simp[listTheory.REVERSE_SNOC_DEF, boolTheory.CONJ_COMM, listTheory.ALL_DISTINCT_REVERSE, listTheory.FILTER_EQ_ID, listTheory.list_size_cong]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'metis_tac[listTheory.DROP_0, listTheory.LAST_CONS_cond, listTheory.DROP_LENGTH_TOO_LONG, boolTheory.UNWIND_THM2, listTheory.list_case_eq]')\n",
      "Updating parameters ... \n",
      "12.173920154571533\n",
      "LIST_REL (R :α -> β -> bool) (l1 :α list) (l2 :β list) ∧ LIST_REL R (l3 :α list) (l4 :β list) ⇔ LIST_REL R (l1 ++ l3) (l2 ++ l4) ∧ LENGTH l1 = LENGTH l2 ∧ LENGTH l3 = LENGTH l4\n",
      "Importing theories...\n",
      "Loading modules...\n",
      "Configuration done.\n",
      "Removing simp lemmas from LIST_REL (R :α -> β -> bool) (l1 :α list) (l2 :β list) ∧ LIST_REL R (l3 :α list) (l4 :β list) ⇔ LIST_REL R (l1 ++ l3) (l2 ++ l4) ∧ LENGTH l1 = LENGTH l2 ∧ LENGTH l3 = LENGTH l4\n",
      "(0, 0, 'EQ_TAC')\n",
      "(0, 0, 'strip_tac')\n",
      "(0, 0, 'strip_tac')\n",
      "same action\n",
      "(0, 0, 'simp[listTheory.LIST_REL_EVERY_ZIP, listTheory.SHORTLEX_LENGTH_LE, boolTheory.COND_RATOR, listTheory.LIST_REL_MEM_IMP, listTheory.SNOC_INDUCT]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'strip_tac')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'Induct_on `R`')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'irule listTheory.SET_TO_LIST_IN_MEM')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'fs[listTheory.TL, listTheory.LIST_REL_EL_EQN, listTheory.lazy_list_case_compute, listTheory.SUM_ACC_SUM_LEM, listTheory.LLEX_NIL2]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 'simp[listTheory.ALL_DISTINCT_MAP_INJ, listTheory.MEM_DROP, listTheory.LIST_REL_EL_EQN, listTheory.SUM_MAP_PLUS_ZIP, listTheory.ZIP_DROP]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'strip_tac')\n",
      "same action\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'metis_tac[boolTheory.SWAP_EXISTS_THM, listTheory.EL_APPEND_EQN, boolTheory.boolAxiom, listTheory.last_drop, listTheory.adjacent_rules]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'fs[listTheory.SUM_ACC_SUM_LEM, listTheory.TAKE_DROP, boolTheory.DISJ_COMM, listTheory.FLAT_compute, listTheory.GENLIST_CONS]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'rw[listTheory.ALL_DISTINCT_REVERSE, listTheory.MAP_MAP_o, listTheory.MAP_APPEND_MAP_EQ, listTheory.NULL_EQ, listTheory.MAP_FRONT]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'metis_tac[listTheory.APPEND_EQ_APPEND_MID, listTheory.LENGTH_NIL_SYM, listTheory.SUM_APPEND, boolTheory.EXISTS_REFL, listTheory.LAST_CONS_cond]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'Induct_on `l2`')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'metis_tac[boolTheory.AND1_THM, boolTheory.LEFT_OR_OVER_AND, boolTheory.IMP_F, boolTheory.IMP_DISJ_THM, boolTheory.SELECT_REFL_2]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'rw[listTheory.REVERSE_11, listTheory.oEL_LUPDATE, listTheory.EVERY_NOT_EXISTS, listTheory.INDEX_OF_def, boolTheory.TRUTH]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'rw[listTheory.HD_dropWhile, listTheory.LLEX_NIL2, listTheory.ITSET_eq_FOLDL_SET_TO_LIST, listTheory.LLEX_CONG, listTheory.LIST_BIND_MAP]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'strip_tac')\n",
      "same action\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'Induct_on `l2`')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'metis_tac[boolTheory.BOOL_FUN_INDUCT, listTheory.LEN_LENGTH_LEM, listTheory.splitAtPki_MAP, listTheory.SUM_eq_0, boolTheory.RES_FORALL_DEF]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'rw[listTheory.EXISTS_NOT_EVERY, boolTheory.LEFT_EXISTS_IMP_THM, boolTheory.RES_SELECT_DEF, listTheory.FILTER_F, listTheory.adjacent_iff]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'metis_tac[listTheory.LENGTH_TAKE, boolTheory.IMP_F, boolTheory.FALSITY, listTheory.LUPDATE_SEM, listTheory.SNOC]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'strip_tac')\n",
      "same action\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'fs[listTheory.ALL_DISTINCT_FLAT_REVERSE, boolTheory.UNWIND_THM1, listTheory.nub_def, boolTheory.itself_Axiom, boolTheory.EXISTS_SIMP]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'rw[listTheory.SUM_MAP_PLUS_ZIP, listTheory.nub_def, listTheory.LLEX_def, listTheory.EVERY2_cong, listTheory.LIST_EQ_REWRITE]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'simp[listTheory.LIST_REL_eq, boolTheory.SELECT_THM, listTheory.MAP2_DEF, listTheory.LIST_BIND_ID, boolTheory.AND_IMP_INTRO]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'fs[listTheory.SET_TO_LIST_THM, listTheory.LENGTH_EQ_NUM, boolTheory.IMP_ANTISYM_AX, listTheory.INDEX_OF_def, listTheory.MEM_FLAT]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'drule listTheory.LAST_CONS')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'metis_tac[listTheory.mem_exists_set, boolTheory.DISJ_IMP_THM, listTheory.EXISTS_SIMP, listTheory.LAST_EL, listTheory.FOLDL_UNION_BIGUNION]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'Induct_on `l2`')\n",
      "same action\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'rw[listTheory.NOT_NULL_MEM, listTheory.FIND_def, boolTheory.BOUNDED_DEF, listTheory.APPEND_11, listTheory.DROP_0]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'drule listTheory.adjacent_def')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'irule listTheory.LUPDATE_SNOC')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'drule listTheory.MAP_ID')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'irule listTheory.UNZIP_MAP')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 'metis_tac[listTheory.adjacent_thm, listTheory.SINGL_LIST_APPLY_R, boolTheory.F_DEF, boolTheory.IMP_F, listTheory.SINGL_LIST_APPLY_L]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'fs[listTheory.EXISTS_LIST_EQ_MAP, listTheory.LUPDATE_GENLIST, listTheory.LIST_EQ, listTheory.LIST_REL_trans, boolTheory.REFL_CLAUSE]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'rw[listTheory.EVERY2_REVERSE, boolTheory.FALSITY, listTheory.LAST_CONS, listTheory.SINGL_LIST_APPLY_R, listTheory.SUM_MAP_PLUS]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'strip_tac')\n",
      "same action\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'Induct_on `R`')\n",
      "same action\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'Induct_on `l4`')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'Induct_on `l2`')\n",
      "same action\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'irule listTheory.dropWhile_def')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'strip_tac')\n",
      "same action\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'metis_tac[listTheory.MONO_EVERY, listTheory.dropWhile_splitAtPki, listTheory.REVERSE_11, boolTheory.EXISTS_DEF, listTheory.LIST_EQ_REWRITE]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'irule listTheory.adjacent_def')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'metis_tac[listTheory.GENLIST_NUMERALS, listTheory.UNIQUE_DEF, boolTheory.LCOMM_THM, listTheory.SUM_IMAGE_LIST_TO_SET_upper_bound, listTheory.ALL_DISTINCT_GENLIST]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(1, 0, 'fs[boolTheory.SKOLEM_THM, boolTheory.itself_TY_DEF, boolTheory.FORALL_SIMP, listTheory.REV_REVERSE_LEM, rich_listTheory.EVERY2_APPEND_suff]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'rw[listTheory.SUM_ACC_DEF, boolTheory.EXISTS_itself, listTheory.GENLIST_APPEND, boolTheory.DE_MORGAN_THM, listTheory.LENGTH_NIL_SYM]')\n",
      "Updating parameters ... \n",
      "12.226503610610962\n",
      "∀(ls :α list) (n :num). ALL_DISTINCT ls ⇒ ALL_DISTINCT (DROP n ls)\n",
      "Importing theories...\n",
      "Loading modules...\n",
      "Configuration done.\n",
      "Removing simp lemmas from ∀(ls :α list) (n :num). ALL_DISTINCT ls ⇒ ALL_DISTINCT (DROP n ls)\n",
      "(0, 0, 'fs[listTheory.SNOC, listTheory.list_case_def, listTheory.LIST_TO_SET_SNOC, listTheory.LIST_TO_SET_FLAT, boolTheory.FORALL_itself]')\n",
      "(0, 0, 'simp[boolTheory.UEXISTS_SIMP, listTheory.MAP_TAKE, listTheory.LIST_EQ_REWRITE, listTheory.FILTER_ALL_DISTINCT, listTheory.adjacent_rules]')\n",
      "(0, 0, 'EQ_TAC')\n",
      "(0, 0, 'EQ_TAC')\n",
      "same action\n",
      "(0, 0, 'drule listTheory.FILTER_EQ_NIL')\n",
      "(0, 0, 'simp[listTheory.LIST_REL_SNOC, listTheory.SHORTLEX_THM, listTheory.adjacent_cases, listTheory.MEM_FLAT, listTheory.LENGTH_NIL]')\n",
      "(0, 0, 'EQ_TAC')\n",
      "same action\n",
      "(0, 0, 'Induct_on `ls`')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'simp[listTheory.MEM_EL, listTheory.FOLDL_CONG, boolTheory.EXISTS_itself, listTheory.LIST_EQ, listTheory.TAKE_LENGTH_ID]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'fs[listTheory.ALL_DISTINCT_GENLIST, boolTheory.BOTH_FORALL_IMP_THM, boolTheory.SELECT_REFL, listTheory.UNZIP_ZIP, listTheory.EXISTS_APPEND]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'rw[listTheory.REVERSE_APPEND, listTheory.LAST_DEF, boolTheory.DATATYPE_TAG_DEF, listTheory.MAP_SNOC, boolTheory.ONTO_DEF]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'EQ_TAC')\n",
      "same action\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'simp[listTheory.EL, listTheory.LUPDATE_compute, boolTheory.literal_case_id, listTheory.EVERY_MEM, listTheory.APPEND_FRONT_LAST]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'Induct_on `n`')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'Induct_on `n`')\n",
      "same action\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'EQ_TAC')\n",
      "same action\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'drule listTheory.MAP_LIST_BIND')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'drule listTheory.SING_HD')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'drule listTheory.DISJOINT_GENLIST_PLUS')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'irule listTheory.MAP2_MAP')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'metis_tac[listTheory.LIST_REL_CONS1, listTheory.LLEX_EL_THM, listTheory.MEM_ZIP_MEM_MAP, boolTheory.SELECT_UNIQUE, boolTheory.JRH_INDUCT_UTIL]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'drule boolTheory.EQ_CLAUSES')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'rw[listTheory.SHORTLEX_transitive, listTheory.LENGTH_o_REVERSE, listTheory.SET_TO_LIST_THM, listTheory.GENLIST_PLUS_APPEND, listTheory.ALL_DISTINCT_SNOC]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'Induct_on `n`')\n",
      "same action\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'strip_tac')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'EQ_TAC')\n",
      "same action\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'metis_tac[listTheory.FILTER_EQ_APPEND, boolTheory.DATATYPE_TAG_THM, listTheory.SINGL_SINGL_APPLY, listTheory.LIST_REL_ind, listTheory.WF_SHORTLEX]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'EQ_TAC')\n",
      "same action\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'irule boolTheory.IMP_CLAUSES')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'irule listTheory.TAKE_DROP')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'simp[listTheory.LIST_REL_MAP1, boolTheory.OR_ELIM_THM, listTheory.NOT_EQ_LIST, listTheory.MEM_SPLIT_APPEND_last, listTheory.HD_GENLIST_COR]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'metis_tac[listTheory.FINITE_LIST_TO_SET, listTheory.isPREFIX_THM, boolTheory.bool_case_CONG, listTheory.LIST_BIND_def, listTheory.SNOC_11]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'drule listTheory.MAP_ID')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'irule listTheory.FILTER_EQ_ID')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'simp[listTheory.LENGTH_EQ_NUM, listTheory.ZIP_DROP, listTheory.FLAT, listTheory.LIST_TO_SET_REVERSE, listTheory.DISJOINT_GENLIST_PLUS]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'Induct_on `n`')\n",
      "same action\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'EQ_TAC')\n",
      "same action\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'fs[listTheory.TAKE_DROP_SWAP, listTheory.FOLDL_EQ_FOLDR, listTheory.ZIP_def, boolTheory.FORALL_THM, boolTheory.literal_case_id]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'metis_tac[listTheory.APPEND_EQ_APPEND, listTheory.splitAtPki_APPEND, listTheory.DROP_LENGTH_TOO_LONG, listTheory.LIST_REL_MAP2, listTheory.SUM_eq_0]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'irule listTheory.SUM_MAP_PLUS_ZIP')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'fs[boolTheory.bool_case_CONG, listTheory.SNOC_INDUCT, listTheory.LENGTH, listTheory.MAP_SNOC, listTheory.NOT_EXISTS]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'metis_tac[listTheory.EL_ALL_DISTINCT_EL_EQ, listTheory.TAKE_def, listTheory.MEM_SPLIT_APPEND_first, listTheory.nub_NIL, boolTheory.MONO_NOT]')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'irule listTheory.SET_TO_LIST_EMPTY')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'EQ_TAC')\n",
      "same action\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'drule boolTheory.MONO_NOT')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'irule listTheory.adjacent_thm')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'drule listTheory.REV_REVERSE_LEM')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 'irule listTheory.SET_TO_LIST_SING')\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'strip_tac')\n",
      "same action\n",
      "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.\n",
      "(0, 0, 'Induct_on `n`')\n",
      "same action\n",
      "Updating parameters ... \n",
      "11.211392641067505\n",
      "∀(l :(α # β) list). ZIP (UNZIP l) = l\n",
      "Importing theories...\n",
      "Loading modules...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m GOALS \u001b[38;5;241m=\u001b[39m [(key, value[\u001b[38;5;241m4\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m database\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m value[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthm\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m value[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m TARGET_THEORIES]\n\u001b[1;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mrun_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGOALS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36mrun_iteration\u001b[0;34m(goals, mode, ARG_LEN)\u001b[0m\n\u001b[1;32m     63\u001b[0m g \u001b[38;5;241m=\u001b[39m goal[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m (g)\n\u001b[0;32m---> 66\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mHolEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m theories \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m$(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m$ \u001b[39m\u001b[38;5;124m'\u001b[39m, goal[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     69\u001b[0m theories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(theories)\n",
      "File \u001b[0;32m~/Documents/PhD/git/repo/PhD/tactic_zero_jax/env/new_env.py:120\u001b[0m, in \u001b[0;36mHolEnv.__init__\u001b[0;34m(self, goal)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess\u001b[38;5;241m.\u001b[39msendline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mhelper.sml\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# self.process.sendline(\"val _ = load \\\"Timeout\\\";\")\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfiguration done.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess\u001b[38;5;241m.\u001b[39mexpect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TARGET_THEORIES = [\"list\"]\n",
    "GOALS = [(key, value[4]) for key, value in database.items() if value[3] == \"thm\" and value[0] in TARGET_THEORIES]\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "run_iteration(GOALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "conceptual-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "# do stuff\n",
    "elapsed = time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "transparent-craft",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.245208740234375e-05"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "assured-intelligence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 11.2 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-henry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
