{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "considerable-sandwich",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "import optax\n",
    "\n",
    "from jax import random\n",
    "import sys\n",
    "from time import sleep\n",
    "import json\n",
    "import pexpect\n",
    "import re\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import timeit\n",
    "import torch\n",
    "\n",
    "import seq2seq\n",
    "from batch_predictor import BatchPredictor\n",
    "from checkpoint import Checkpoint\n",
    "\n",
    "from policy_networks import *\n",
    "import policy_networks\n",
    "\n",
    "from new_env import *\n",
    "\n",
    "from jax.config import config\n",
    "config.update(\"jax_debug_nans\", True) \n",
    "#jax.config.update(\"jax_enable_x64\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intelligent-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "path_dir = \"/home/sean/Documents/PhD/tactic_zero_jax/env/model_params\"\n",
    "\n",
    "def save(params, path):\n",
    "    with open(path, 'wb') as fp:\n",
    "        pickle.dump(params, fp)\n",
    "\n",
    "def load(path):\n",
    "    with open(path, 'rb') as fp:\n",
    "        return pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "necessary-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HOLPATH = \"/home/sean/Documents/hol/HOL/bin/hol --maxheap=256\"\n",
    "HOLPATH = \"/home/sean/Documents/PhD/HOL4/HOL/bin/hol --maxheap=256\"\n",
    "\n",
    "#tactic_zero_path = \"/home/sean/Documents/PhD/git/repo/PhD/tacticzero/holgym/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "desperate-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"typed_database.json\") as f:\n",
    "    database = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "liked-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "MORE_TACTICS = True\n",
    "if not MORE_TACTICS:\n",
    "    thms_tactic = [\"simp\", \"fs\", \"metis_tac\"]\n",
    "    thm_tactic = [\"irule\"]\n",
    "    term_tactic = [\"Induct_on\"]\n",
    "    no_arg_tactic = [\"strip_tac\"]\n",
    "else:\n",
    "    thms_tactic = [\"simp\", \"fs\", \"metis_tac\", \"rw\"]\n",
    "    thm_tactic = [\"irule\", \"drule\"]\n",
    "    term_tactic = [\"Induct_on\"]\n",
    "    no_arg_tactic = [\"strip_tac\", \"EQ_TAC\"]\n",
    "    \n",
    "tactic_pool = thms_tactic + thm_tactic + term_tactic + no_arg_tactic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "textile-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Move to another file \n",
    "\n",
    "def get_polish(raw_goal):\n",
    "        goal = construct_goal(raw_goal)\n",
    "        process.sendline(goal.encode(\"utf-8\"))\n",
    "        process.expect(\"\\r\\n>\")\n",
    "        process.sendline(\"val _ = set_term_printer (HOLPP.add_string o pt);\".encode(\"utf-8\"))\n",
    "        process.expect(\"\\r\\n>\")\n",
    "        process.sendline(\"top_goals();\".encode(\"utf-8\"))\n",
    "        process.expect(\"val it =\")\n",
    "        process.expect([\": goal list\", \":\\r\\n +goal list\"])\n",
    "\n",
    "        polished_raw = process.before.decode(\"utf-8\")\n",
    "        polished_subgoals = re.sub(\"“|”\",\"\\\"\", polished_raw)\n",
    "        polished_subgoals = re.sub(\"\\r\\n +\",\" \", polished_subgoals)\n",
    "\n",
    "        pd = eval(polished_subgoals)\n",
    "        \n",
    "        process.expect(\"\\r\\n>\")\n",
    "        process.sendline(\"drop();\".encode(\"utf-8\"))\n",
    "        process.expect(\"\\r\\n>\")\n",
    "        process.sendline(\"val _ = set_term_printer default_pt;\".encode(\"utf-8\"))\n",
    "        process.expect(\"\\r\\n>\")\n",
    "\n",
    "        data = [{\"polished\":{\"assumptions\": e[0][0], \"goal\":e[0][1]},\n",
    "                 \"plain\":{\"assumptions\": e[1][0], \"goal\":e[1][1]}}\n",
    "                for e in zip(pd, [([], raw_goal)])]\n",
    "        return data \n",
    "    \n",
    "def construct_goal(goal):\n",
    "    s = \"g \" + \"`\" + goal + \"`;\"\n",
    "    return s\n",
    "\n",
    "def gather_encoded_content_(history, encoder):\n",
    "    fringe_sizes = []\n",
    "    contexts = []\n",
    "    reverted = []\n",
    "    for i in history:\n",
    "        c = i[\"content\"]\n",
    "        contexts.extend(c)\n",
    "        fringe_sizes.append(len(c))\n",
    "    for e in contexts:\n",
    "        g = revert_with_polish(e)\n",
    "        reverted.append(g.strip().split())\n",
    "    out = []\n",
    "    sizes = []\n",
    "    for goal in reverted:\n",
    "        out_, sizes_ = encoder.encode([goal])\n",
    "        out.append(torch.cat(out_.split(1), dim=2).squeeze(0))\n",
    "        sizes.append(sizes_)\n",
    "\n",
    "    representations = out\n",
    "\n",
    "    return representations, contexts, fringe_sizes\n",
    "\n",
    "def parse_theory(pg):\n",
    "    theories = re.findall(r'C\\$(\\w+)\\$ ', pg)\n",
    "    theories = set(theories)\n",
    "    for th in EXCLUDED_THEORIES:\n",
    "        theories.discard(th)\n",
    "    return list(theories)\n",
    "\n",
    "def revert_with_polish(context):\n",
    "    target = context[\"polished\"]\n",
    "    assumptions = target[\"assumptions\"]\n",
    "    goal = target[\"goal\"]\n",
    "    for i in reversed(assumptions): \n",
    "        #goal = \"@ @ D$min$==> {} {}\".format(i, goal)\n",
    "        goal = \"@ @ C$min$ ==> {} {}\".format(i, goal)\n",
    "\n",
    "    return goal \n",
    "\n",
    "def split_by_fringe(goal_set, goal_scores, fringe_sizes):\n",
    "    # group the scores by fringe\n",
    "    fs = []\n",
    "    gs = []\n",
    "    counter = 0\n",
    "    for i in fringe_sizes:\n",
    "        end = counter + i\n",
    "        fs.append(goal_scores[counter:end])\n",
    "        gs.append(goal_set[counter:end])\n",
    "        counter = end\n",
    "    return gs, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "capital-major",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIST_REL (R :α -> β -> bool) (l1 :α list) (l2 :β list) ∧ LIST_REL R (l3 :α list) (l4 :β list) ⇒ LIST_REL R (l1 ++ l3) (l2 ++ l4)\n"
     ]
    }
   ],
   "source": [
    "with open(\"include_probability.json\") as f:\n",
    "    database = json.load(f)\n",
    "\n",
    "with open(\"polished_def_dict.json\") as f:\n",
    "    defs = json.load(f)\n",
    "\n",
    "fact_pool = list(defs.keys())\n",
    "\n",
    "encoded_database = torch.load('encoded_include_probability.pt')\n",
    "\n",
    "TARGET_THEORIES = [\"bool\", \"min\", \"list\"]\n",
    "GOALS = [(key, value[4]) for key, value in database.items() if value[3] == \"thm\" and value[0] in TARGET_THEORIES]\n",
    "\n",
    "print (GOALS[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "forbidden-norfolk",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'seq2seq.models.EncoderRNN.EncoderRNN' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.GRU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'seq2seq.models.DecoderRNN.DecoderRNN' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "#checkpoint_path = \"models/2020_04_22_20_36_50\" # 91% accuracy model, only core theories\n",
    "#checkpoint_path = \"models/2020_04_26_20_11_28\" # 95% accuracy model, core theories + integer + sorting\n",
    "#checkpoint_path = \"models/2020_09_24_23_38_06\" # 98% accuracy model, core theories + integer + sorting | separate theory tokens\n",
    "#checkpoint_path = \"models/2020_11_28_16_45_10\" # 96-98% accuracy model, core theories + integer + sorting + real | separate theory tokens\n",
    "#checkpoint_path = \"models/2020_12_04_03_47_22\" # 97% accuracy model, core theories + integer + sorting + real + bag | separate theory tokens\n",
    "\n",
    "#checkpoint_path = \"models/2021_02_21_15_46_04\" # 98% accuracy model, up to probability theory\n",
    "\n",
    "checkpoint_path = \"models/2021_02_22_16_07_03\" # 97-98% accuracy model, up to and include probability theory\n",
    "\n",
    "checkpoint = Checkpoint.load(checkpoint_path)\n",
    "seq2seq = checkpoint.model\n",
    "input_vocab = checkpoint.input_vocab\n",
    "output_vocab = checkpoint.output_vocab\n",
    "\n",
    "batch_encoder_ = BatchPredictor(seq2seq, input_vocab, output_vocab)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "virtual-activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to give the log probability of pi(f | s) so gradient can be computed directly\n",
    "#also returns sampled index and contexts to determine goal to give tactic network\n",
    "def sample_fringe(context_params, context_net, rng_key, jax_reps, context_set, fringe_sizes):\n",
    "    context_scores = context_net(context_params, rng_key, jax_reps)\n",
    "    contexts_by_fringe, scores_by_fringe = split_by_fringe(context_set, context_scores, fringe_sizes)\n",
    "    fringe_scores = []\n",
    "    for s in scores_by_fringe:\n",
    "        fringe_score = jnp.sum(s)\n",
    "        fringe_scores.append(fringe_score)\n",
    "    #TODO some fringes can be empty, but still give value 0 which assigns nonzero probability?\n",
    "    fringe_scores = jnp.stack(fringe_scores)\n",
    "    fringe_probs = jax.nn.log_softmax(fringe_scores)\n",
    "\n",
    "    #samples, gives an index (looks like it does gumbel softmax under the hood to keep differentiability?)\n",
    "    sampled_idx = jax.random.categorical(rng_key,fringe_probs)\n",
    "\n",
    "    log_prob = fringe_probs[sampled_idx]\n",
    "    #log_prob = jnp.log(prob)\n",
    "    return log_prob, (sampled_idx, contexts_by_fringe)\n",
    "                                                           \n",
    "#grad_log_context, (fringe_idx, contexts_by_fringe) = jax.grad(sample_fringe, has_aux=True)(context_params, apply_context, rng_key, jax_reps, context_set, fringe_sizes)\n",
    "\n",
    "#takes a goal encoding and samples tactic from network, and returns log prob for gradient \n",
    "def sample_tactic(tactic_params, tac_net, rng_key, goal_endcoding, action_size=len(tactic_pool)):\n",
    "    tac_scores = tac_net(tactic_params, rng_key, goal_endcoding, action_size)\n",
    "    tac_scores = jnp.ravel(tac_scores)\n",
    "    #tac_scores = tac_scores - max(tac_scores)\n",
    "    #print (tac_scores)\n",
    "    #subtract max element for numerical stability \n",
    "    tac_probs = jax.nn.log_softmax(tac_scores)\n",
    "    tac_idx = jax.random.categorical(rng_key, tac_probs)\n",
    "    log_prob = tac_probs[tac_idx]#jnp.log(tac_probs[tac_idx])\n",
    "    #print (jnp.exp(log_prob).primal)#, jnp.exp(tac_probs), rng_key)\n",
    "    return log_prob, tac_idx\n",
    "\n",
    "#grad_log_tac, tac_idx = jax.grad(sample_tactic, has_aux=True)(tactic_params, apply_tac, rng_key, jnp.expand_dims(target_representation,0), len(tactic_pool))\n",
    "\n",
    "#sampled_tac = tactic_pool[tac_idx]\n",
    "\n",
    "def sample_term(term_params, term_net, rng_key, candidates):\n",
    "    term_scores = term_net(term_params, rng_key, candidates)\n",
    "    term_scores = jnp.ravel(term_scores)\n",
    "    term_probs = jax.nn.log_softmax(term_scores)\n",
    "    term_idx = jax.random.categorical(rng_key, term_probs)\n",
    "    log_prob = term_probs[term_idx]#jnp.log(term_probs[term_idx])\n",
    "    return log_prob, term_idx\n",
    "\n",
    "#grad_log_term, term_idx = jax.grad(sample_term, has_aux=True)(term_params, apply_term, rng_key, candidates)#, tac_idx, len(tactic_pool), candidates.shape[1])\n",
    "\n",
    "#function for sampling single argument given previous arguments, \n",
    "def sample_arg(arg_params, arg_net, rng_key, input_, candidates, hidden, tactic_size, embedding_dim):\n",
    "    hidden, arg_scores = arg_net(arg_params, rng_key, input_, candidates, hidden, tactic_size, embedding_dim)\n",
    "    arg_scores = jnp.ravel(arg_scores)\n",
    "    arg_probs = jax.nn.log_softmax(arg_scores)\n",
    "    arg_idx = jax.random.categorical(rng_key, arg_probs)\n",
    "    log_prob = arg_probs[arg_idx]#jnp.log(arg_probs[arg_idx])\n",
    "    return log_prob, (arg_idx, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "german-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def episode_loss(context_params, tactic_params, term_params, arg_params, apply_context, apply_tac, apply_term, apply_arg, rng_key, env, encoded_fact_pool, candidate_args):\n",
    "    log_list = []\n",
    "    discounted_reward_list = []\n",
    "    trace = []\n",
    "    gamma = 0.99\n",
    "    for i in range(50):\n",
    "        _, rng_key = jax.random.split(rng_key)\n",
    "        \n",
    "        #print (\"Proof step {} of 50\\n\".format(i+1))\n",
    "        \n",
    "        try:\n",
    "            jax_reps, context_set, fringe_sizes = gather_encoded_content_(env.history, batch_encoder_)\n",
    "            #convert to jax\n",
    "        except:\n",
    "            print (\"Encoder error\")\n",
    "            if len(log_list) > 0:\n",
    "                return sum([i[0] * i[1] for i in zip(log_list, discounted_reward_list)])\n",
    "            else:\n",
    "                return 0\n",
    "            \n",
    "        jax_reps = jnp.stack([jnp.array(jax_reps[i][0].cpu()) for i in range(len(jax_reps))])\n",
    "        logs, reward, action = run_iter(context_params, tactic_params, term_params, arg_params, apply_context, apply_tac, apply_term, apply_arg, jax_reps, context_set, fringe_sizes, rng_key, env, encoded_fact_pool, candidate_args)\n",
    "\n",
    "        log_list.append(logs)\n",
    "        discounted_reward_list.append(reward * (gamma ** i))\n",
    "        \n",
    "        trace.append((env.history, action))\n",
    "\n",
    "                \n",
    "        #if goal proven\n",
    "        if reward == 5:\n",
    "            print (\"Goal proved in {} steps\".format(i+1))\n",
    "            return sum([i[0] * i[1] for i in zip(log_list, discounted_reward_list)]), trace\n",
    "        \n",
    "        #timeout\n",
    "        if i == 49:\n",
    "            discounted_reward_list[-1] = -5.\n",
    "            \n",
    "    loss = sum([i[0] * i[1] for i in zip(log_list, discounted_reward_list)])\n",
    "    \n",
    "    return loss, trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "powerful-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iter(context_params, tactic_params, term_params, arg_params, context_net, tactic_net, term_net, arg_net, jax_reps, context_set, fringe_sizes, rng_key, env, encoded_fact_pool, candidate_args):\n",
    "    \n",
    "    log_context, (fringe_idx, contexts_by_fringe) = sample_fringe(context_params, context_net, rng_key, jax_reps, context_set, fringe_sizes)\n",
    "    \n",
    "    try:\n",
    "        target_context = contexts_by_fringe[fringe_idx][0]\n",
    "    except:\n",
    "        print (\"error {} {}\".format(contexts_by_fringe), fringe_idx)\n",
    "    target_goal = target_context[\"polished\"][\"goal\"]\n",
    "    target_representation = jax_reps[context_set.index(target_context)]\n",
    "    \n",
    "    log_tac, tac_idx = sample_tactic(tactic_params, tactic_net, rng_key, jnp.expand_dims(target_representation,0), len(tactic_pool))\n",
    "    \n",
    "    sampled_tac = tactic_pool[tac_idx]\n",
    "    arg_logs = []\n",
    "\n",
    "    tactic = sampled_tac\n",
    "    #for testing\n",
    "    \n",
    "    #sampled_tac = \"Induct_on\"\n",
    "\n",
    "    #if tactic requires no argument\n",
    "    if sampled_tac in no_arg_tactic:\n",
    "        full_tactic = sampled_tac #tactic_pool[tac]\n",
    "\n",
    "\n",
    "    #Induct_on case; use term policy to find which term to induct on \n",
    "    elif sampled_tac in term_tactic:\n",
    "\n",
    "        goal_tokens = target_goal.split()\n",
    "        term_tokens = [[t] for t in set(goal_tokens) if t[0] == \"V\"]\n",
    "        #add conditional if tokens is empty \n",
    "\n",
    "        #now want encodings for terms from AE\n",
    "\n",
    "        term_reps = []\n",
    "\n",
    "        for term in term_tokens:\n",
    "            term_rep, _ = batch_encoder_.encode([term])\n",
    "            #output is bidirectional so concat vectors\n",
    "            term_reps.append(torch.cat(term_rep.split(1), dim=2).squeeze(0))\n",
    "        \n",
    "        #no terms in expression, only contains literals (e.g. induct_on `0`)\n",
    "        if len(term_reps) == 0:\n",
    "            print (\"No variables to induct on for goal {}\".format(target_goal))\n",
    "            #return negative loss for now (positive overall as negative of log prob is positive)\n",
    "            return 1., -1., \"Induct no vars\"\n",
    "            \n",
    "            \n",
    "        # convert to jax\n",
    "        term_reps = jnp.stack([jnp.array(term_reps[i][0].cpu()) for i in range(len(term_reps))])\n",
    "\n",
    "        # now want inputs to term_net to be target_representation (i.e. goal) concatenated with terms\n",
    "        # models the policies conditional dependence of the term given the goal\n",
    "\n",
    "        #stack goal representation for each token\n",
    "        goal_stack = jnp.concatenate([jnp.expand_dims(target_representation,0) for _ in term_tokens])\n",
    "\n",
    "        #concat with term encodings to give candidate matrix\n",
    "        candidates = jnp.concatenate([goal_stack, term_reps], 1)\n",
    "\n",
    "        log_term, term_idx = sample_term(term_params, term_net, rng_key, candidates)\n",
    "\n",
    "        sampled_term = term_tokens[term_idx]\n",
    "\n",
    "        tm = sampled_term[0][1:] # remove headers, e.g., \"V\" / \"C\" / ...\n",
    "    \n",
    "        arg_logs = [log_term]\n",
    "        \n",
    "        if tm:\n",
    "            tactic = \"Induct_on `{}`\".format(tm)\n",
    "        else:\n",
    "            # only to raise an error\n",
    "            tactic = \"Induct_on\"\n",
    "        \n",
    "    #argument tactic\n",
    "    else:\n",
    "        #stack goals to possible arguments to feed into FFN\n",
    "        goal_stack = jnp.concatenate([jnp.expand_dims(target_representation,0) for _ in encoded_fact_pool])\n",
    "        candidates = jnp.concatenate([encoded_fact_pool, goal_stack], 1)\n",
    "        \n",
    "        #initial state set as goal\n",
    "        hidden = jnp.expand_dims(target_representation,0)\n",
    "        init_state = hk.LSTMState(hidden,hidden)\n",
    "    \n",
    "        # run through first with tac_idx to initialise state with tactic as c_0\n",
    "        hidden, _ = arg_net(arg_params, rng_key, tac_idx, candidates, init_state, len(tactic_pool), 256)\n",
    "        \n",
    "        ARG_LEN = 5\n",
    "        arg_inds = []\n",
    "        arg_logs = []\n",
    "        input_ = tac_idx\n",
    "        for _ in range(ARG_LEN):\n",
    "            log_arg, (arg_idx, hidden) = sample_arg(arg_params, arg_net, rng_key, input_, candidates, hidden, len(tactic_pool), 256)\n",
    "            arg_logs.append(log_arg)\n",
    "            arg_inds.append(arg_idx)\n",
    "            input_ = jnp.expand_dims(encoded_fact_pool[arg_idx], 0)\n",
    "        \n",
    "        arg = [candidate_args[i] for i in arg_inds]\n",
    "\n",
    "        tactic = env.assemble_tactic(sampled_tac, arg)\n",
    "        \n",
    "    \n",
    "    \n",
    "    action = (int(fringe_idx), 0, tactic)\n",
    "    #print (\"Action {}:\\n\".format(action))\n",
    "    \n",
    "    try:\n",
    "        reward, done = env.step(action)\n",
    "\n",
    "    except:\n",
    "        print(\"Step exception raised.\")\n",
    "        # print(\"Fringe: {}\".format(env.history))\n",
    "        print(\"Handling: {}\".format(env.handling))\n",
    "        print(\"Using: {}\".format(env.using))\n",
    "        # try again\n",
    "        # counter = env.counter\n",
    "        frequency = env.frequency\n",
    "        env.close()\n",
    "        print(\"Aborting current game ...\")\n",
    "        print(\"Restarting environment ...\")\n",
    "        print(env.goal)\n",
    "        env = HolEnv(env.goal)\n",
    "        flag = False\n",
    "        return \n",
    "        \n",
    "    #print (\"Result: Reward {}\".format(reward))#, env.history[-1]))\n",
    "\n",
    "    \n",
    "    #negative as we want gradient ascent \n",
    "    \n",
    "    logs = (-log_tac - log_context  - sum(arg_logs))\n",
    "\n",
    "    return logs, reward, action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "published-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(goals):\n",
    "\n",
    "    rng_key = jax.random.PRNGKey(11)\n",
    "\n",
    "    init_context, apply_context = hk.transform(policy_networks._context_forward)\n",
    "    apply_context = jax.jit(apply_context)\n",
    "\n",
    "    init_tac, apply_tac = hk.transform(policy_networks._tac_forward)\n",
    "    apply_tac = partial(jax.jit, static_argnums=3)(apply_tac)\n",
    "\n",
    "    init_term, apply_term = hk.transform(policy_networks._term_no_tac_forward)\n",
    "    apply_term = jax.jit(apply_term)\n",
    "\n",
    "    init_arg, apply_arg = hk.transform(policy_networks._arg_forward)\n",
    "    apply_arg = partial(jax.jit, static_argnums=(5,6))(apply_arg)\n",
    "\n",
    "    #initialise these with e.g. random uniform, glorot, He etc. should exist outside function for action selection \n",
    "    context_params = init_context(rng_key, jax.random.normal(rng_key, (1,256)))\n",
    "\n",
    "    tactic_params = init_tac(rng_key, jax.random.normal(rng_key, (1,256)), len(tactic_pool))\n",
    "\n",
    "    #term_policy for now is only considering variables for induction, hence does not need any arguments \n",
    "    term_params = init_term(rng_key, jax.random.normal(rng_key, (1,512)))\n",
    "\n",
    "    hidden = jax.random.normal(rng_key, (1,256))\n",
    "\n",
    "    init_state = hk.LSTMState(hidden, hidden)\n",
    "\n",
    "    arg_params = init_arg(rng_key, jax.random.randint(rng_key, (), 0, len(tactic_pool)), jax.random.normal(rng_key, (1,512)), init_state, len(tactic_pool), 256)\n",
    "\n",
    "        \n",
    "    context_lr = 1e-4\n",
    "    tactic_lr = 1e-4\n",
    "    arg_lr = 1e-4\n",
    "    term_lr = 1e-4\n",
    "\n",
    "    context_optimiser = optax.rmsprop(context_lr)\n",
    "    tactic_optimiser = optax.rmsprop(tactic_lr)\n",
    "    arg_optimiser = optax.rmsprop(arg_lr)\n",
    "    term_optimiser = optax.rmsprop(term_lr)\n",
    "\n",
    "    opt_state_context = context_optimiser.init(context_params)\n",
    "    opt_state_tactic = tactic_optimiser.init(tactic_params)\n",
    "    opt_state_arg = arg_optimiser.init(arg_params)\n",
    "    opt_state_term = term_optimiser.init(term_params)\n",
    "    \n",
    "    proof_dict = {}\n",
    "    \n",
    "\n",
    "    for goal in goals:\n",
    "        g = goal[1]\n",
    "            \n",
    "        env = HolEnv(g)\n",
    "\n",
    "        theories = re.findall(r'C\\$(\\w+)\\$ ', goal[0])\n",
    "        theories = set(theories)\n",
    "        theories = list(theories)\n",
    "\n",
    "        allowed_theories = theories\n",
    "\n",
    "        goal_theory = g\n",
    "\n",
    "        #print (\"Target goal: {}\".format(g))\n",
    "        \n",
    "        try:\n",
    "            allowed_arguments_ids = []\n",
    "            candidate_args = []\n",
    "            goal_theory = g#database[polished_goal][0] # plain_database[goal][0]\n",
    "            for i,t in enumerate(database):\n",
    "                if database[t][0] in allowed_theories and (database[t][0] != goal_theory or int(database[t][2]) < int(database[polished_goal][2])):\n",
    "                    allowed_arguments_ids.append(i)\n",
    "                    candidate_args.append(t)\n",
    "\n",
    "            env.toggle_simpset(\"diminish\", goal_theory)\n",
    "            #print(\"Removed simpset of {}\".format(goal_theory))\n",
    "\n",
    "        except:\n",
    "            allowed_arguments_ids = []\n",
    "            candidate_args = []\n",
    "            for i,t in enumerate(database):\n",
    "                if database[t][0] in allowed_theories:\n",
    "                    allowed_arguments_ids.append(i)\n",
    "                    candidate_args.append(t)\n",
    "            #print(\"Theorem not found in database.\")\n",
    "\n",
    "        #print (\"Number of candidate facts to use: {}\".format(len(candidate_args)))\n",
    "\n",
    "        encoded_database = torch.load('encoded_include_probability.pt')\n",
    "\n",
    "        encoded_fact_pool = torch.index_select(encoded_database, 0, torch.tensor(allowed_arguments_ids))\n",
    "        \n",
    "        encoded_fact_pool = jnp.array(encoded_fact_pool)\n",
    "        \n",
    "        try:\n",
    "            gradients, trace = jax.grad(episode_loss, argnums=(0,1,2,3), has_aux=True)(context_params, tactic_params, term_params, arg_params, apply_context, apply_tac, apply_term, apply_arg,  rng_key, env, encoded_fact_pool, candidate_args)\n",
    "        except:\n",
    "            print (\"error\")\n",
    "            continue\n",
    "        \n",
    "        proof_dict[goal] = trace\n",
    "            \n",
    "\n",
    "        #update parameters\n",
    "        context_updates, opt_state_context = context_optimiser.update(gradients[0], opt_state_context)\n",
    "        context_params = optax.apply_updates(context_params, context_updates)\n",
    "\n",
    "        tactic_updates, opt_state_tactic = tactic_optimiser.update(gradients[1], opt_state_tactic)\n",
    "        tactic_params = optax.apply_updates(tactic_params, tactic_updates)\n",
    "\n",
    "        term_updates, opt_state_term = term_optimiser.update(gradients[2], opt_state_term)\n",
    "        term_params = optax.apply_updates(term_params, term_updates)\n",
    "\n",
    "        arg_updates, opt_state_arg = arg_optimiser.update(gradients[3], opt_state_arg)\n",
    "        arg_params = optax.apply_updates(arg_params, arg_updates)\n",
    "\n",
    "        #save trace \n",
    "        save(proof_dict, path_dir + \"/trace\")\n",
    "        \n",
    "        #save params after each proof attempt\n",
    "        save(context_params, path_dir + \"/context_params\")\n",
    "        save(opt_state_context, path_dir+\"/context_state\")\n",
    "        save(tactic_params, path_dir+\"/tactic_params\")\n",
    "        save(opt_state_tactic, path_dir+\"/tactic_state\")\n",
    "        save(term_params, path_dir+\"/term_params\")\n",
    "        save(opt_state_term, path_dir+\"/term_state\")\n",
    "        save(arg_params, path_dir+\"/arg_params\")\n",
    "        save(opt_state_arg, path_dir+\"/arg_state\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "occupational-dancing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@ C$bool$ ! | Vt @ @ C$min$ ==> C$bool$ F Vt', '∀(t :bool). F ⇒ t'),\n",
       " ('@ C$bool$ ! | Vb @ C$bool$ ! | Vt @ @ C$min$ = @ @ @ C$bool$ COND Vb Vt Vt Vt',\n",
       "  '∀(b :bool) (t :α). (if b then t else t) = t'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | Va @ @ C$min$ = @ C$bool$ ? | Vx @ @ C$bool$ /\\\\ @ @ C$min$ = Vx Va @ VP Vx @ VP Va',\n",
       "  '∀(P :α -> bool) (a :α). (∃(x :α). x = a ∧ P x) ⇔ P a'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | Va @ @ C$min$ = @ C$bool$ ? | Vx @ @ C$bool$ /\\\\ @ @ C$min$ = Va Vx @ VP Vx @ VP Va',\n",
       "  '∀(P :α -> bool) (a :α). (∃(x :α). a = x ∧ P x) ⇔ P a'),\n",
       " ('@ C$bool$ ! | Vf @ C$bool$ ! | Vv @ @ C$min$ = @ C$bool$ ! | Vx @ @ C$min$ ==> @ @ C$min$ = Vx Vv @ Vf Vx @ Vf Vv',\n",
       "  '∀(f :α -> bool) (v :α). (∀(x :α). x = v ⇒ f x) ⇔ f v'),\n",
       " ('@ C$bool$ ! | Vf @ C$bool$ ! | Vv @ @ C$min$ = @ C$bool$ ! | Vx @ @ C$min$ ==> @ @ C$min$ = Vv Vx @ Vf Vx @ Vf Vv',\n",
       "  '∀(f :α -> bool) (v :α). (∀(x :α). v = x ⇒ f x) ⇔ f v'),\n",
       " ('@ @ C$min$ = @ C$bool$ ?! | Vx Vt @ @ C$bool$ /\\\\ Vt @ C$bool$ ! | Vx @ C$bool$ ! | Vy @ @ C$min$ = Vx Vy',\n",
       "  '(∃!(x :α). (t :bool)) ⇔ t ∧ ∀(x :α) (y :α). x = y'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$min$ ==> @ C$bool$ ?! | Vx @ @ C$bool$ \\\\/ @ VP Vx @ VQ Vx @ @ C$bool$ \\\\/ @ C$bool$ ?! | Vx @ VP Vx @ C$bool$ ?! | Vx @ VQ Vx',\n",
       "  '∀(P :α -> bool) (Q :α -> bool). (∃!(x :α). P x ∨ Q x) ⇒ (∃!(x :α). P x) ∨ ∃!(x :α). Q x'),\n",
       " (\"@ C$bool$ ! | VP @ C$bool$ ! | Vrep @ @ C$min$ = @ @ C$bool$ TYPE_DEFINITION VP Vrep @ @ C$bool$ /\\\\ @ C$bool$ ! | Vx' @ C$bool$ ! | Vx'' @ @ C$min$ ==> @ @ C$min$ = @ Vrep Vx' @ Vrep Vx'' @ @ C$min$ = Vx' Vx'' @ C$bool$ ! | Vx @ @ C$min$ = @ VP Vx @ C$bool$ ? | Vx' @ @ C$min$ = Vx @ Vrep Vx'\",\n",
       "  \"∀(P :α -> bool) (rep :β -> α). TYPE_DEFINITION P rep ⇔ (∀(x' :β) (x'' :β). rep x' = rep x'' ⇒ x' = x'') ∧ ∀(x :α). P x ⇔ ∃(x' :β). x = rep x'\"),\n",
       " ('C$bool$ T', 'T'),\n",
       " ('@ C$bool$ ! | VP @ @ C$min$ = @ C$bool$ ! | Vx @ C$bool$ ! | Vy @ @ VP Vx Vy @ C$bool$ ! | Vy @ C$bool$ ! | Vx @ @ VP Vx Vy',\n",
       "  '∀(P :α -> β -> bool). (∀(x :α) (y :β). P x y) ⇔ ∀(y :β) (x :α). P x y'),\n",
       " ('@ C$bool$ ! | VP @ @ C$min$ = @ C$bool$ ? | Vx @ C$bool$ ? | Vy @ @ VP Vx Vy @ C$bool$ ? | Vy @ C$bool$ ? | Vx @ @ VP Vx Vy',\n",
       "  '∀(P :α -> β -> bool). (∃(x :α) (y :β). P x y) ⇔ ∃(y :β) (x :α). P x y'),\n",
       " ('@ C$bool$ ! | VP @ @ C$min$ = @ C$bool$ ! | Vx @ C$bool$ ? | Vy @ @ VP Vx Vy @ C$bool$ ? | Vf @ C$bool$ ! | Vx @ @ VP Vx @ Vf Vx',\n",
       "  '∀(P :α -> β -> bool). (∀(x :α). ∃(y :β). P x y) ⇔ ∃(f :α -> β). ∀(x :α). P x (f x)'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | Vx @ @ C$min$ ==> @ C$bool$ ! | Vy @ @ C$min$ = @ VP Vy @ @ C$min$ = Vy Vx @ @ C$min$ = @ C$min$ @ VP Vx',\n",
       "  '∀(P :α -> bool) (x :α). (∀(y :α). P y ⇔ y = x) ⇒ $@ P = x'),\n",
       " ('@ C$bool$ ! | VP @ @ C$min$ = @ VP @ C$min$ @ | Vx @ VP Vx @ C$bool$ ? | Vx @ VP Vx',\n",
       "  '∀(P :α -> bool). P (@(x :α). P x) ⇔ ∃(x :α). P x'),\n",
       " ('@ C$bool$ ! | Vx @ @ C$min$ = @ C$min$ @ | Vy @ @ C$min$ = Vx Vy Vx',\n",
       "  '∀(x :α). (@(y :α). x = y) = x'),\n",
       " ('@ C$bool$ ! | Vx @ @ C$min$ = @ C$min$ @ | Vy @ @ C$min$ = Vy Vx Vx',\n",
       "  '∀(x :α). (@(y :α). y = x) = x'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$min$ ==> @ @ C$bool$ /\\\\ @ C$bool$ ? | Vx @ VP Vx @ C$bool$ ! | Vx @ @ C$min$ ==> @ VP Vx @ VQ Vx @ VQ @ C$min$ @ VP',\n",
       "  '∀(P :α -> bool) (Q :α -> bool). (∃(x :α). P x) ∧ (∀(x :α). P x ⇒ Q x) ⇒ Q ($@ P)'),\n",
       " ('@ C$bool$ ! | VA @ C$bool$ ! | VB @ C$bool$ ! | VC @ @ C$min$ = @ @ C$bool$ \\\\/ @ @ C$bool$ /\\\\ VB VC VA @ @ C$bool$ /\\\\ @ @ C$bool$ \\\\/ VB VA @ @ C$bool$ \\\\/ VC VA',\n",
       "  '∀(A :bool) (B :bool) (C :bool). B ∧ C ∨ A ⇔ (B ∨ A) ∧ (C ∨ A)'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$min$ = @ @ C$bool$ \\\\/ VP @ C$bool$ ? | Vx @ VQ Vx @ C$bool$ ? | Vx @ @ C$bool$ \\\\/ VP @ VQ Vx',\n",
       "  '∀(P :bool) (Q :α -> bool). P ∨ (∃(x :α). Q x) ⇔ ∃(x :α). P ∨ Q x'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$min$ = @ C$bool$ ! | Vx @ @ C$bool$ \\\\/ VP @ VQ Vx @ @ C$bool$ \\\\/ VP @ C$bool$ ! | Vx @ VQ Vx',\n",
       "  '∀(P :bool) (Q :α -> bool). (∀(x :α). P ∨ Q x) ⇔ P ∨ ∀(x :α). Q x'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$min$ = @ C$bool$ ! | Vx @ @ C$min$ ==> VP @ VQ Vx @ @ C$min$ ==> VP @ C$bool$ ! | Vx @ VQ Vx',\n",
       "  '∀(P :bool) (Q :α -> bool). (∀(x :α). P ⇒ Q x) ⇔ P ⇒ ∀(x :α). Q x'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$min$ = @ C$bool$ ? | Vx @ @ C$min$ ==> VP @ VQ Vx @ @ C$min$ ==> VP @ C$bool$ ? | Vx @ VQ Vx',\n",
       "  '∀(P :bool) (Q :α -> bool). (∃(x :α). P ⇒ Q x) ⇔ P ⇒ ∃(x :α). Q x'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$min$ = @ C$bool$ ? | Vx @ @ C$bool$ /\\\\ VP @ VQ Vx @ @ C$bool$ /\\\\ VP @ C$bool$ ? | Vx @ VQ Vx',\n",
       "  '∀(P :bool) (Q :α -> bool). (∃(x :α). P ∧ Q x) ⇔ P ∧ ∃(x :α). Q x'),\n",
       " ('@ C$bool$ ! | VA @ C$bool$ ! | VB @ C$bool$ ! | VC @ @ C$min$ = @ @ C$bool$ /\\\\ @ @ C$bool$ \\\\/ VB VC VA @ @ C$bool$ \\\\/ @ @ C$bool$ /\\\\ VB VA @ @ C$bool$ /\\\\ VC VA',\n",
       "  '∀(A :bool) (B :bool) (C :bool). (B ∨ C) ∧ A ⇔ B ∧ A ∨ C ∧ A'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$min$ = @ @ C$bool$ /\\\\ VP @ C$bool$ ! | Vx @ VQ Vx @ C$bool$ ! | Vx @ @ C$bool$ /\\\\ VP @ VQ Vx',\n",
       "  '∀(P :bool) (Q :α -> bool). P ∧ (∀(x :α). Q x) ⇔ ∀(x :α). P ∧ Q x'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | Vf @ @ C$min$ = @ @ C$bool$ RES_SELECT VP Vf @ C$min$ @ | Vx @ @ C$bool$ /\\\\ @ @ C$bool$ IN Vx VP @ Vf Vx',\n",
       "  '∀(P :α -> bool) (f :α -> bool). RES_SELECT P f = @(x :α). x ∈ P ∧ f x'),\n",
       " ('@ @ C$min$ = @ @ C$bool$ RES_FORALL VP | Vx C$bool$ T C$bool$ T',\n",
       "  '(∀(x :α)::(P :α -> bool). T) ⇔ T'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | Vf @ @ C$min$ = @ @ C$bool$ RES_FORALL VP Vf @ C$bool$ ! | Vx @ @ C$min$ ==> @ @ C$bool$ IN Vx VP @ Vf Vx',\n",
       "  '∀(P :α -> bool) (f :α -> bool). RES_FORALL P f ⇔ ∀(x :α). x ∈ P ⇒ f x'),\n",
       " ('@ @ C$min$ ==> @ @ C$min$ = VP VQ @ @ C$min$ ==> @ C$bool$ ! | Vx @ @ C$min$ ==> @ @ C$bool$ IN Vx VQ @ @ C$min$ = @ Vf Vx @ Vg Vx @ @ C$min$ = @ @ C$bool$ RES_FORALL VP Vf @ @ C$bool$ RES_FORALL VQ Vg',\n",
       "  '(P :α -> bool) = (Q :α -> bool) ⇒ (∀(x :α). x ∈ Q ⇒ ((f :α -> bool) x ⇔ (g :α -> bool) x)) ⇒ (RES_FORALL P f ⇔ RES_FORALL Q g)'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | Vf @ @ C$min$ = @ @ C$bool$ RES_EXISTS_UNIQUE VP Vf @ @ C$bool$ /\\\\ @ @ C$bool$ RES_EXISTS VP | Vx @ Vf Vx @ @ C$bool$ RES_FORALL VP | Vx @ @ C$bool$ RES_FORALL VP | Vy @ @ C$min$ ==> @ @ C$bool$ /\\\\ @ Vf Vx @ Vf Vy @ @ C$min$ = Vx Vy',\n",
       "  '∀(P :α -> bool) (f :α -> bool). RES_EXISTS_UNIQUE P f ⇔ (∃(x :α)::P. f x) ∧ ∀(x :α) (y :α)::P. f x ∧ f y ⇒ x = y'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | Vf @ @ C$min$ = @ @ C$bool$ RES_EXISTS VP Vf @ C$bool$ ? | Vx @ @ C$bool$ /\\\\ @ @ C$bool$ IN Vx VP @ Vf Vx',\n",
       "  '∀(P :α -> bool) (f :α -> bool). RES_EXISTS P f ⇔ ∃(x :α). x ∈ P ∧ f x'),\n",
       " ('@ @ C$min$ = @ @ C$bool$ RES_EXISTS VP | Vx C$bool$ F C$bool$ F',\n",
       "  '(∃(x :α)::(P :α -> bool). F) ⇔ F'),\n",
       " ('@ @ C$min$ ==> @ @ C$min$ = VP VQ @ @ C$min$ ==> @ C$bool$ ! | Vx @ @ C$min$ ==> @ @ C$bool$ IN Vx VQ @ @ C$min$ = @ Vf Vx @ Vg Vx @ @ C$min$ = @ @ C$bool$ RES_EXISTS VP Vf @ @ C$bool$ RES_EXISTS VQ Vg',\n",
       "  '(P :α -> bool) = (Q :α -> bool) ⇒ (∀(x :α). x ∈ Q ⇒ ((f :α -> bool) x ⇔ (g :α -> bool) x)) ⇒ (RES_EXISTS P f ⇔ RES_EXISTS Q g)'),\n",
       " ('@ C$bool$ ! | Vx @ @ C$min$ = @ @ C$min$ = Vx Vx C$bool$ T',\n",
       "  '∀(x :α). x = x ⇔ T'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ C$min$ ==> VQ @ C$bool$ ! | Vx @ VP Vx @ C$bool$ ! | Vx @ @ C$min$ ==> VQ @ VP Vx @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ C$bool$ /\\\\ @ C$bool$ ! | Vx @ VP Vx VQ @ C$bool$ ! | Vx @ @ C$bool$ /\\\\ @ VP Vx VQ @ @ C$min$ = @ @ C$bool$ /\\\\ VQ @ C$bool$ ! | Vx @ VP Vx @ C$bool$ ! | Vx @ @ C$bool$ /\\\\ VQ @ VP Vx',\n",
       "  '∀(P :α -> bool) (Q :bool). (Q ⇒ (∀(x :α). P x) ⇔ ∀(x :α). Q ⇒ P x) ∧ ((∀(x :α). P x) ∧ Q ⇔ ∀(x :α). P x ∧ Q) ∧ (Q ∧ (∀(x :α). P x) ⇔ ∀(x :α). Q ∧ P x)'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ C$min$ ==> @ C$bool$ ? | Vx @ VP Vx VQ @ C$bool$ ! | Vx @ @ C$min$ ==> @ VP Vx VQ @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ C$bool$ /\\\\ @ C$bool$ ? | Vx @ VP Vx VQ @ C$bool$ ? | Vx @ @ C$bool$ /\\\\ @ VP Vx VQ @ @ C$min$ = @ @ C$bool$ /\\\\ VQ @ C$bool$ ? | Vx @ VP Vx @ C$bool$ ? | Vx @ @ C$bool$ /\\\\ VQ @ VP Vx',\n",
       "  '∀(P :α -> bool) (Q :bool). ((∃(x :α). P x) ⇒ Q ⇔ ∀(x :α). P x ⇒ Q) ∧ ((∃(x :α). P x) ∧ Q ⇔ ∃(x :α). P x ∧ Q) ∧ (Q ∧ (∃(x :α). P x) ⇔ ∃(x :α). Q ∧ P x)'),\n",
       " ('@ @ C$min$ ==> @ @ C$min$ ==> @ @ C$min$ ==> VP VQ VP VP',\n",
       "  '(((P :bool) ⇒ (Q :bool)) ⇒ P) ⇒ P'),\n",
       " ('@ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ @ C$min$ ==> Vt2 @ @ C$bool$ \\\\/ Vt1 Vt2',\n",
       "  '∀(t1 :bool) (t2 :bool). t2 ⇒ t1 ∨ t2'),\n",
       " ('@ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ @ C$min$ ==> Vt1 @ @ C$bool$ \\\\/ Vt1 Vt2',\n",
       "  '∀(t1 :bool) (t2 :bool). t1 ⇒ t1 ∨ t2'),\n",
       " ('@ C$bool$ ! | VA @ C$bool$ ! | VB @ @ C$min$ = @ @ C$min$ = VA @ @ C$bool$ \\\\/ VB VA @ @ C$min$ ==> VB VA',\n",
       "  '∀(A :bool) (B :bool). (A ⇔ B ∨ A) ⇔ B ⇒ A'),\n",
       " ('@ C$bool$ ! | Vt @ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ @ C$min$ ==> @ @ C$bool$ \\\\/ Vt1 Vt2 @ @ C$min$ ==> @ @ C$min$ ==> Vt1 Vt @ @ C$min$ ==> @ @ C$min$ ==> Vt2 Vt Vt',\n",
       "  '∀(t :bool) (t1 :bool) (t2 :bool). t1 ∨ t2 ⇒ (t1 ⇒ t) ⇒ (t2 ⇒ t) ⇒ t'),\n",
       " (\"@ C$bool$ ! | VP @ C$bool$ ! | VP' @ C$bool$ ! | VQ @ C$bool$ ! | VQ' @ @ C$min$ ==> @ @ C$bool$ /\\\\ @ @ C$min$ ==> @ C$bool$ ~ VQ @ @ C$min$ = VP VP' @ @ C$min$ ==> @ C$bool$ ~ VP' @ @ C$min$ = VQ VQ' @ @ C$min$ = @ @ C$bool$ \\\\/ VP VQ @ @ C$bool$ \\\\/ VP' VQ'\",\n",
       "  \"∀(P :bool) (P' :bool) (Q :bool) (Q' :bool). (¬Q ⇒ (P ⇔ P')) ∧ (¬P' ⇒ (Q ⇔ Q')) ⇒ (P ∨ Q ⇔ P' ∨ Q')\"),\n",
       " ('@ C$bool$ ! | Vt @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ C$bool$ \\\\/ C$bool$ T Vt C$bool$ T @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ C$bool$ \\\\/ Vt C$bool$ T C$bool$ T @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ C$bool$ \\\\/ C$bool$ F Vt Vt @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ C$bool$ \\\\/ Vt C$bool$ F Vt @ @ C$min$ = @ @ C$bool$ \\\\/ Vt Vt Vt',\n",
       "  '∀(t :bool). (T ∨ t ⇔ T) ∧ (t ∨ T ⇔ T) ∧ (F ∨ t ⇔ t) ∧ (t ∨ F ⇔ t) ∧ (t ∨ t ⇔ t)'),\n",
       " ('@ C$bool$ ! | Vf @ @ C$min$ = @ C$bool$ ONTO Vf @ C$bool$ ! | Vy @ C$bool$ ? | Vx @ @ C$min$ = Vy @ Vf Vx',\n",
       "  '∀(f :α -> β). ONTO f ⇔ ∀(y :β). ∃(x :α). y = f x'),\n",
       " ('@ C$bool$ ! | Vf @ @ C$min$ = @ C$bool$ ONE_ONE Vf @ C$bool$ ! | Vx1 @ C$bool$ ! | Vx2 @ @ C$min$ ==> @ @ C$min$ = @ Vf Vx1 @ Vf Vx2 @ @ C$min$ = Vx1 Vx2',\n",
       "  '∀(f :α -> β). ONE_ONE f ⇔ ∀(x1 :α) (x2 :α). f x1 = f x2 ⇒ x1 = x2'),\n",
       " ('@ C$bool$ ! | VA @ C$bool$ ! | VB @ @ C$min$ = @ C$bool$ ~ @ @ C$min$ ==> VA VB @ @ C$bool$ /\\\\ VA @ C$bool$ ~ VB',\n",
       "  '∀(A :bool) (B :bool). ¬(A ⇒ B) ⇔ A ∧ ¬B'),\n",
       " ('@ C$bool$ ! | VP @ @ C$min$ = @ C$bool$ ~ @ C$bool$ ! | Vx @ VP Vx @ C$bool$ ? | Vx @ C$bool$ ~ @ VP Vx',\n",
       "  '∀(P :α -> bool). ¬(∀(x :α). P x) ⇔ ∃(x :α). ¬P x'),\n",
       " ('@ C$bool$ ! | Vt @ @ C$min$ ==> @ C$bool$ ~ Vt @ @ C$min$ = Vt C$bool$ F',\n",
       "  '∀(t :bool). ¬t ⇒ (t ⇔ F)'),\n",
       " ('@ C$bool$ ! | VP @ @ C$min$ = @ C$bool$ ~ @ C$bool$ ? | Vx @ VP Vx @ C$bool$ ! | Vx @ C$bool$ ~ @ VP Vx',\n",
       "  '∀(P :α -> bool). ¬(∃(x :α). P x) ⇔ ∀(x :α). ¬P x'),\n",
       " ('@ @ C$bool$ /\\\\ @ C$bool$ ! | Vt @ @ C$min$ = @ C$bool$ ~ @ C$bool$ ~ Vt Vt @ @ C$bool$ /\\\\ @ @ C$min$ = @ C$bool$ ~ C$bool$ T C$bool$ F @ @ C$min$ = @ C$bool$ ~ C$bool$ F C$bool$ T',\n",
       "  '(∀(t :bool). ¬¬t ⇔ t) ∧ (¬T ⇔ F) ∧ (¬F ⇔ T)'),\n",
       " ('@ C$bool$ ~ @ @ C$bool$ /\\\\ Vt @ C$bool$ ~ Vt', '¬((t :bool) ∧ ¬t)'),\n",
       " ('@ @ C$min$ ==> @ @ C$bool$ /\\\\ @ @ C$min$ ==> Vx Vy @ @ C$min$ ==> Vz Vw @ @ C$min$ ==> @ @ C$bool$ \\\\/ Vx Vz @ @ C$bool$ \\\\/ Vy Vw',\n",
       "  '((x :bool) ⇒ (y :bool)) ∧ ((z :bool) ⇒ (w :bool)) ⇒ x ∨ z ⇒ y ∨ w'),\n",
       " ('@ @ C$min$ = @ @ C$min$ ==> Vy Vx @ @ C$min$ ==> @ C$bool$ ~ Vx @ C$bool$ ~ Vy',\n",
       "  '(y :bool) ⇒ (x :bool) ⇔ ¬x ⇒ ¬y'),\n",
       " ('@ @ C$min$ ==> @ @ C$min$ ==> Vy Vx @ @ C$min$ ==> @ C$bool$ ~ Vx @ C$bool$ ~ Vy',\n",
       "  '((y :bool) ⇒ (x :bool)) ⇒ ¬x ⇒ ¬y'),\n",
       " ('@ @ C$min$ ==> @ @ C$bool$ /\\\\ @ @ C$min$ ==> Vy Vx @ @ C$min$ ==> Vz Vw @ @ C$min$ ==> @ @ C$min$ ==> Vx Vz @ @ C$min$ ==> Vy Vw',\n",
       "  '((y :bool) ⇒ (x :bool)) ∧ ((z :bool) ⇒ (w :bool)) ⇒ (x ⇒ z) ⇒ y ⇒ w'),\n",
       " ('@ @ C$min$ ==> @ C$bool$ ! | Vx @ @ C$min$ ==> @ VP Vx @ VQ Vx @ @ C$min$ ==> @ C$bool$ ? | Vx @ VP Vx @ C$bool$ ? | Vx @ VQ Vx',\n",
       "  '(∀(x :α). (P :α -> bool) x ⇒ (Q :α -> bool) x) ⇒ (∃(x :α). P x) ⇒ ∃(x :α). Q x'),\n",
       " ('@ @ C$min$ ==> @ @ C$min$ ==> Vx Vy @ @ C$min$ ==> @ @ C$min$ ==> Vz Vw @ @ C$min$ ==> @ @ @ C$bool$ COND Vb Vx Vz @ @ @ C$bool$ COND Vb Vy Vw',\n",
       "  '((x :bool) ⇒ (y :bool)) ⇒ ((z :bool) ⇒ (w :bool)) ⇒ (if (b :bool) then x else z) ⇒ if b then y else w'),\n",
       " ('@ @ C$min$ ==> @ @ C$bool$ /\\\\ @ @ C$min$ ==> Vx Vy @ @ C$min$ ==> Vz Vw @ @ C$min$ ==> @ @ C$bool$ /\\\\ Vx Vz @ @ C$bool$ /\\\\ Vy Vw',\n",
       "  '((x :bool) ⇒ (y :bool)) ∧ ((z :bool) ⇒ (w :bool)) ⇒ x ∧ z ⇒ y ∧ w'),\n",
       " ('@ @ C$min$ ==> @ C$bool$ ! | Vx @ @ C$min$ ==> @ VP Vx @ VQ Vx @ @ C$min$ ==> @ C$bool$ ! | Vx @ VP Vx @ C$bool$ ! | Vx @ VQ Vx',\n",
       "  '(∀(x :α). (P :α -> bool) x ⇒ (Q :α -> bool) x) ⇒ (∀(x :α). P x) ⇒ ∀(x :α). Q x'),\n",
       " ('@ C$bool$ ! | Vf @ C$bool$ ! | Vx @ @ C$min$ = @ @ C$bool$ literal_case Vf Vx @ Vf Vx',\n",
       "  '∀(f :α -> β) (x :α). (literal_case f x :β) = f x'),\n",
       " ('@ @ C$min$ = @ @ @ C$bool$ literal_case | Vx @ VN Vx VM Vb @ @ C$bool$ literal_case | Vx @ @ VN Vx Vb VM',\n",
       "  '((case (M :α) of x => (N :α -> β -> γ) x) (b :β) :γ) = case M of x => N x b'),\n",
       " ('@ @ C$min$ = @ VP @ @ C$bool$ literal_case | Vx @ VN Vx VM @ @ C$bool$ literal_case | Vx @ VP @ VN Vx VM',\n",
       "  '(P :β -> γ) (case (M :α) of x => (N :α -> β) x) = case M of x => P (N x)'),\n",
       " ('@ @ C$min$ = @ @ C$bool$ literal_case | Vx @ @ @ C$bool$ COND @ @ C$min$ = Vx Va Vt Vu Va Vt',\n",
       "  '(case (a :α) of a => (t :β) | x => (u :β)) = t'),\n",
       " ('@ C$bool$ ! | Vf @ C$bool$ ! | Vg @ C$bool$ ! | VM @ C$bool$ ! | VN @ @ C$min$ ==> @ @ C$bool$ /\\\\ @ @ C$min$ = VM VN @ C$bool$ ! | Vx @ @ C$min$ ==> @ @ C$min$ = Vx VN @ @ C$min$ = @ Vf Vx @ Vg Vx @ @ C$min$ = @ @ C$bool$ literal_case Vf VM @ @ C$bool$ literal_case Vg VN',\n",
       "  '∀(f :α -> β) (g :α -> β) (M :α) (N :α). M = N ∧ (∀(x :α). x = N ⇒ f x = g x) ⇒ (literal_case f M :β) = (literal_case g N :β)'),\n",
       " ('@ C$bool$ ! | Vf @ C$bool$ ! | Vx @ @ C$min$ = @ @ C$bool$ LET Vf Vx @ Vf Vx',\n",
       "  '∀(f :α -> β) (x :α). LET f x = f x'),\n",
       " ('@ @ C$min$ = @ @ @ C$bool$ LET | Vx @ VN Vx VM Vb @ @ C$bool$ LET | Vx @ @ VN Vx Vb VM',\n",
       "  '(let (x :α) = (M :α) in (N :α -> β -> γ) x) (b :β) = (let (x :α) = M in N x b)'),\n",
       " ('@ @ C$min$ = @ VP @ @ C$bool$ LET | Vx @ VN Vx VM @ @ C$bool$ LET | Vx @ VP @ VN Vx VM',\n",
       "  '(P :β -> bool) (let (x :α) = (M :α) in (N :α -> β) x) ⇔ (let (x :α) = M in P (N x))'),\n",
       " ('@ C$bool$ ! | Vf @ C$bool$ ! | Vg @ C$bool$ ! | VM @ C$bool$ ! | VN @ @ C$min$ ==> @ @ C$bool$ /\\\\ @ @ C$min$ = VM VN @ C$bool$ ! | Vx @ @ C$min$ ==> @ @ C$min$ = Vx VN @ @ C$min$ = @ Vf Vx @ Vg Vx @ @ C$min$ = @ @ C$bool$ LET Vf VM @ @ C$bool$ LET Vg VN',\n",
       "  '∀(f :α -> β) (g :α -> β) (M :α) (N :α). M = N ∧ (∀(x :α). x = N ⇒ f x = g x) ⇒ LET f M = LET g N'),\n",
       " ('@ C$bool$ ! | VA @ C$bool$ ! | VB @ C$bool$ ! | VC @ @ C$min$ = @ @ C$bool$ \\\\/ VA @ @ C$bool$ /\\\\ VB VC @ @ C$bool$ /\\\\ @ @ C$bool$ \\\\/ VA VB @ @ C$bool$ \\\\/ VA VC',\n",
       "  '∀(A :bool) (B :bool) (C :bool). A ∨ B ∧ C ⇔ (A ∨ B) ∧ (A ∨ C)'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$min$ = @ @ C$bool$ \\\\/ @ C$bool$ ? | Vx @ VP Vx VQ @ C$bool$ ? | Vx @ @ C$bool$ \\\\/ @ VP Vx VQ',\n",
       "  '∀(P :α -> bool) (Q :bool). (∃(x :α). P x) ∨ Q ⇔ ∃(x :α). P x ∨ Q'),\n",
       " (\"@ C$bool$ ! | VP @ C$bool$ ! | VP' @ C$bool$ ! | VQ @ C$bool$ ! | VQ' @ @ C$min$ ==> @ @ C$bool$ /\\\\ @ @ C$min$ = VP VP' @ @ C$min$ ==> @ C$bool$ ~ VP' @ @ C$min$ = VQ VQ' @ @ C$min$ = @ @ C$bool$ \\\\/ VP VQ @ @ C$bool$ \\\\/ VP' VQ'\",\n",
       "  \"∀(P :bool) (P' :bool) (Q :bool) (Q' :bool). (P ⇔ P') ∧ (¬P' ⇒ (Q ⇔ Q')) ⇒ (P ∨ Q ⇔ P' ∨ Q')\"),\n",
       " ('@ C$bool$ ! | VQ @ C$bool$ ! | VP @ @ C$min$ = @ C$bool$ ! | Vx @ @ C$bool$ \\\\/ @ VP Vx VQ @ @ C$bool$ \\\\/ @ C$bool$ ! | Vx @ VP Vx VQ',\n",
       "  '∀(Q :bool) (P :α -> bool). (∀(x :α). P x ∨ Q) ⇔ (∀(x :α). P x) ∨ Q'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$min$ = @ C$bool$ ! | Vx @ @ C$min$ ==> @ VP Vx VQ @ @ C$min$ ==> @ C$bool$ ? | Vx @ VP Vx VQ',\n",
       "  '∀(P :α -> bool) (Q :bool). (∀(x :α). P x ⇒ Q) ⇔ (∃(x :α). P x) ⇒ Q'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$min$ = @ C$bool$ ? | Vx @ @ C$min$ ==> @ VP Vx VQ @ @ C$min$ ==> @ C$bool$ ! | Vx @ VP Vx VQ',\n",
       "  '∀(P :α -> bool) (Q :bool). (∃(x :α). P x ⇒ Q) ⇔ (∀(x :α). P x) ⇒ Q'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$min$ = @ C$bool$ ? | Vx @ @ C$bool$ /\\\\ @ VP Vx VQ @ @ C$bool$ /\\\\ @ C$bool$ ? | Vx @ VP Vx VQ',\n",
       "  '∀(P :α -> bool) (Q :bool). (∃(x :α). P x ∧ Q) ⇔ (∃(x :α). P x) ∧ Q'),\n",
       " ('@ C$bool$ ! | VA @ C$bool$ ! | VB @ C$bool$ ! | VC @ @ C$min$ = @ @ C$bool$ /\\\\ VA @ @ C$bool$ \\\\/ VB VC @ @ C$bool$ \\\\/ @ @ C$bool$ /\\\\ VA VB @ @ C$bool$ /\\\\ VA VC',\n",
       "  '∀(A :bool) (B :bool) (C :bool). A ∧ (B ∨ C) ⇔ A ∧ B ∨ A ∧ C'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$min$ = @ @ C$bool$ /\\\\ @ C$bool$ ! | Vx @ VP Vx VQ @ C$bool$ ! | Vx @ @ C$bool$ /\\\\ @ VP Vx VQ',\n",
       "  '∀(P :α -> bool) (Q :bool). (∀(x :α). P x) ∧ Q ⇔ ∀(x :α). P x ∧ Q'),\n",
       " (\"@ C$bool$ ! | VP @ C$bool$ ! | VP' @ C$bool$ ! | VQ @ C$bool$ ! | VQ' @ @ C$min$ ==> @ @ C$bool$ /\\\\ @ @ C$min$ = VP VP' @ @ C$min$ ==> VP' @ @ C$min$ = VQ VQ' @ @ C$min$ = @ @ C$bool$ /\\\\ VP VQ @ @ C$bool$ /\\\\ VP' VQ'\",\n",
       "  \"∀(P :bool) (P' :bool) (Q :bool) (Q' :bool). (P ⇔ P') ∧ (P' ⇒ (Q ⇔ Q')) ⇒ (P ∧ Q ⇔ P' ∧ Q')\"),\n",
       " ('@ C$bool$ ! | Vf @ @ C$min$ ==> @ C$bool$ ! | Vx @ C$bool$ ! | Vy @ C$bool$ ! | Vz @ @ C$min$ = @ @ Vf Vx @ @ Vf Vy Vz @ @ Vf @ @ Vf Vx Vy Vz @ @ C$min$ ==> @ C$bool$ ! | Vx @ C$bool$ ! | Vy @ @ C$min$ = @ @ Vf Vx Vy @ @ Vf Vy Vx @ C$bool$ ! | Vx @ C$bool$ ! | Vy @ C$bool$ ! | Vz @ @ C$min$ = @ @ Vf Vx @ @ Vf Vy Vz @ @ Vf Vy @ @ Vf Vx Vz',\n",
       "  '∀(f :α -> α -> α). (∀(x :α) (y :α) (z :α). f x (f y z) = f (f x y) z) ⇒ (∀(x :α) (y :α). f x y = f y x) ⇒ ∀(x :α) (y :α) (z :α). f x (f y z) = f y (f x z)'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | Vt @ @ C$min$ ==> @ C$bool$ ! | Vx @ @ C$min$ ==> @ @ C$min$ = Vx Vt @ VP Vx @ C$bool$ ? VP',\n",
       "  '∀(P :α -> bool) (t :α). (∀(x :α). x = t ⇒ P x) ⇒ $? P'),\n",
       " ('@ C$bool$ ! | Vi @ @ C$min$ = Vi C$bool$ the_value',\n",
       "  '∀(i :α itself). i = (:α)'),\n",
       " ('@ C$bool$ ! | VP @ @ C$min$ ==> @ VP C$bool$ the_value @ C$bool$ ! | Vi @ VP Vi',\n",
       "  '∀(P :α itself -> bool). P (:α) ⇒ ∀(i :α itself). P i'),\n",
       " ('@ C$bool$ ! | Ve @ C$bool$ ? | Vf @ @ C$min$ = @ Vf C$bool$ the_value Ve',\n",
       "  '∀(e :β). ∃(f :α itself -> β). f (:α) = e'),\n",
       " ('@ C$bool$ ! | Vt @ @ C$min$ = @ @ C$min$ ==> Vt C$bool$ F @ @ C$min$ = Vt C$bool$ F',\n",
       "  '∀(t :bool). t ⇒ F ⇔ (t ⇔ F)'),\n",
       " ('@ C$bool$ ! | Vt @ @ C$min$ ==> @ @ C$min$ ==> Vt C$bool$ F @ C$bool$ ~ Vt',\n",
       "  '∀(t :bool). (t ⇒ F) ⇒ ¬t'),\n",
       " ('@ C$bool$ ! | VA @ C$bool$ ! | VB @ @ C$min$ = @ @ C$min$ ==> VA VB @ @ C$bool$ \\\\/ @ C$bool$ ~ VA VB',\n",
       "  '∀(A :bool) (B :bool). A ⇒ B ⇔ ¬A ∨ B'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ C$bool$ ! | VR @ @ C$min$ = @ @ C$min$ ==> VP @ @ C$bool$ /\\\\ VQ VR @ @ C$bool$ /\\\\ @ @ C$min$ ==> VP VQ @ @ C$min$ ==> VP VR',\n",
       "  '∀(P :bool) (Q :bool) (R :bool). P ⇒ Q ∧ R ⇔ (P ⇒ Q) ∧ (P ⇒ R)'),\n",
       " (\"@ C$bool$ ! | Vx @ C$bool$ ! | Vx' @ C$bool$ ! | Vy @ C$bool$ ! | Vy' @ @ C$min$ ==> @ @ C$bool$ /\\\\ @ @ C$min$ = Vx Vx' @ @ C$min$ ==> Vx' @ @ C$min$ = Vy Vy' @ @ C$min$ = @ @ C$min$ ==> Vx Vy @ @ C$min$ ==> Vx' Vy'\",\n",
       "  \"∀(x :bool) (x' :bool) (y :bool) (y' :bool). (x ⇔ x') ∧ (x' ⇒ (y ⇔ y')) ⇒ (x ⇒ y ⇔ x' ⇒ y')\"),\n",
       " ('@ C$bool$ ! | Vt @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ C$min$ ==> C$bool$ T Vt Vt @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ C$min$ ==> Vt C$bool$ T C$bool$ T @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ C$min$ ==> C$bool$ F Vt C$bool$ T @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ C$min$ ==> Vt Vt C$bool$ T @ @ C$min$ = @ @ C$min$ ==> Vt C$bool$ F @ C$bool$ ~ Vt',\n",
       "  '∀(t :bool). (T ⇒ t ⇔ t) ∧ (t ⇒ T ⇔ T) ∧ (F ⇒ t ⇔ T) ∧ (t ⇒ t ⇔ T) ∧ (t ⇒ F ⇔ ¬t)'),\n",
       " ('@ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ @ C$min$ ==> @ @ C$min$ ==> Vt1 Vt2 @ @ C$min$ ==> @ @ C$min$ ==> Vt2 Vt1 @ @ C$min$ = Vt1 Vt2',\n",
       "  '∀(t1 :bool) (t2 :bool). (t1 ⇒ t2) ⇒ (t2 ⇒ t1) ⇒ (t1 ⇔ t2)'),\n",
       " ('@ C$bool$ ! | Vf @ C$bool$ ! | Vg @ @ C$min$ = @ @ C$min$ = Vf Vg @ C$bool$ ! | Vx @ @ C$min$ = @ Vf Vx @ Vg Vx',\n",
       "  '∀(f :α -> β) (g :α -> β). f = g ⇔ ∀(x :α). f x = g x'),\n",
       " ('@ @ C$min$ = @ C$bool$ ! Vf @ C$bool$ ! | Vx @ Vf Vx',\n",
       "  '$! (f :α -> bool) ⇔ ∀(x :α). f x'),\n",
       " ('@ C$bool$ ! | Vt @ @ C$min$ = @ C$bool$ ! | Vx Vt Vt',\n",
       "  '∀(t :bool). (∀(x :α). t) ⇔ t'),\n",
       " ('@ @ C$min$ = @ C$bool$ ! | Vx @ VP Vx @ VP C$bool$ the_value',\n",
       "  '(∀(x :α itself). (P :α itself -> bool) x) ⇔ P (:α)'),\n",
       " ('@ @ C$min$ = @ C$bool$ ! | Vb @ VP Vb @ @ C$bool$ /\\\\ @ VP C$bool$ T @ VP C$bool$ F',\n",
       "  '(∀(b :bool). (P :bool -> bool) b) ⇔ P T ∧ P F'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$min$ = @ C$bool$ ! | Vx @ @ C$bool$ /\\\\ @ VP Vx @ VQ Vx @ @ C$bool$ /\\\\ @ C$bool$ ! | Vx @ VP Vx @ C$bool$ ! | Vx @ VQ Vx',\n",
       "  '∀(P :α -> bool) (Q :α -> bool). (∀(x :α). P x ∧ Q x) ⇔ (∀(x :α). P x) ∧ ∀(x :α). Q x'),\n",
       " ('@ C$bool$ ! | Vt @ @ C$min$ ==> @ C$bool$ ~ Vt @ @ C$min$ ==> Vt C$bool$ F',\n",
       "  '∀(t :bool). ¬t ⇒ t ⇒ F'),\n",
       " ('@ @ C$min$ = @ C$bool$ ?! | Vx @ VP Vx @ @ C$bool$ /\\\\ @ C$bool$ ? | Vx @ VP Vx @ C$bool$ ! | Vx @ C$bool$ ! | Vy @ @ C$min$ ==> @ @ C$bool$ /\\\\ @ VP Vx @ VP Vy @ @ C$min$ = Vx Vy',\n",
       "  '(∃!(x :α). (P :α -> bool) x) ⇔ (∃(x :α). P x) ∧ ∀(x :α) (y :α). P x ∧ P y ⇒ x = y'),\n",
       " ('@ C$bool$ ! | Va @ C$bool$ ?! | Vx @ @ C$min$ = Vx Va',\n",
       "  '∀(a :α). ∃!(x :α). x = a'),\n",
       " ('@ @ C$min$ = @ C$bool$ ?! | Vx @ VP Vx @ C$bool$ ? | Vx @ C$bool$ ! | Vy @ @ C$min$ = @ VP Vy @ @ C$min$ = Vy Vx',\n",
       "  '(∃!(x :α). (P :α -> bool) x) ⇔ ∃(x :α). ∀(y :α). P y ⇔ y = x'),\n",
       " ('@ @ C$min$ = @ C$bool$ ? Vf @ C$bool$ ? | Vx @ Vf Vx',\n",
       "  '$? (f :α -> bool) ⇔ ∃(x :α). f x'),\n",
       " ('@ C$bool$ ! | Vt @ @ C$min$ = @ C$bool$ ? | Vx Vt Vt',\n",
       "  '∀(t :bool). (∃(x :α). t) ⇔ t'),\n",
       " ('@ C$bool$ ! | Va @ C$bool$ ? | Vx @ @ C$min$ = Vx Va',\n",
       "  '∀(a :α). ∃(x :α). x = a'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$min$ = @ C$bool$ ? | Vx @ @ C$bool$ \\\\/ @ VP Vx @ VQ Vx @ @ C$bool$ \\\\/ @ C$bool$ ? | Vx @ VP Vx @ C$bool$ ? | Vx @ VQ Vx',\n",
       "  '∀(P :α -> bool) (Q :α -> bool). (∃(x :α). P x ∨ Q x) ⇔ (∃(x :α). P x) ∨ ∃(x :α). Q x'),\n",
       " ('@ @ C$min$ = @ C$bool$ ? | Vx @ VP Vx @ VP C$bool$ the_value',\n",
       "  '(∃(x :α itself). (P :α itself -> bool) x) ⇔ P (:α)'),\n",
       " ('@ C$bool$ ! | Vt @ @ C$bool$ \\\\/ Vt @ C$bool$ ~ Vt', '∀(t :bool). t ∨ ¬t'),\n",
       " ('@ C$bool$ ! | VM @ @ C$min$ = | Vx @ VM Vx VM',\n",
       "  '∀(M :α -> β). (λ(x :α). M x) = M'),\n",
       " ('@ C$bool$ ! | Vx @ C$bool$ ! | Vy @ C$bool$ ! | Vz @ @ C$min$ ==> @ @ C$bool$ /\\\\ @ @ C$min$ = Vx Vy @ @ C$min$ = Vy Vz @ @ C$min$ = Vx Vz',\n",
       "  '∀(x :α) (y :α) (z :α). x = y ∧ y = z ⇒ x = z'),\n",
       " ('@ C$bool$ ! | Vx @ C$bool$ ! | Vy @ @ C$min$ = @ @ C$min$ = Vx Vy @ @ C$min$ = Vy Vx',\n",
       "  '∀(x :α) (y :α). x = y ⇔ y = x'),\n",
       " ('@ C$bool$ ! | Vx @ C$bool$ ! | Vy @ @ C$min$ ==> @ @ C$min$ = Vx Vy @ @ C$min$ = Vy Vx',\n",
       "  '∀(x :α) (y :α). x = y ⇒ y = x'),\n",
       " ('@ C$bool$ ! | Vx @ @ C$min$ = Vx Vx', '∀(x :α). x = x'),\n",
       " ('@ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ @ C$min$ = @ @ C$min$ = Vt1 Vt2 @ @ C$bool$ /\\\\ @ @ C$min$ ==> Vt1 Vt2 @ @ C$min$ ==> Vt2 Vt1',\n",
       "  '∀(t1 :bool) (t2 :bool). (t1 ⇔ t2) ⇔ (t1 ⇒ t2) ∧ (t2 ⇒ t1)'),\n",
       " ('@ C$bool$ ! | Vf @ C$bool$ ! | Vg @ @ C$min$ ==> @ C$bool$ ! | Vx @ @ C$min$ = @ Vf Vx @ Vg Vx @ @ C$min$ = Vf Vg',\n",
       "  '∀(f :α -> β) (g :α -> β). (∀(x :α). f x = g x) ⇒ f = g'),\n",
       " ('@ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ @ C$min$ = @ @ C$min$ = Vt1 Vt2 @ @ C$bool$ \\\\/ @ @ C$bool$ /\\\\ Vt1 Vt2 @ @ C$bool$ /\\\\ @ C$bool$ ~ Vt1 @ C$bool$ ~ Vt2',\n",
       "  '∀(t1 :bool) (t2 :bool). (t1 ⇔ t2) ⇔ t1 ∧ t2 ∨ ¬t1 ∧ ¬t2'),\n",
       " ('@ C$bool$ ! | Vt @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ C$min$ = C$bool$ T Vt Vt @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ C$min$ = Vt C$bool$ T Vt @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ C$min$ = C$bool$ F Vt @ C$bool$ ~ Vt @ @ C$min$ = @ @ C$min$ = Vt C$bool$ F @ C$bool$ ~ Vt',\n",
       "  '∀(t :bool). ((T ⇔ t) ⇔ t) ∧ ((t ⇔ T) ⇔ t) ∧ ((F ⇔ t) ⇔ ¬t) ∧ ((t ⇔ F) ⇔ ¬t)'),\n",
       " ('@ C$bool$ ! | VA @ C$bool$ ! | VB @ @ C$min$ = @ @ C$bool$ \\\\/ VA VB @ @ C$bool$ \\\\/ VB VA',\n",
       "  '∀(A :bool) (B :bool). A ∨ B ⇔ B ∨ A'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ C$bool$ ! | VR @ @ C$min$ = @ @ C$min$ ==> @ @ C$bool$ \\\\/ VP VQ VR @ @ C$bool$ /\\\\ @ @ C$min$ ==> VP VR @ @ C$min$ ==> VQ VR',\n",
       "  '∀(P :bool) (Q :bool) (R :bool). P ∨ Q ⇒ R ⇔ (P ⇒ R) ∧ (Q ⇒ R)'),\n",
       " ('@ C$bool$ ! | VA @ C$bool$ ! | VB @ @ C$min$ = @ @ C$bool$ \\\\/ VA VB @ @ C$min$ ==> @ C$bool$ ~ VA VB',\n",
       "  '∀(A :bool) (B :bool). A ∨ B ⇔ ¬A ⇒ B'),\n",
       " ('@ C$bool$ ! | VA @ C$bool$ ! | VB @ C$bool$ ! | VC @ @ C$min$ = @ @ C$bool$ \\\\/ VA @ @ C$bool$ \\\\/ VB VC @ @ C$bool$ \\\\/ @ @ C$bool$ \\\\/ VA VB VC',\n",
       "  '∀(A :bool) (B :bool) (C :bool). A ∨ B ∨ C ⇔ (A ∨ B) ∨ C'),\n",
       " ('@ C$bool$ ! | VA @ C$bool$ ! | VB @ @ C$bool$ /\\\\ @ @ C$min$ = @ C$bool$ ~ @ @ C$bool$ /\\\\ VA VB @ @ C$bool$ \\\\/ @ C$bool$ ~ VA @ C$bool$ ~ VB @ @ C$min$ = @ C$bool$ ~ @ @ C$bool$ \\\\/ VA VB @ @ C$bool$ /\\\\ @ C$bool$ ~ VA @ C$bool$ ~ VB',\n",
       "  '∀(A :bool) (B :bool). (¬(A ∧ B) ⇔ ¬A ∨ ¬B) ∧ (¬(A ∨ B) ⇔ ¬A ∧ ¬B)'),\n",
       " ('@ C$bool$ ! | Vx @ @ C$min$ = @ C$bool$ DATATYPE Vx C$bool$ T',\n",
       "  '∀(x :α). DATATYPE x ⇔ T'),\n",
       " ('@ @ C$min$ = @ C$bool$ DATATYPE @ @ Vbool C$bool$ T C$bool$ F C$bool$ T',\n",
       "  'DATATYPE ((bool :bool -> bool -> bool) T F) ⇔ T'),\n",
       " ('@ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ @ C$min$ = @ @ C$bool$ /\\\\ Vt1 Vt2 @ @ C$bool$ /\\\\ Vt2 Vt1',\n",
       "  '∀(t1 :bool) (t2 :bool). t1 ∧ t2 ⇔ t2 ∧ t1'),\n",
       " ('@ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ C$bool$ ! | Vt3 @ @ C$min$ = @ @ C$bool$ /\\\\ Vt1 @ @ C$bool$ /\\\\ Vt2 Vt3 @ @ C$bool$ /\\\\ @ @ C$bool$ /\\\\ Vt1 Vt2 Vt3',\n",
       "  '∀(t1 :bool) (t2 :bool) (t3 :bool). t1 ∧ t2 ∧ t3 ⇔ (t1 ∧ t2) ∧ t3'),\n",
       " ('@ C$bool$ ! | Vb @ C$bool$ ! | Vf @ C$bool$ ! | Vg @ C$bool$ ! | Vx @ @ C$min$ = @ @ @ @ C$bool$ COND Vb Vf Vg Vx @ @ @ C$bool$ COND Vb @ Vf Vx @ Vg Vx',\n",
       "  '∀(b :bool) (f :α -> β) (g :α -> β) (x :α). ((if b then f else g) x :β) = if b then f x else g x'),\n",
       " ('@ C$bool$ ! | Vf @ C$bool$ ! | Vb @ C$bool$ ! | Vx @ C$bool$ ! | Vy @ @ C$min$ = @ Vf @ @ @ C$bool$ COND Vb Vx Vy @ @ @ C$bool$ COND Vb @ Vf Vx @ Vf Vy',\n",
       "  '∀(f :α -> β) (b :bool) (x :α) (y :α). f (if b then x else y) = if b then f x else f y'),\n",
       " ('@ C$bool$ ! | Vb @ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ @ C$min$ = @ @ @ C$bool$ COND Vb Vt1 Vt2 @ @ C$bool$ \\\\/ @ @ C$bool$ /\\\\ Vb Vt1 @ @ C$bool$ /\\\\ @ C$bool$ ~ Vb Vt2',\n",
       "  '∀(b :bool) (t1 :bool) (t2 :bool). (if b then t1 else t2) ⇔ b ∧ t1 ∨ ¬b ∧ t2'),\n",
       " ('@ C$bool$ ! | Vb @ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ @ C$min$ = @ @ @ C$bool$ COND Vb Vt1 Vt2 @ @ C$bool$ /\\\\ @ @ C$min$ ==> Vb Vt1 @ @ C$min$ ==> @ C$bool$ ~ Vb Vt2',\n",
       "  '∀(b :bool) (t1 :bool) (t2 :bool). (if b then t1 else t2) ⇔ (b ⇒ t1) ∧ (¬b ⇒ t2)'),\n",
       " ('@ C$bool$ ! | Vb @ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ @ C$min$ = @ @ @ C$bool$ COND Vb Vt1 Vt2 @ @ C$bool$ /\\\\ @ @ C$bool$ \\\\/ @ C$bool$ ~ Vb Vt1 @ @ C$bool$ \\\\/ Vb Vt2',\n",
       "  '∀(b :bool) (t1 :bool) (t2 :bool). (if b then t1 else t2) ⇔ (¬b ∨ t1) ∧ (b ∨ t2)'),\n",
       " (\"@ C$bool$ ! | VP @ C$bool$ ! | VQ @ C$bool$ ! | Vx @ C$bool$ ! | Vx' @ C$bool$ ! | Vy @ C$bool$ ! | Vy' @ @ C$min$ ==> @ @ C$bool$ /\\\\ @ @ C$min$ = VP VQ @ @ C$bool$ /\\\\ @ @ C$min$ ==> VQ @ @ C$min$ = Vx Vx' @ @ C$min$ ==> @ C$bool$ ~ VQ @ @ C$min$ = Vy Vy' @ @ C$min$ = @ @ @ C$bool$ COND VP Vx Vy @ @ @ C$bool$ COND VQ Vx' Vy'\",\n",
       "  \"∀(P :bool) (Q :bool) (x :α) (x' :α) (y :α) (y' :α). (P ⇔ Q) ∧ (Q ⇒ x = x') ∧ (¬Q ⇒ y = y') ⇒ (if P then x else y) = if Q then x' else y'\"),\n",
       " ('@ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ @ C$bool$ COND C$bool$ T Vt1 Vt2 Vt1 @ @ C$min$ = @ @ @ C$bool$ COND C$bool$ F Vt1 Vt2 Vt2',\n",
       "  '∀(t1 :α) (t2 :α). (if T then t1 else t2) = t1 ∧ (if F then t1 else t2) = t2'),\n",
       " ('@ C$bool$ ! | Vb @ C$bool$ ! | Vf @ C$bool$ ! | Vg @ @ C$min$ = | Vx @ @ @ C$bool$ COND Vb @ Vf Vx @ Vg Vx @ @ @ C$bool$ COND Vb Vf Vg',\n",
       "  '∀(b :bool) (f :α -> β) (g :α -> β). (λ(x :α). if b then f x else g x) = if b then f else g'),\n",
       " ('@ C$bool$ ! | Vv @ @ C$min$ = @ C$bool$ BOUNDED Vv C$bool$ T',\n",
       "  '∀(v :bool). BOUNDED v ⇔ T'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$min$ = @ C$bool$ ! | Vx @ @ C$bool$ \\\\/ VP VQ @ @ C$bool$ \\\\/ @ C$bool$ ! | Vx VP @ C$bool$ ! | Vx VQ',\n",
       "  '∀(P :bool) (Q :bool). (∀(x :α). P ∨ Q) ⇔ (∀(x :α). P) ∨ ∀(x :α). Q'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$min$ = @ C$bool$ ! | Vx @ @ C$min$ ==> VP VQ @ @ C$min$ ==> @ C$bool$ ? | Vx VP @ C$bool$ ! | Vx VQ',\n",
       "  '∀(P :bool) (Q :bool). (∀(x :α). P ⇒ Q) ⇔ (∃(x :α). P) ⇒ ∀(x :α). Q'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$min$ = @ C$bool$ ? | Vx @ @ C$min$ ==> VP VQ @ @ C$min$ ==> @ C$bool$ ! | Vx VP @ C$bool$ ? | Vx VQ',\n",
       "  '∀(P :bool) (Q :bool). (∃(x :α). P ⇒ Q) ⇔ (∀(x :α). P) ⇒ ∃(x :α). Q'),\n",
       " ('@ C$bool$ ! | VP @ C$bool$ ! | VQ @ @ C$min$ = @ C$bool$ ? | Vx @ @ C$bool$ /\\\\ VP VQ @ @ C$bool$ /\\\\ @ C$bool$ ? | Vx VP @ C$bool$ ? | Vx VQ',\n",
       "  '∀(P :bool) (Q :bool). (∃(x :α). P ∧ Q) ⇔ (∃(x :α). P) ∧ ∃(x :α). Q'),\n",
       " ('@ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ C$bool$ ? | Vfn @ @ C$bool$ /\\\\ @ @ C$min$ = @ Vfn C$bool$ T Vt1 @ @ C$min$ = @ Vfn C$bool$ F Vt2',\n",
       "  '∀(t1 :α) (t2 :α). ∃(fn :bool -> α). fn T = t1 ∧ fn F = t2'),\n",
       " ('@ C$bool$ ! | VP @ @ C$min$ ==> @ @ C$bool$ /\\\\ @ VP C$bool$ T @ VP C$bool$ F @ C$bool$ ! | Vb @ VP Vb',\n",
       "  '∀(P :bool -> bool). P T ∧ P F ⇒ ∀(b :bool). P b'),\n",
       " ('@ C$bool$ ! | VP @ @ C$min$ ==> @ @ C$bool$ /\\\\ @ VP | Vb C$bool$ T @ @ C$bool$ /\\\\ @ VP | Vb C$bool$ F @ @ C$bool$ /\\\\ @ VP | Vb Vb @ VP | Vb @ C$bool$ ~ Vb @ C$bool$ ! | Vf @ VP Vf',\n",
       "  '∀(P :(bool -> bool) -> bool). P (λ(b :bool). T) ∧ P (λ(b :bool). F) ∧ P (λ(b :bool). b) ∧ P (λ(b :bool). ¬b) ⇒ ∀(f :bool -> bool). P f'),\n",
       " ('@ C$bool$ ! | Vf @ @ C$bool$ \\\\/ @ @ C$min$ = Vf | Vb C$bool$ T @ @ C$bool$ \\\\/ @ @ C$min$ = Vf | Vb C$bool$ F @ @ C$bool$ \\\\/ @ @ C$min$ = Vf | Vb Vb @ @ C$min$ = Vf | Vb @ C$bool$ ~ Vb',\n",
       "  '∀(f :bool -> bool). f = (λ(b :bool). T) ∨ f = (λ(b :bool). F) ∨ f = (λ(b :bool). b) ∨ f = (λ(b :bool). ¬b)'),\n",
       " ('@ @ C$bool$ /\\\\ @ C$bool$ ~ @ @ C$min$ = C$bool$ T C$bool$ F @ C$bool$ ~ @ @ C$min$ = C$bool$ F C$bool$ T',\n",
       "  '(T ⇎ F) ∧ (F ⇎ T)'),\n",
       " ('@ @ C$bool$ /\\\\ @ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ @ C$min$ = @ @ @ C$bool$ COND C$bool$ T Vt1 Vt2 Vt1 @ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ @ C$min$ = @ @ @ C$bool$ COND C$bool$ F Vt1 Vt2 Vt2',\n",
       "  '(∀(t1 :α) (t2 :α). (if T then t1 else t2) = t1) ∧ ∀(t1 :α) (t2 :α). (if F then t1 else t2) = t2'),\n",
       " ('@ C$bool$ ! | Vf @ C$bool$ ! | Vy @ @ C$min$ = @ | Vx @ Vf Vx Vy @ Vf Vy',\n",
       "  '∀(f :α -> β) (y :α). (λ(x :α). f x) y = f y'),\n",
       " ('@ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ @ C$min$ ==> Vt1 @ @ C$min$ ==> Vt2 @ @ C$bool$ /\\\\ Vt1 Vt2',\n",
       "  '∀(t1 :bool) (t2 :bool). t1 ⇒ t2 ⇒ t1 ∧ t2'),\n",
       " ('@ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ C$bool$ ! | Vt3 @ @ C$min$ = @ @ C$min$ ==> Vt1 @ @ C$min$ ==> Vt2 Vt3 @ @ C$min$ ==> @ @ C$bool$ /\\\\ Vt1 Vt2 Vt3',\n",
       "  '∀(t1 :bool) (t2 :bool) (t3 :bool). t1 ⇒ t2 ⇒ t3 ⇔ t1 ∧ t2 ⇒ t3'),\n",
       " (\"@ C$bool$ ! | VP @ C$bool$ ! | VP' @ C$bool$ ! | VQ @ C$bool$ ! | VQ' @ @ C$min$ ==> @ @ C$bool$ /\\\\ @ @ C$min$ ==> VQ @ @ C$min$ = VP VP' @ @ C$min$ ==> VP' @ @ C$min$ = VQ VQ' @ @ C$min$ = @ @ C$bool$ /\\\\ VP VQ @ @ C$bool$ /\\\\ VP' VQ'\",\n",
       "  \"∀(P :bool) (P' :bool) (Q :bool) (Q' :bool). (Q ⇒ (P ⇔ P')) ∧ (P' ⇒ (Q ⇔ Q')) ⇒ (P ∧ Q ⇔ P' ∧ Q')\"),\n",
       " ('@ C$bool$ ! | Vt @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ C$bool$ /\\\\ C$bool$ T Vt Vt @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ C$bool$ /\\\\ Vt C$bool$ T Vt @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ C$bool$ /\\\\ C$bool$ F Vt C$bool$ F @ @ C$bool$ /\\\\ @ @ C$min$ = @ @ C$bool$ /\\\\ Vt C$bool$ F C$bool$ F @ @ C$min$ = @ @ C$bool$ /\\\\ Vt Vt Vt',\n",
       "  '∀(t :bool). (T ∧ t ⇔ t) ∧ (t ∧ T ⇔ t) ∧ (F ∧ t ⇔ F) ∧ (t ∧ F ⇔ F) ∧ (t ∧ t ⇔ t)'),\n",
       " ('@ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ @ C$min$ ==> @ @ C$bool$ /\\\\ Vt1 Vt2 Vt2',\n",
       "  '∀(t1 :bool) (t2 :bool). t1 ∧ t2 ⇒ t2'),\n",
       " ('@ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ @ C$min$ ==> @ @ C$bool$ /\\\\ Vt1 Vt2 Vt1',\n",
       "  '∀(t1 :bool) (t2 :bool). t1 ∧ t2 ⇒ t1'),\n",
       " ('@ C$bool$ ! | Vt1 @ C$bool$ ! | Vt2 @ @ C$min$ = @ | Vx Vt1 Vt2 Vt1',\n",
       "  '∀(t1 :α) (t2 :β). (λ(x :β). t1) t2 = t1'),\n",
       " ('@ C$bool$ ! | VP @ @ C$min$ ==> @ C$bool$ ? | Vrep @ @ C$bool$ TYPE_DEFINITION VP Vrep @ C$bool$ ? | Vrep @ C$bool$ ? | Vabs @ @ C$bool$ /\\\\ @ C$bool$ ! | Va @ @ C$min$ = @ Vabs @ Vrep Va Va @ C$bool$ ! | Vr @ @ C$min$ = @ VP Vr @ @ C$min$ = @ Vrep @ Vabs Vr Vr',\n",
       "  '∀(P :α -> bool). (∃(rep :β -> α). TYPE_DEFINITION P rep) ⇒ ∃(rep :β -> α) (abs :α -> β). (∀(a :β). abs (rep a) = a) ∧ ∀(r :α). P r ⇔ rep (abs r) = r')]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_THEORIES = [\"bool\"]\n",
    "GOALS = [(key, value[4]) for key, value in database.items() if value[3] == \"thm\" and value[0] in TARGET_THEORIES]\n",
    "\n",
    "\n",
    "#train(GOALS)\n",
    "GOALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "following-impossible",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utp_model\n",
    "\n",
    "def run_iteration(goals, mode=\"training\", ARG_LEN=5):\n",
    "    \n",
    "\n",
    "    learning_rate = 1e-5\n",
    "\n",
    "    context_rate = 5e-5\n",
    "    tac_rate = 5e-5\n",
    "    arg_rate = 5e-5\n",
    "    term_rate = 5e-5\n",
    "\n",
    "    gamma = 0.99 # 0.9\n",
    "\n",
    "    # for entropy regularization\n",
    "    trade_off = 1e-2\n",
    "\n",
    "    context_net = utp_model.ContextPolicy()\n",
    "\n",
    "    tac_net = utp_model.TacPolicy(len(tactic_pool))\n",
    "\n",
    "    arg_net = utp_model.ArgPolicy(len(tactic_pool), 256)\n",
    "\n",
    "    term_net = utp_model.TermPolicy(len(tactic_pool), 256)\n",
    "\n",
    "    context_net = context_net.to(device)\n",
    "    tac_net = tac_net.to(device)\n",
    "    arg_net = arg_net.to(device)\n",
    "    term_net = term_net.to(device)\n",
    "\n",
    "    optimizer_context = torch.optim.RMSprop(list(context_net.parameters()), lr=context_rate)\n",
    "\n",
    "    optimizer_tac = torch.optim.RMSprop(list(tac_net.parameters()), lr=tac_rate)\n",
    "\n",
    "    optimizer_arg = torch.optim.RMSprop(list(arg_net.parameters()), lr=arg_rate)\n",
    "\n",
    "    optimizer_term = torch.optim.RMSprop(list(term_net.parameters()), lr=term_rate)\n",
    "\n",
    "\n",
    "    torch.set_grad_enabled(mode==\"training\" or mode==\"subgoals\")\n",
    "    global iteration_counter\n",
    "    # state_pool = []\n",
    "    fringe_pool = []\n",
    "    tac_pool = []\n",
    "    arg_pool = []\n",
    "    reward_pool = []\n",
    "    reward_print = []\n",
    "    action_pool = []\n",
    "    steps = 0\n",
    "    flag = True\n",
    "    replay_flag = False\n",
    "    tac_print = []\n",
    "\n",
    "    induct_arg = []\n",
    "    proved = 0\n",
    "    iteration_rewards = []\n",
    "\n",
    "    for goal in goals:\n",
    "        g = goal[1]\n",
    "            \n",
    "        env = HolEnv(g)\n",
    "\n",
    "        theories = re.findall(r'C\\$(\\w+)\\$ ', goal[0])\n",
    "        theories = set(theories)\n",
    "        theories = list(theories)\n",
    "\n",
    "        allowed_theories = theories\n",
    "\n",
    "        goal_theory = g\n",
    "\n",
    "        #print (\"Target goal: {}\".format(g))\n",
    "        \n",
    "        try:\n",
    "            allowed_arguments_ids = []\n",
    "            candidate_args = []\n",
    "            goal_theory = g#database[polished_goal][0] # plain_database[goal][0]\n",
    "            for i,t in enumerate(database):\n",
    "                if database[t][0] in allowed_theories and (database[t][0] != goal_theory or int(database[t][2]) < int(database[polished_goal][2])):\n",
    "                    allowed_arguments_ids.append(i)\n",
    "                    candidate_args.append(t)\n",
    "\n",
    "            env.toggle_simpset(\"diminish\", goal_theory)\n",
    "            #print(\"Removed simpset of {}\".format(goal_theory))\n",
    "\n",
    "        except:\n",
    "            allowed_arguments_ids = []\n",
    "            candidate_args = []\n",
    "            for i,t in enumerate(database):\n",
    "                if database[t][0] in allowed_theories:\n",
    "                    allowed_arguments_ids.append(i)\n",
    "                    candidate_args.append(t)\n",
    "            #print(\"Theorem not found in database.\")\n",
    "\n",
    "        #print (\"Number of candidate facts to use: {}\".format(len(candidate_args)))\n",
    "\n",
    "        encoded_database = torch.load('encoded_include_probability.pt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        encoded_fact_pool = torch.index_select(encoded_database, 0, torch.tensor(allowed_arguments_ids, device=device))\n",
    "\n",
    "\n",
    "        for i in range(50):\n",
    "\n",
    "            # gather all the goals in the history\n",
    "            try:\n",
    "                representations, context_set, fringe_sizes = gather_encoded_content(env.history, batch_encoder_)\n",
    "            except Exception as e:\n",
    "                print (e)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            representations = representations.to(device)\n",
    "            context_scores = context_net(representations)\n",
    "            contexts_by_fringe, scores_by_fringe = split_by_fringe(context_set, context_scores, fringe_sizes)\n",
    "            fringe_scores = []\n",
    "            for s in scores_by_fringe:\n",
    "                # fringe_score = torch.prod(s) # TODO: make it sum\n",
    "                fringe_score = torch.sum(s) # TODO: make it sum\n",
    "                fringe_scores.append(fringe_score)\n",
    "            fringe_scores = torch.stack(fringe_scores)\n",
    "            fringe_probs = F.softmax(fringe_scores, dim=0)\n",
    "            fringe_m = Categorical(fringe_probs)\n",
    "            fringe = fringe_m.sample()\n",
    "            fringe_pool.append(fringe_m.log_prob(fringe))\n",
    "\n",
    "            # take the first context in the chosen fringe for now\n",
    "            try:\n",
    "                target_context = contexts_by_fringe[fringe][0]\n",
    "            except:\n",
    "                print (\"error {} {}\".format(contexts_by_fringe, fringe))\n",
    "\n",
    "           # target_context = contexts_by_fringe[fringe][0]\n",
    "            target_goal = target_context[\"polished\"][\"goal\"]\n",
    "            target_representation = representations[context_set.index(target_context)]\n",
    "            # print(target_representation.shape)\n",
    "            # exit()\n",
    "\n",
    "            # size: (1, max_contexts, max_assumptions+1, max_len)\n",
    "            tac_input = target_representation.unsqueeze(0)\n",
    "            tac_input = tac_input.to(device)\n",
    "\n",
    "            # compute scores of tactics\n",
    "            tac_probs = tac_net(tac_input)\n",
    "            # print(tac_probs)\n",
    "            tac_m = Categorical(tac_probs)\n",
    "            tac = tac_m.sample()\n",
    "            # log directly the log probability\n",
    "            tac_pool.append(tac_m.log_prob(tac))\n",
    "            action_pool.append(tactic_pool[tac])\n",
    "            tac_print.append(tac_probs.detach())\n",
    "            # print(len(fact_pool[0].strip().split()))\n",
    "            # exit()\n",
    "\n",
    "            tac_tensor = tac.to(device)\n",
    "\n",
    "\n",
    "            if tactic_pool[tac] in no_arg_tactic:\n",
    "                tactic = tactic_pool[tac]\n",
    "                arg_probs = []\n",
    "                arg_probs.append(torch.tensor(0))\n",
    "                arg_pool.append(arg_probs)\n",
    "            elif tactic_pool[tac] == \"Induct_on\":\n",
    "                arg_probs = []\n",
    "                candidates = []\n",
    "                # input = torch.cat([target_representation, tac_tensor], dim=1)\n",
    "                tokens = target_goal.split()\n",
    "                tokens = list(dict.fromkeys(tokens))\n",
    "                tokens = [[t] for t in tokens if t[0] == \"V\"]\n",
    "                if tokens:\n",
    "                    # concatenate target_representation to token\n",
    "                    # use seq2seq to compute the representation of a token\n",
    "                    # also we don't need to split an element in tokens because they are singletons\n",
    "                    # but we need to make it a list containing a singleton list, i.e., [['Vl']]\n",
    "\n",
    "                    token_representations, _ = batch_encoder_.encode(tokens)\n",
    "                    # reshaping\n",
    "                    encoded_tokens = torch.cat(token_representations.split(1), dim=2).squeeze(0)\n",
    "                    target_representation_list = [target_representation.unsqueeze(0) for _ in tokens]\n",
    "\n",
    "                    target_representations = torch.cat(target_representation_list)\n",
    "                    # size: (len(tokens), 512)\n",
    "                    candidates = torch.cat([encoded_tokens, target_representations], dim=1)\n",
    "                    candidates = candidates.to(device)\n",
    "\n",
    "                    # concat = [torch.cat([torch.tensor([input_vocab.stoi[i] for _ in range(256)], dtype=torch.float), target_representation]) for i in tokens]\n",
    "\n",
    "                    # candidates = torch.stack(concat)\n",
    "                    # candidates = candidates.to(device)\n",
    "\n",
    "                    scores = term_net(candidates, tac_tensor)\n",
    "                    term_probs = F.softmax(scores, dim=0)\n",
    "                    try:\n",
    "                        term_m = Categorical(term_probs.squeeze(1))\n",
    "                    except:\n",
    "                        print(\"probs: {}\".format(term_probs))                                          \n",
    "                        print(\"candidates: {}\".format(candidates.shape))\n",
    "                        print(\"scores: {}\".format(scores))\n",
    "                        print(\"tokens: {}\".format(tokens))\n",
    "                        exit()\n",
    "                    term = term_m.sample()\n",
    "                    arg_probs.append(term_m.log_prob(term))\n",
    "                    induct_arg.append(tokens[term])                \n",
    "                    tm = tokens[term][0][1:] # remove headers, e.g., \"V\" / \"C\" / ...\n",
    "                    arg_pool.append(arg_probs)\n",
    "                    if tm:\n",
    "                        tactic = \"Induct_on `{}`\".format(tm)\n",
    "                    else:\n",
    "                        print(\"tm is empty\")\n",
    "                        print(tokens)\n",
    "                        # only to raise an error\n",
    "                        tactic = \"Induct_on\"\n",
    "                else:\n",
    "                    arg_probs.append(torch.tensor(0))\n",
    "                    induct_arg.append(\"No variables\")\n",
    "                    arg_pool.append(arg_probs)\n",
    "                    tactic = \"Induct_on\"\n",
    "            else:\n",
    "                hidden0 = hidden1 = target_representation.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "                hidden0 = hidden0.to(device)\n",
    "                hidden1 = hidden1.to(device)\n",
    "\n",
    "                hidden = (hidden0, hidden1)\n",
    "\n",
    "                # concatenate the candidates with hidden states.\n",
    "\n",
    "                hc = torch.cat([hidden0.squeeze(), hidden1.squeeze()])\n",
    "                hiddenl = [hc.unsqueeze(0) for _ in allowed_arguments_ids]\n",
    "\n",
    "                hiddenl = torch.cat(hiddenl)\n",
    "\n",
    "                # size: (len(fact_pool), 512)\n",
    "                candidates = torch.cat([encoded_fact_pool, hiddenl], dim=1)\n",
    "                candidates = candidates.to(device)\n",
    "\n",
    "                input = tac_tensor\n",
    "                # run it once before predicting the first argument\n",
    "                hidden, _ = arg_net(input, candidates, hidden)\n",
    "\n",
    "                # the indices of chosen args\n",
    "                arg_step = []\n",
    "                arg_step_probs = []\n",
    "                if tactic_pool[tac] in thm_tactic:\n",
    "                    arg_len = 1\n",
    "                else:\n",
    "                    arg_len = ARG_LEN\n",
    "\n",
    "                for i in range(arg_len):\n",
    "                    hidden, scores = arg_net(input, candidates, hidden)\n",
    "                    arg_probs = F.softmax(scores, dim=0)\n",
    "                    arg_m = Categorical(arg_probs.squeeze(1))\n",
    "                    arg = arg_m.sample()\n",
    "                    arg_step.append(arg)\n",
    "                    arg_step_probs.append(arg_m.log_prob(arg))\n",
    "\n",
    "                    hidden0 = hidden[0].squeeze().repeat(1, 1, 1)\n",
    "                    hidden1 = hidden[1].squeeze().repeat(1, 1, 1)\n",
    "                    # encoded chosen argument\n",
    "                    input = encoded_fact_pool[arg].unsqueeze(0).unsqueeze(0)\n",
    "                    # print(input.shape)\n",
    "\n",
    "                    # renew candidates                \n",
    "                    hc = torch.cat([hidden0.squeeze(), hidden1.squeeze()])\n",
    "                    hiddenl = [hc.unsqueeze(0) for _ in allowed_arguments_ids]\n",
    "\n",
    "                    hiddenl = torch.cat(hiddenl)\n",
    "\n",
    "                    # size: (len(fact_pool), 512)\n",
    "                    candidates = torch.cat([encoded_fact_pool, hiddenl], dim=1)\n",
    "                    candidates = candidates.to(device)\n",
    "\n",
    "                arg_pool.append(arg_step_probs)\n",
    "\n",
    "                tac = tactic_pool[tac]\n",
    "                arg = [candidate_args[i] for i in arg_step]\n",
    "\n",
    "                tactic = env.assemble_tactic(tac, arg)\n",
    "\n",
    "            action = (fringe.item(), 0, tactic)\n",
    "\n",
    "\n",
    "\n",
    "            # reward, done = env.step(action)\n",
    "            try:\n",
    "                # when step is performed, env.history (probably) changes\n",
    "                # if goal_index == 0:\n",
    "                #     raise \"boom\"\n",
    "                reward, done = env.step(action)\n",
    "\n",
    "            except:\n",
    "                print(\"Step exception raised.\")\n",
    "                # print(\"Fringe: {}\".format(env.history))\n",
    "                print(\"Handling: {}\".format(env.handling))\n",
    "                print(\"Using: {}\".format(env.using))\n",
    "                # try again\n",
    "                # counter = env.counter\n",
    "                frequency = env.frequency\n",
    "                env.close()\n",
    "                print(\"Aborting current game ...\")\n",
    "                print(\"Restarting environment ...\")\n",
    "                print(env.goal)\n",
    "                env = HolEnv(env.goal)\n",
    "                flag = False\n",
    "                break\n",
    "\n",
    "            if t == 49:\n",
    "                reward = -5\n",
    "            # state_pool.append(state)\n",
    "            reward_print.append(reward)\n",
    "            # reward_pool.append(reward+trade_off*entropy)\n",
    "            reward_pool.append(reward)\n",
    "\n",
    "                # pg = ng\n",
    "\n",
    "            steps += 1\n",
    "            total_reward = float(np.sum(reward_print))\n",
    "\n",
    "            if t == 49:\n",
    "                print(\"Failed.\")\n",
    "                print(\"Rewards: {}\".format(reward_print))\n",
    "                # print(\"Rewards: {}\".format(reward_pool))\n",
    "                print(\"Tactics: {}\".format(action_pool))\n",
    "                # print(\"Mean reward: {}\\n\".format(np.mean(reward_pool)))\n",
    "                print(\"Total: {}\".format(total_reward))\n",
    "                iteration_rewards.append(total_reward)\n",
    "\n",
    "            # Update policy\n",
    "            # Discount reward\n",
    "            print(\"Updating parameters ... \")\n",
    "            running_add = 0\n",
    "            for i in reversed(range(steps)):\n",
    "                if reward_pool[i] == 0:\n",
    "                    running_add = 0\n",
    "                else:\n",
    "                    running_add = running_add * gamma + reward_pool[i]\n",
    "                    reward_pool[i] = running_add\n",
    "\n",
    "            optimizer_context.zero_grad()\n",
    "            optimizer_tac.zero_grad()\n",
    "            optimizer_arg.zero_grad()\n",
    "            optimizer_term.zero_grad()\n",
    "\n",
    "            for i in range(steps):\n",
    "                # size : (1,1,4,128)\n",
    "                total_loss = 0\n",
    "\n",
    "                # state = state_pool[i]\n",
    "                reward = reward_pool[i]\n",
    "\n",
    "                fringe_loss = -fringe_pool[i] * (reward)\n",
    "                arg_loss = -torch.sum(torch.stack(arg_pool[i])) * (reward)\n",
    "\n",
    "                tac_loss = -tac_pool[i] * (reward)\n",
    "\n",
    "                # entropy = fringe_pool[i] + torch.sum(torch.stack(arg_pool[i])) + tac_pool[i]\n",
    "\n",
    "                # loss = fringe_loss + tac_loss + arg_loss + trade_off*entropy\n",
    "                loss = fringe_loss + tac_loss + arg_loss\n",
    "                total_loss += loss\n",
    "                #loss.backward()\n",
    "\n",
    "            total_loss.backward()\n",
    "\n",
    "            # optimizer.step()\n",
    "\n",
    "            optimizer_context.step()\n",
    "            optimizer_tac.step()\n",
    "            optimizer_arg.step()\n",
    "            optimizer_term.step()\n",
    "\n",
    "            fringe_pool = []\n",
    "            tac_pool = []\n",
    "            arg_pool = []\n",
    "            action_pool = []\n",
    "            reward_pool = []\n",
    "            reward_print = []\n",
    "            steps = 0\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "entertaining-paint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing theories...\n",
      "Loading modules...\n",
      "Configuration done.\n",
      "Removing simp lemmas from ∀(P :α -> bool) (a :α). (∃(x :α). x = a ∧ P x) ⇔ P a\n",
      "Updating parameters ... \n",
      "Updating parameters ... \n",
      "Updating parameters ... \n",
      "Updating parameters ... \n",
      "Updating parameters ... \n",
      "error [[{'polished': {'assumptions': [], 'goal': '@ C$bool$ ! | VP @ C$bool$ ! | Va @ @ C$min$ = @ C$bool$ ? | Vx @ @ C$bool$ /\\\\ @ @ C$min$ = Vx Va @ VP Vx @ VP Va'}, 'plain': {'assumptions': [], 'goal': '∀(P :α -> bool) (a :α). (∃(x :α). x = a ∧ P x) ⇔ P a'}}], [{'polished': {'assumptions': [], 'goal': '@ C$bool$ ! | Va @ @ C$min$ = @ C$bool$ ? | Vx @ @ C$bool$ /\\\\ @ @ C$min$ = Vx Va @ VP Vx @ VP Va'}, 'plain': {'assumptions': [], 'goal': '∀(a :α). (∃(x :α). x = a ∧ (P :α -> bool) x) ⇔ P a'}}], []] 2\n",
      "Step exception raised.\n",
      "Handling: ∀(a :α). (∃(x :α). x = a ∧ (P :α -> bool) x) ⇔ P a\n",
      "Using: metis_tac[boolTheory.bool_case_CONG, boolTheory.FORALL_BOOL, boolTheory.bool_case_CONG, boolTheory.FORALL_SIMP, boolTheory.BOTH_FORALL_IMP_THM]\n",
      "Found HOL pids: ['17464', '18660', '25692', '25701']\n",
      "Tried closing 17464\n",
      "Tried closing 18660\n",
      "Tried closing 25692\n",
      "Tried closing 25701\n",
      "Tried closing 25701\n",
      "Aborting current game ...\n",
      "Restarting environment ...\n",
      "∀(P :α -> bool) (a :α). (∃(x :α). x = a ∧ P x) ⇔ P a\n",
      "Importing theories...\n",
      "Loading modules...\n",
      "Configuration done.\n",
      "Importing theories...\n",
      "Loading modules...\n",
      "Configuration done.\n",
      "Removing simp lemmas from ∀(P :α -> bool) (a :α). (∃(x :α). a = x ∧ P x) ⇔ P a\n",
      "Updating parameters ... \n",
      "error [[{'polished': {'assumptions': [], 'goal': '@ C$bool$ ! | VP @ C$bool$ ! | Va @ @ C$min$ = @ C$bool$ ? | Vx @ @ C$bool$ /\\\\ @ @ C$min$ = Va Vx @ VP Vx @ VP Va'}, 'plain': {'assumptions': [], 'goal': '∀(P :α -> bool) (a :α). (∃(x :α). a = x ∧ P x) ⇔ P a'}}], []] 1\n",
      "Step exception raised.\n",
      "Handling: ∀(P :α -> bool) (a :α). (∃(x :α). a = x ∧ P x) ⇔ P a\n",
      "Using: fs[boolTheory.IMP_F, boolTheory.IMP_DISJ_THM, boolTheory.DE_MORGAN_THM, boolTheory.LEFT_AND_CONG, boolTheory.boolAxiom]\n",
      "Found HOL pids: ['17464', '18660', '25737', '25746']\n",
      "Tried closing 17464\n",
      "Tried closing 18660\n",
      "Tried closing 25737\n",
      "Tried closing 25746\n",
      "Tried closing 25746\n",
      "Aborting current game ...\n",
      "Restarting environment ...\n",
      "∀(P :α -> bool) (a :α). (∃(x :α). a = x ∧ P x) ⇔ P a\n",
      "Importing theories...\n",
      "Loading modules...\n",
      "Configuration done.\n",
      "Importing theories...\n",
      "Loading modules...\n",
      "Configuration done.\n",
      "Removing simp lemmas from ∀(f :α -> bool) (v :α). (∀(x :α). x = v ⇒ f x) ⇔ f v\n",
      "Updating parameters ... \n",
      "Updating parameters ... \n",
      "error [[{'polished': {'assumptions': [], 'goal': '@ C$bool$ ! | Vf @ C$bool$ ! | Vv @ @ C$min$ = @ C$bool$ ! | Vx @ @ C$min$ ==> @ @ C$min$ = Vx Vv @ Vf Vx @ Vf Vv'}, 'plain': {'assumptions': [], 'goal': '∀(f :α -> bool) (v :α). (∀(x :α). x = v ⇒ f x) ⇔ f v'}}], []] 1\n",
      "Step exception raised.\n",
      "Handling: ∀(f :α -> bool) (v :α). (∀(x :α). x = v ⇒ f x) ⇔ f v\n",
      "Using: simp[boolTheory.ABS_SIMP, boolTheory.BOUNDED_THM, boolTheory.COND_RATOR, boolTheory.FALSITY, boolTheory.UNWIND_FORALL_THM1]\n",
      "Found HOL pids: ['17464', '18660', '25783', '25792']\n",
      "Tried closing 17464\n",
      "Tried closing 18660\n",
      "Tried closing 25783\n",
      "Tried closing 25792\n",
      "Tried closing 25792\n",
      "Aborting current game ...\n",
      "Restarting environment ...\n",
      "∀(f :α -> bool) (v :α). (∀(x :α). x = v ⇒ f x) ⇔ f v\n",
      "Importing theories...\n",
      "Loading modules...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mrun_iteration\u001b[0;34m(goals, mode, ARG_LEN)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;66;03m# when step is performed, env.history (probably) changes\u001b[39;00m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;66;03m# if goal_index == 0:\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m#     raise \"boom\"\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     reward, done \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/PhD/git/repo/PhD/tactic_zero_jax/env/new_env.py:417\u001b[0m, in \u001b[0;36mHolEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    416\u001b[0m target_fringe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory[fringe_id]\n\u001b[0;32m--> 417\u001b[0m pre_target \u001b[38;5;241m=\u001b[39m \u001b[43mtarget_fringe\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgoal_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    418\u001b[0m target \u001b[38;5;241m=\u001b[39m pre_target[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m GOALS \u001b[38;5;241m=\u001b[39m [(key, value[\u001b[38;5;241m4\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m database\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m value[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthm\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m value[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m TARGET_THEORIES]\n\u001b[1;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mrun_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGOALS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mrun_iteration\u001b[0;34m(goals, mode, ARG_LEN)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRestarting environment ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28mprint\u001b[39m(env\u001b[38;5;241m.\u001b[39mgoal)\n\u001b[0;32m--> 305\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mHolEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgoal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/PhD/git/repo/PhD/tactic_zero_jax/env/new_env.py:120\u001b[0m, in \u001b[0;36mHolEnv.__init__\u001b[0;34m(self, goal)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess\u001b[38;5;241m.\u001b[39msendline(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mhelper.sml\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# self.process.sendline(\"val _ = load \\\"Timeout\\\";\")\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfiguration done.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess\u001b[38;5;241m.\u001b[39mexpect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "TARGET_THEORIES = [\"bool\"]\n",
    "GOALS = [(key, value[4]) for key, value in database.items() if value[3] == \"thm\" and value[0] in TARGET_THEORIES]\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "run_iteration(GOALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "overall-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_encoded_content(history, encoder):\n",
    "    # figure out why this is slower than tests\n",
    "    # figured out: remember to do strip().split()\n",
    "    fringe_sizes = []\n",
    "    contexts = []\n",
    "    reverted = []\n",
    "    for i in history:\n",
    "        c = i[\"content\"]\n",
    "        contexts.extend(c)\n",
    "        fringe_sizes.append(len(c))\n",
    "    for e in contexts:\n",
    "        g = revert_with_polish(e)\n",
    "        reverted.append(g.strip().split())\n",
    "    # print(reverted)\n",
    "    # s1 = timeit.default_timer()\n",
    "    out, sizes = encoder.encode(reverted)\n",
    "    # merge two hidden variables\n",
    "    representations = torch.cat(out.split(1), dim=2).squeeze(0)\n",
    "    # print(representations.shape)\n",
    "    # s2 = timeit.default_timer()    \n",
    "    # print(s2-s1)\n",
    "\n",
    "    return representations, contexts, fringe_sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "athletic-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-slide",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
