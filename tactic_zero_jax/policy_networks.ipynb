{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "alternate-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk\n",
    "import jax\n",
    "import optax\n",
    "from jax import random\n",
    "from jax import numpy as jnp\n",
    "from jax import jit\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "revised-crown",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define networks for agent as in torch implementation\n",
    "\n",
    "#should be given multiple encoded contexts (goals, assumptions) at once, so shape (batch, encoding_dim)\n",
    "\n",
    "class ContextPolicy(hk.Module):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)    \n",
    "        \n",
    "        #can make deeper as with Minchao's later models\n",
    "        self.fc = hk.Linear(512)\n",
    "        self.fc2 = hk.Linear(1024)\n",
    "        self.head = hk.Linear(1)\n",
    "        #no sigmoid?\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        x = jax.nn.relu(self.fc(x)) \n",
    "        x = jax.nn.relu(self.fc2(x)) \n",
    "        \n",
    "        x = self.head(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def _context_forward(x):\n",
    "    module = ContextPolicy()\n",
    "    return module(x)\n",
    "\n",
    "\n",
    "# from old code, takes in just a single context encoding. Should it also take in the state?\n",
    "\n",
    "class TacPolicy(hk.Module):\n",
    "    def __init__(self, tactic_size, name=None):\n",
    "        super().__init__(name=name)    \n",
    "    \n",
    "        self.fc = hk.Linear(512)\n",
    "        self.fc2 = hk.Linear(1024)\n",
    "\n",
    "        self.head = hk.Linear(tactic_size)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "\n",
    "        x = jax.nn.relu(self.fc(x)) \n",
    "        x = jax.nn.relu(self.fc2(x)) \n",
    "        x = jax.nn.softmax(self.head(x), axis=1) \n",
    "        \n",
    "        return x\n",
    "\n",
    "def _tac_forward(x, action_size):\n",
    "    module = TacPolicy(action_size)\n",
    "    return module(x)\n",
    "\n",
    "#called one sample at a time \n",
    "\n",
    "\n",
    "class ArgPolicy(hk.Module):\n",
    "    \n",
    "    #tactic_size is integer for number of possible tactics given by tactic_pool, embedding dim will match size of AE so they can stack\n",
    "    def __init__(self, tactic_size, embedding_dim, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.tactic_embeddings = hk.Embed(tactic_size, embedding_dim)\n",
    "    \n",
    "        self.lstm = hk.LSTM(embedding_dim)\n",
    "        self.fc = hk.Linear(512)\n",
    "        self.fc2 = hk.Linear(1024)\n",
    "        self.head = hk.Linear(1)\n",
    "\n",
    "    # x is the previously predicted argument / tactic.\n",
    "    # candidates is a matrix of possible arguments concatenated with the hidden states.\n",
    "\n",
    "    def __call__(self, x, candidates, hidden):\n",
    "        \n",
    "        #asserting x is integer  \n",
    "        #if x.shape == torch.Size([1]):\n",
    "            # x is a tactic\n",
    "            # print(\"good\")\n",
    "        x = jnp.expand_dims(self.tactic_embeddings(x), 0)\n",
    "        #else:\n",
    "        #    x = x\n",
    "        \n",
    "        #x = jnp.reshape(x, (1,-1))\n",
    "        \n",
    "        s = jax.nn.relu(self.fc(candidates)) \n",
    "        s = jax.nn.relu(self.fc2(s))\n",
    "        scores = self.head(s)\n",
    "        \n",
    "        o, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        return hidden, scores\n",
    "\n",
    "def _arg_forward(x, candidates, hidden, tactic_size, embedding_dim):#, init_state=None):\n",
    "    module = ArgPolicy(tactic_size, embedding_dim)\n",
    "    return module(x, candidates, hidden)\n",
    "\n",
    "\n",
    "class TermPolicy(hk.Module):\n",
    "    def __init__(self, tactic_size, embedding_dim, name=None):\n",
    "        super().__init__(name=name)  \n",
    "        \n",
    "        self.tactic_embeddings = hk.Embed(tactic_size, embedding_dim)\n",
    "        \n",
    "        self.fc = hk.Linear(512)\n",
    "        self.fc2 = hk.Linear(1024)\n",
    "        self.head = hk.Linear(1)\n",
    "\n",
    "    def __call__(self, candidates, tac):\n",
    "        #tac is just an index here, the embedding layer simplifies the one-hot \n",
    "        tac = self.tactic_embeddings(tac)#.view(1,-1)\n",
    "        \n",
    "        #concatenate the tactic to every candidate \n",
    "    \n",
    "        tac_tensor = jnp.stack([tac for _ in range(candidates.shape[0])], 1)\n",
    "        x  = jnp.concatenate([jnp.reshape(tac_tensor, candidates.shape), candidates], axis=1)\n",
    "    \n",
    "        x = jax.nn.relu(self.fc(x))\n",
    "        x = jax.nn.relu(self.fc2(x))\n",
    "        x = self.head(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "def _term_forward(candidates, tac, tactic_size, embedding_dim):\n",
    "    module = TermPolicy(tactic_size, embedding_dim)\n",
    "    return module(candidates, tac)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "offensive-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "init_context, apply_context = hk.transform(_context_forward)\n",
    "init_tac, apply_tac = hk.transform(_tac_forward)\n",
    "init_arg, apply_arg = hk.transform(_arg_forward)\n",
    "init_term, apply_term = hk.transform(_term_forward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "other-narrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key = random.PRNGKey(1009)\n",
    "\n",
    "batch_size = 10\n",
    "MAX_LEN = 256\n",
    "\n",
    "\n",
    "c_term = random.normal(rng_key, (6, MAX_LEN))\n",
    "\n",
    "x_tac = random.normal(rng_key, (1, MAX_LEN))\n",
    "\n",
    "#candidate network, shapes given from old repo. Matrix of encoded arguments\n",
    "\n",
    "c_arg = random.normal(rng_key, (8, MAX_LEN))\n",
    "\n",
    "#hidden dim size, will be set initialised as the target goal g \n",
    "h0 = random.normal(rng_key, (1,MAX_LEN))\n",
    "#initial state, will be initialised as chosen tactic t \n",
    "c0 = random.normal(rng_key, (1,MAX_LEN))\n",
    "\n",
    "init_state = hk.LSTMState(h0, c0)\n",
    "\n",
    "#arg takes int up to tac_size\n",
    "x_arg = 5\n",
    "\n",
    "x_context = random.normal(rng_key, (batch_size, 256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "excessive-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAC_SIZE = 10\n",
    "context_params = init_context(rng_key, x_context)\n",
    "tactic_params = init_tac(rng_key, x_tac, TAC_SIZE)\n",
    "arg_params = init_arg(rng_key, x_arg, c_arg, init_state, TAC_SIZE, MAX_LEN)\n",
    "term_params = init_term(rng_key, c_term, x_arg, TAC_SIZE, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "advisory-advisory",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_context = jax.jit(apply_context)\n",
    "apply_tac = partial(jax.jit, static_argnums=3)(apply_tac)\n",
    "apply_arg = partial(jax.jit, static_argnums=(5,6))(apply_arg)\n",
    "apply_term = partial(jax.jit, static_argnums=(4,5))(apply_term)\n",
    "\n",
    "\n",
    "out_context = apply_context(context_params, rng_key, x_context)\n",
    "out_tac = apply_tac(tactic_params, rng_key, x_tac, TAC_SIZE)\n",
    "out_arg = apply_arg(arg_params,  rng_key, x_arg, c_arg, init_state, TAC_SIZE, MAX_LEN)\n",
    "out_term = apply_term(term_params, rng_key,c_term, x_arg, TAC_SIZE, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "complimentary-honolulu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1) (1, 10) (8, 1) (6, 1)\n"
     ]
    }
   ],
   "source": [
    "print (out_context.shape,out_tac.shape, out_arg[1].shape, out_term.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "fatty-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#can multiply learning rate by reward for each update to give the policy gradient after grad of log probs is done \n",
    "context_lr = 1e-2\n",
    "tactic_lr = 1e-2 \n",
    "arg_lr = 1e-2\n",
    "term_lr = 1e-2\n",
    "\n",
    "context_optimiser = optax.rmsprop(context_lr)\n",
    "tactic_optimiser = optax.rmsprop(tactic_lr)\n",
    "arg_optimiser = optax.rmsprop(arg_lr)\n",
    "term_optimiser = optax.rmsprop(term_lr)\n",
    "\n",
    "opt_state_context = context_optimiser.init(context_params)\n",
    "opt_state_tactic = tactic_optimiser.init(tactic_params)\n",
    "opt_state_arg = arg_optimiser.init(arg_params)\n",
    "opt_state_term = term_optimiser.init(term_params)\n",
    "\n",
    "\n",
    "\n",
    "def compute_probs(params, net, *args):\n",
    "    probs = jax.nn.softmax(jnp.ravel(net(params,*args)))\n",
    "    logits = jnp.log(probs)\n",
    "    ind = random.categorical(rng_key, logits)\n",
    "    log_prob = logits[ind]\n",
    "    return log_prob\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "valued-means",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient example. May need to construct separate function for each net during training \n",
    "\n",
    "def compute_probs(params, net, *args):\n",
    "    probs = jax.nn.softmax(jnp.ravel(net(params,*args)))\n",
    "    logits = jnp.log(probs)\n",
    "    ind = random.categorical(rng_key, logits)\n",
    "    log_prob = logits[ind]\n",
    "    return log_prob\n",
    "\n",
    "grad = jax.grad(compute_probs)(term_params, apply_term, rng_key, c_term, x_arg,TAC_SIZE, MAX_LEN)\n",
    "\n",
    "updates, opt_state_term = term_optimiser.update(grad, opt_state_term)\n",
    "term_params = optax.apply_updates(term_params, updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "royal-reunion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'term_policy/~/embed': {'embeddings': DeviceArray([[0., 0., 0., ..., 0., 0., 0.],\n",
      "             [0., 0., 0., ..., 0., 0., 0.],\n",
      "             [0., 0., 0., ..., 0., 0., 0.],\n",
      "             ...,\n",
      "             [0., 0., 0., ..., 0., 0., 0.],\n",
      "             [0., 0., 0., ..., 0., 0., 0.],\n",
      "             [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}, 'term_policy/~/linear': {'b': DeviceArray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "             0., 0.], dtype=float32), 'w': DeviceArray([[nan, nan, nan, ..., nan, nan, nan],\n",
      "             [nan, nan, nan, ..., nan, nan, nan],\n",
      "             [nan, nan, nan, ..., nan, nan, nan],\n",
      "             ...,\n",
      "             [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "             [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "             [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)}, 'term_policy/~/linear_1': {'b': DeviceArray([0., 0., 0., ..., 0., 0., 0.], dtype=float32), 'w': DeviceArray([[nan, nan, nan, ..., nan, nan, nan],\n",
      "             [nan, nan, nan, ..., nan, nan, nan],\n",
      "             [nan, nan, nan, ..., nan, nan, nan],\n",
      "             ...,\n",
      "             [nan, nan, nan, ..., nan, nan, nan],\n",
      "             [nan, nan, nan, ..., nan, nan, nan],\n",
      "             [nan, nan, nan, ..., nan, nan, nan]], dtype=float32)}, 'term_policy/~/linear_2': {'b': DeviceArray([nan], dtype=float32), 'w': DeviceArray([[nan],\n",
      "             [nan],\n",
      "             [nan],\n",
      "             ...,\n",
      "             [nan],\n",
      "             [nan],\n",
      "             [nan]], dtype=float32)}}\n"
     ]
    }
   ],
   "source": [
    "# grads_test = grad\n",
    "\n",
    "# print (grads_test\n",
    "#       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-belly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-pierre",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
