{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sublime-nashville",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dependent-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seq2seq.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "announced-rebel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoencoder.py\t\tcheckpoint.py  __pycache__\ttemp.py\r\n",
      "autoencoder_test.ipynb\tmodels\t       pytorch-seq2seq\ttest.py\r\n",
      "batch_predictor.py\tpredictor.py   seq2seq\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "exterior-lover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['@', '@', 'Cmin$=', '@', '@', 'Cmin$=', '@', 'Clist$REVERSE', 'Vl', 'Clist$NIL', '@', '@', 'Cmin$=', 'Vl', 'Clist$NIL', '<eos>']]\n",
      "tensor([ 0.9227, -0.9994,  0.9012, -0.1492, -0.7326, -0.1064,  0.9871, -0.3356,\n",
      "        -0.2293, -0.1615,  0.9423, -0.9502, -0.4562,  0.9700,  0.3955,  0.1864,\n",
      "         0.2855, -0.7346,  0.6362, -0.3392,  0.9620, -0.3084,  0.7971,  0.6478,\n",
      "         0.7215, -0.8193, -0.1357, -0.2715,  0.7896, -0.4495,  0.7842, -0.8479,\n",
      "         0.5934, -0.8262, -0.0249,  0.1982,  0.5330, -0.9736,  0.2923,  0.1848,\n",
      "        -0.2433, -0.6897,  0.9870, -0.9894, -0.8268,  0.9557, -0.2367, -0.3137,\n",
      "         0.3133, -0.3285,  0.1337,  0.7346,  0.6674, -0.7748,  0.9517, -0.3573,\n",
      "         0.1711, -0.9966,  0.6222,  0.9682,  0.0441, -0.0091, -0.6403, -0.4003,\n",
      "        -0.6224, -0.1272, -0.1120, -0.7380,  0.9291,  0.9387,  0.2281,  0.5093,\n",
      "        -0.9825,  0.2802,  0.0792, -0.8104,  0.9210, -0.8724, -0.0052,  0.6844,\n",
      "         0.2957,  0.2354,  0.1477,  0.9221, -0.8610, -0.7140,  0.3618, -0.4524,\n",
      "        -0.9166,  0.7865,  0.4989, -0.0042,  0.3476,  0.2339,  0.6870, -0.7854,\n",
      "        -0.0088, -0.3457,  0.9976, -0.0568,  0.9881, -0.9419, -0.9735, -0.1519,\n",
      "        -0.1459,  0.1296,  0.8713, -0.0138, -0.6549,  0.8391, -0.9821, -0.7633,\n",
      "        -0.8492, -0.0825, -0.8203,  0.7728, -0.1294, -0.1137, -0.9849,  0.9917,\n",
      "         0.9618, -0.8965, -0.6334,  0.9648,  0.6115, -0.9926,  0.2345,  0.9257,\n",
      "         0.4439, -0.8677,  0.0444,  0.8018,  0.2726,  0.0902,  0.5515, -0.3182,\n",
      "        -0.0532, -0.3999,  0.0918, -0.2693, -0.4815,  0.4827, -0.0040, -1.0000,\n",
      "        -0.2258,  0.2222, -0.2926,  0.0833,  0.1504,  0.1607, -0.2918, -0.3588,\n",
      "         0.2481,  0.0812, -0.1652,  0.0267,  0.1465, -0.7104, -0.1096, -0.6374,\n",
      "         0.0100, -0.2867,  0.5463, -0.1401, -0.1431, -0.5445,  0.8628,  0.2834,\n",
      "        -0.0217, -0.3442, -0.2911,  0.3486,  0.6323,  0.0602,  0.0970, -0.2371,\n",
      "         0.9226,  0.0073,  0.6664,  0.9976, -0.1169,  0.3535,  0.1392, -0.3400,\n",
      "         0.0334, -0.6320,  0.0332, -0.3437,  0.1553,  0.1365, -0.1177, -0.1027,\n",
      "         0.5583,  0.9009,  0.3503, -0.0105,  0.7595,  0.2149,  0.7173, -0.9893,\n",
      "         0.0229,  0.5473, -0.0207, -0.1167, -0.4486, -0.3534,  0.0596, -0.2955,\n",
      "        -0.2569,  0.3444,  0.4826, -0.1697,  0.2085,  0.7599,  0.8302,  0.1238,\n",
      "        -0.2275, -0.3232, -0.1568, -0.9914, -0.3930, -0.2307,  0.5758, -0.2299,\n",
      "        -0.0482, -0.3381,  0.8677,  0.5138,  0.2677,  0.0363, -0.2935,  0.5515,\n",
      "        -0.6408,  0.0227,  0.2318, -0.5621, -0.2191,  0.2834, -0.7392,  0.1674,\n",
      "         0.2515, -0.0218,  0.0018, -0.4845, -0.2716,  0.0691, -0.2495,  0.6860,\n",
      "         0.3261,  0.1745, -0.3254, -0.2288, -0.4305, -0.3068,  0.1969,  0.9061])\n",
      "torch.Size([256])\n",
      "tensor([[[ 0.9227, -0.9994,  0.9012, -0.1492, -0.7326, -0.1064,  0.9871,\n",
      "          -0.3356, -0.2293, -0.1615,  0.9423, -0.9502, -0.4562,  0.9700,\n",
      "           0.3955,  0.1864,  0.2855, -0.7346,  0.6362, -0.3392,  0.9620,\n",
      "          -0.3084,  0.7971,  0.6478,  0.7215, -0.8193, -0.1357, -0.2715,\n",
      "           0.7896, -0.4495,  0.7842, -0.8479,  0.5934, -0.8262, -0.0249,\n",
      "           0.1982,  0.5330, -0.9736,  0.2923,  0.1848, -0.2433, -0.6897,\n",
      "           0.9870, -0.9894, -0.8268,  0.9557, -0.2367, -0.3137,  0.3133,\n",
      "          -0.3285,  0.1337,  0.7346,  0.6674, -0.7748,  0.9517, -0.3573,\n",
      "           0.1711, -0.9966,  0.6222,  0.9682,  0.0441, -0.0091, -0.6403,\n",
      "          -0.4003, -0.6224, -0.1272, -0.1120, -0.7380,  0.9291,  0.9387,\n",
      "           0.2281,  0.5093, -0.9825,  0.2802,  0.0792, -0.8104,  0.9210,\n",
      "          -0.8724, -0.0052,  0.6844,  0.2957,  0.2354,  0.1477,  0.9221,\n",
      "          -0.8610, -0.7140,  0.3618, -0.4524, -0.9166,  0.7865,  0.4989,\n",
      "          -0.0042,  0.3476,  0.2339,  0.6870, -0.7854, -0.0088, -0.3457,\n",
      "           0.9976, -0.0568,  0.9881, -0.9419, -0.9735, -0.1519, -0.1459,\n",
      "           0.1296,  0.8713, -0.0138, -0.6549,  0.8391, -0.9821, -0.7633,\n",
      "          -0.8492, -0.0825, -0.8203,  0.7728, -0.1294, -0.1137, -0.9849,\n",
      "           0.9917,  0.9618, -0.8965, -0.6334,  0.9648,  0.6115, -0.9926,\n",
      "           0.2345,  0.9257]],\n",
      "\n",
      "        [[ 0.4439, -0.8677,  0.0444,  0.8018,  0.2726,  0.0902,  0.5515,\n",
      "          -0.3182, -0.0532, -0.3999,  0.0918, -0.2693, -0.4815,  0.4827,\n",
      "          -0.0040, -1.0000, -0.2258,  0.2222, -0.2926,  0.0833,  0.1504,\n",
      "           0.1607, -0.2918, -0.3588,  0.2481,  0.0812, -0.1652,  0.0267,\n",
      "           0.1465, -0.7104, -0.1096, -0.6374,  0.0100, -0.2867,  0.5463,\n",
      "          -0.1401, -0.1431, -0.5445,  0.8628,  0.2834, -0.0217, -0.3442,\n",
      "          -0.2911,  0.3486,  0.6323,  0.0602,  0.0970, -0.2371,  0.9226,\n",
      "           0.0073,  0.6664,  0.9976, -0.1169,  0.3535,  0.1392, -0.3400,\n",
      "           0.0334, -0.6320,  0.0332, -0.3437,  0.1553,  0.1365, -0.1177,\n",
      "          -0.1027,  0.5583,  0.9009,  0.3503, -0.0105,  0.7595,  0.2149,\n",
      "           0.7173, -0.9893,  0.0229,  0.5473, -0.0207, -0.1167, -0.4486,\n",
      "          -0.3534,  0.0596, -0.2955, -0.2569,  0.3444,  0.4826, -0.1697,\n",
      "           0.2085,  0.7599,  0.8302,  0.1238, -0.2275, -0.3232, -0.1568,\n",
      "          -0.9914, -0.3930, -0.2307,  0.5758, -0.2299, -0.0482, -0.3381,\n",
      "           0.8677,  0.5138,  0.2677,  0.0363, -0.2935,  0.5515, -0.6408,\n",
      "           0.0227,  0.2318, -0.5621, -0.2191,  0.2834, -0.7392,  0.1674,\n",
      "           0.2515, -0.0218,  0.0018, -0.4845, -0.2716,  0.0691, -0.2495,\n",
      "           0.6860,  0.3261,  0.1745, -0.3254, -0.2288, -0.4305, -0.3068,\n",
      "           0.1969,  0.9061]]])\n",
      "0.003758118997211568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'seq2seq.models.EncoderRNN.EncoderRNN' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.GRU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'seq2seq.models.DecoderRNN.DecoderRNN' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/sean/Documents/venvs/jax/lib/python3.9/site-packages/torch/nn/functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import timeit\n",
    "import torch\n",
    "\n",
    "#from seq2seq.evaluator import BatchPredictor\n",
    "#from seq2seq.util.checkpoint import Checkpoint\n",
    "\n",
    "from batch_predictor import BatchPredictor\n",
    "from checkpoint import Checkpoint\n",
    "\n",
    "# Load models directly because the package is installed\n",
    "#\n",
    "#checkpoint_path = \"models/2020_04_22_20_36_50\" # 91% accuracy model, only core theories\n",
    "checkpoint_path = \"models/2020_04_26_20_11_28\" # 95% accuracy model, core theories + integer + sorting\n",
    "#checkpoint_path = \"models/2020_09_24_23_38_06\" # 98% accuracy model, core theories + integer + sorting | separate theory tokens\n",
    "# checkpoint_path = \"autoencoder/models/2020_11_28_16_45_10\" # 96-98% accuracy model, core theories + integer + sorting + real | separate theory tokens\n",
    "\n",
    "#checkpoint_path = \"models/2020_12_04_03_47_22\" # 97% accuracy model, core theories + integer + sorting + real + bag | separate theory tokens\n",
    "\n",
    "################## \n",
    "#checkpoint_path = \"models/2021_02_21_15_46_04\" # 98% accuracy model, up to probability theory\n",
    "\n",
    "#heckpoint_path = \"models/2021_02_22_16_07_03\" # 97-98% accuracy model, up to and include probability theory\n",
    "\n",
    "# logging.info(\"loading checkpoint from {}\".format(checkpoint_path))\n",
    "\n",
    "checkpoint = Checkpoint.load(checkpoint_path)\n",
    "seq2seq = checkpoint.model\n",
    "input_vocab = checkpoint.input_vocab\n",
    "output_vocab = checkpoint.output_vocab\n",
    "\n",
    "batch_encoder = BatchPredictor(seq2seq, input_vocab, output_vocab)\n",
    "\n",
    "predictor = BatchPredictor(seq2seq, input_vocab, output_vocab)\n",
    "\n",
    "seqs = ['@ C$bool$ ! | Vs @ @ C$min$ = @ @ C$pred_set$ SUBSET C$pred_set$ UNIV Vs @ @ C$min$ = Vs C$pred_set$ UNIV']#[\"@ @ Cmin$= CConseqConv$ASM_MARKER | Vy | Vx Vx\", \"@ @ Cmin$= CConseqConv$ASM_MARKER | Vy | Vy Vt\", \"@ Cbool$! | Vh1 @ Cbool$! | Vh2 @ @ Cmin$==> @ Cbool$~ @ @ Cmin$= Vh1 Vh2 @ Cbool$! | Vl1 @ Cbool$! | Vl2 @ Cbool$~ @ @ Cmin$= @ @ Clist$CONS Vh1 Vl1 @ @ Clist$CONS Vh2 Vl2\",\"@ Cbool$! | Vh1 @ Cbool$! | Vh2 @ @ Cmin$==> @ Cbool$~ @ @ Cmin$= Vh1 Vh2 @ Cbool$! | Vl1 @ Cbool$! | Vl2 @ Cbool$~ @ @ Cmin$= @ @ Clist$CONS Vh1 Vl1 @ @ Clist$CONS Vh2 Vl2\",\"@ Cbool$! | Vh1 @ Cbool$! | Vh2 @ @ Cmin$==> @ Cbool$~ @ @ Cmin$= Vh1 Vh2 @ Cbool$! | Vl1 @ Cbool$! | Vl2 @ Cbool$~ @ @ Cmin$= @ @ Clist$CONS Vh1 Vl1 @ @ Clist$CONS Vh2 Vl2\"]\n",
    "\n",
    "#seqs = [\"@ Cbool$~ @ @ @ Clist$SHORTLEX VR Vl Clist$NIL\"]\n",
    "seqs = [['@', '@', 'Cmin$=', '@', '@', 'Cmin$=', '@', 'Clist$REVERSE', 'Vl', 'Clist$NIL', '@', '@', 'Cmin$=', 'Vl', 'Clist$NIL']]#, \n",
    "# ['@', '@', 'Cmin$=', '@', '@', 'Cmin$=', '@', 'Clist$REVERSE', 'Clist$NIL', 'Clist$NIL', '@', '@', 'Cmin$=', 'Clist$NIL', 'Clist$NIL'], \n",
    " #['@', '@', 'Dmin$==>', '@', '@', 'Cmin$=', '@', '@', 'Cmin$=', '@', 'Clist$REVERSE', 'Vl', 'Clist$NIL', '@', '@', 'Cmin$=', 'Vl', 'Clist$NIL', '@', 'Cbool$!', '|', 'Vh', '@', '@', 'Cmin$=', '@', '@', 'Cmin$=', '@', 'Clist$REVERSE', '@', '@', 'Clist$CONS', 'Vh', 'Vl', 'Clist$NIL', '@', '@', 'Cmin$=', '@', '@', 'Clist$CONS', 'Vh', 'Vl', 'Clist$NIL'], ['@', '@', 'Dmin$==>', '@', '@', 'Cmin$=', '@', '@', 'Cmin$=', '@', 'Clist$REVERSE', 'Vl', 'Clist$NIL', '@', '@', 'Cmin$=', 'Vl', 'Clist$NIL', '@', 'Cbool$!', '|', 'Vh', '@', '@', 'Cmin$=', '@', '@', 'Cmin$=', '@', 'Clist$REVERSE', '@', '@', 'Clist$CONS', 'Vh', 'Vl', 'Clist$NIL', '@', '@', 'Cmin$=', '@', '@', 'Clist$CONS', 'Vh', 'Vl', 'Clist$NIL']]\n",
    "\n",
    "\n",
    "\n",
    "#seqs = [i.strip().split() for i in seqs]\n",
    "\n",
    "# relatively fast encoder: 2~5ms a batch\n",
    "# compared to HOL's 0.1s time limit of tactic execution, encoding is not a bottleneck now\n",
    "\n",
    "print(batch_encoder.predict(seqs))\n",
    "\n",
    "s1 = timeit.default_timer()\n",
    "\n",
    "# size: (2 [by default bidirectional], batch_num, hidden_length)\n",
    "out, sizes = batch_encoder.encode(seqs)\n",
    "representation = torch.cat(out.split(1), dim=2).squeeze()\n",
    "print(representation)\n",
    "print(representation.shape)\n",
    "print(out)\n",
    "\n",
    "s2 = timeit.default_timer()\n",
    "print(s2-s1)\n",
    "\n",
    "\n",
    "#s1 = timeit.default_timer()\n",
    "# out, sizes = batch_encoder.encode([\"@ Cbool$! | Vh1 @ Cbool$! | Vh2 @ @ Cmin$==> @ Cbool$~ @ @ Cmin$= Vh1 Vh2 @ Cbool$! | Vl1 @ Cbool$! | Vl2 @ Cbool$~ @ @ Cmin$= @ @ Clist$CONS Vh1 Vl1 @ @ Clist$CONS Vh2 Vl2\"])\n",
    "\n",
    "# out, sizes = batch_encoder.encode([\"@ Cbool$! | Vh1 @ Cbool$! | Vh2 @ @ Cmin$==> @ Cbool$~ @ @ Cmin$= Vh1 Vh2 @ Cbool$! | Vl1 @ Cbool$! | Vl2 @ Cbool$~ @ @ Cmin$= @ @ Clist$CONS Vh1 Vl1 @ @ Clist$CONS Vh2 Vl2\".strip().split()])\n",
    "\n",
    "# # merge two hidden variables\n",
    "# representations = torch.cat(out.split(1), dim=2).squeeze(0)\n",
    "# print(representations)\n",
    "# # print(representations.shape)\n",
    "# s2 = timeit.default_timer()    \n",
    "# print(s2-s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "weighted-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq2seq.decoder.use_attention = False\n",
    "# dec = seq2seq.decoder(None, out, representations)[2]# representations))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
