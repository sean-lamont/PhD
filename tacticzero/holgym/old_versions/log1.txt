Python 3.7.3 (default, Mar 27 2019, 22:11:17) 
[GCC 7.3.0] :: Anaconda, Inc. on linux
Type "help", "copyright", "credits" or "license" for more information.
>>> python.el: native completion setup loaded
>>> 
Importing theories...
Removing simp lemmas...
Loading modules...
Configuration done.
Initialization done. Main goal is:
∀l1 l2 P P'. l1 = l2 ∧ (∀x. MEM x l2 ⇒ (P x ⇔ P' x)) ⇒ (EXISTS P l1 ⇔ EXISTS P' l2).
Game: 0
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'metis_tac', 'fs', 'metis_tac', 'Induct_on', 'Induct_on', 'metis_tac', 'simp', 'fs', 'simp', 'metis_tac', 'simp', 'Induct_on', 'strip_tac', 'metis_tac', 'simp', 'simp', 'Induct_on', 'Induct_on', 'strip_tac', 'strip_tac', 'metis_tac', 'strip_tac', 'fs', 'simp', 'metis_tac', 'simp', 'Induct_on', 'fs', 'metis_tac', 'simp', 'simp', 'metis_tac', 'simp', 'simp', 'simp', 'metis_tac', 'Induct_on', 'Induct_on', 'fs', 'simp', 'fs', 'fs', 'strip_tac', 'metis_tac', 'simp', 'metis_tac', 'fs', 'Induct_on', 'Induct_on', 'fs']
Total: -35
Time: 27.817389574000003  
Induct args: ['Cbool$!', 'Cmin$=', '@', '@', '@', '@', 'Vl2', 'Vx', '@', '@']
Preferences: tensor([0.2744, 0.1845, 0.1934, 0.1921, 0.1556])
Proved so far: 0

Game: 1
Initialization done. Main goal is:
∀P l. ¬EXISTS P l ⇔ EVERY ($~ ∘ P) l.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[INDEX_FIND_def, FILTER, OPT_MMAP_def, REVERSE_DEF, UNIQUE_DEF]', '∀P l. ¬EXISTS P l ⇔ EVERY ($~ ∘ P) l')]
Time: 0.5078199579999989  
Induct args: []
Preferences: tensor([0.1756, 0.5196, 0.0844, 0.0963, 0.1242])
Proved so far: 1

Game: 2
Initialization done. Main goal is:
GENLIST f 0 = [] ∧ GENLIST f (NUMERAL n) = GENLIST_AUX f (NUMERAL n) [].
Failed.
Rewards: [-1, 1, 1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['Induct_on', 'Induct_on', 'fs', 'fs', 'simp', 'fs', 'Induct_on', 'strip_tac', 'Induct_on', 'Induct_on', 'simp', 'Induct_on', 'fs', 'Induct_on', 'strip_tac', 'simp', 'fs', 'fs', 'fs', 'Induct_on', 'Induct_on', 'Induct_on', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'strip_tac', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'strip_tac', 'simp', 'Induct_on', 'fs', 'fs', 'Induct_on', 'fs', 'Induct_on', 'fs', 'metis_tac', 'fs', 'fs', 'simp', 'Induct_on', 'fs']
Total: -41
Time: 18.81941087300001  
Induct args: ['Clist$GENLIST', 'Clist$NIL', '@', '@', 'Cmin$=', '@', '@', '@', '@', '@', 'Vf', 'Carithmetic$NUMERAL', '@', 'Clist$GENLIST', '@', '@']
Preferences: tensor([0.1509, 0.5547, 0.0577, 0.0711, 0.1655])
Proved so far: 1

Game: 3
Initialization done. Main goal is:
∀P l. ¬EVERY P l ⇔ EXISTS ($~ ∘ P) l.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[SNOC, FOLDL, EL, PAD_LEFT, nub_def]', '∀P l. ¬EVERY P l ⇔ EXISTS ($~ ∘ P) l')]
Time: 0.503696352999981  
Induct args: []
Preferences: tensor([0.0459, 0.8224, 0.0327, 0.0580, 0.0410])
Proved so far: 2

Game: 4
Initialization done. Main goal is:
∀ts tt n. n < MIN (LENGTH ts) (LENGTH tt) ⇒ EL n (MAP2 f ts tt) = f (EL n ts) (EL n tt).
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.371993095999983  
Induct args: []
Preferences: tensor([0.0264, 0.8948, 0.0210, 0.0367, 0.0211])
Proved so far: 2

Game: 5
Initialization done. Main goal is:
∀h l1 l2. LAST (l1 ++ h::l2) = LAST (h::l2).
Failed.
Rewards: [1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'metis_tac', 'Induct_on', 'fs', 'metis_tac', 'Induct_on', 'Induct_on', 'simp', 'fs', 'Induct_on', 'metis_tac', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'simp', 'metis_tac', 'strip_tac', 'fs', 'Induct_on', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'simp', 'Induct_on', 'fs', 'fs', 'fs', 'fs']
Total: -37
Time: 24.560668846  
Induct args: ['|', 'Clist$NIL', '@', '|', 'Clist$CONS', 'Vl1']
Preferences: tensor([0.0919, 0.7202, 0.0365, 0.0976, 0.0537])
Proved so far: 2

Game: 6
Initialization done. Main goal is:
∀P l1 l2. EXISTS ($~ ∘ P) l1 ⇒ dropWhile P (l1 ++ l2) = dropWhile P l1 ++ l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'simp', 'fs', 'simp', 'metis_tac', 'fs', 'fs', 'fs', 'simp', 'fs', 'Induct_on', 'fs', 'fs', 'strip_tac', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'strip_tac', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'Induct_on']
Total: -35
Time: 23.139109278000035  
Induct args: ['Vl1', '@']
Preferences: tensor([0.0746, 0.8281, 0.0402, 0.0321, 0.0251])
Proved so far: 2

Game: 7
Initialization done. Main goal is:
∀e L. UNIQUE e L ⇔ LENGTH (FILTER ($= e) L) = 1.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -47
Time: 22.411672871999997  
Induct args: []
Preferences: tensor([0.0455, 0.8383, 0.0343, 0.0292, 0.0527])
Proved so far: 2

Game: 8
Initialization done. Main goal is:
LIST_BIND l (λx. x) = FLAT l ∧ LIST_BIND l I = FLAT l.
Failed.
Rewards: [-1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.924451852000004  
Induct args: ['Clist$FLAT']
Preferences: tensor([0.0106, 0.9508, 0.0096, 0.0157, 0.0134])
Proved so far: 2

Game: 9
Initialization done. Main goal is:
(∀x. P x ⇒ Q x) ⇒ EVERY P l ⇒ EVERY Q l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.479688418000023  
Induct args: ['VQ', '@', '@']
Preferences: tensor([0.0207, 0.8453, 0.0402, 0.0382, 0.0556])
Proved so far: 2

Game: 10
Initialization done. Main goal is:
∀l f. (MAP f l = [] ⇔ l = []) ∧ ([] = MAP f l ⇔ l = []).
Proved in 4 steps.
Rewards: [1, -1, -1, 10]
Tactics: ['strip_tac', 'Induct_on', 'metis_tac', 'fs']
Total: 9
Proof trace: [('strip_tac', '∀l f. (MAP f l = [] ⇔ l = []) ∧ ([] = MAP f l ⇔ l = [])'), ('fs[FLAT, LIST_APPLY_def, SHORTLEX_def, ALL_DISTINCT, LEN_DEF]', '∀f. (MAP f l = [] ⇔ l = []) ∧ ([] = MAP f l ⇔ l = [])')]
Time: 2.3682093730000133  
Induct args: ['Cmin$=']
Preferences: tensor([0.0403, 0.8004, 0.0396, 0.0247, 0.0950])
Proved so far: 3

Game: 11
Initialization done. Main goal is:
∀l1 l2 P. LENGTH l1 = LENGTH l2 ⇒ (EVERY (λx. P (SND x)) (ZIP (l1,l2)) ⇔ EVERY P l2).
Failed.
Rewards: [-1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'simp', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -45
Time: 23.396113084000035  
Induct args: []
Preferences: tensor([0.0193, 0.9235, 0.0206, 0.0238, 0.0128])
Proved so far: 3

Game: 12
Initialization done. Main goal is:
∀ls f. EVERY (λx. ∃y. x = f y) ls ⇒ ∃l. ls = MAP f l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on']
Total: -51
Time: 21.946439709000003  
Induct args: ['Vl']
Preferences: tensor([0.0041, 0.9678, 0.0063, 0.0084, 0.0134])
Proved so far: 3

Game: 13
Initialization done. Main goal is:
∀l. ALL_DISTINCT l ⇔ ∀n1 n2. n1 < LENGTH l ∧ n2 < LENGTH l ⇒ (EL n1 l = EL n2 l ⇔ n1 = n2).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1]
Tactics: ['fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'metis_tac', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'metis_tac', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'metis_tac', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs']
Total: -47
Time: 22.871437307999997  
Induct args: ['@', '@', 'Cbool$!', '@', 'Vl']
Preferences: tensor([0.0192, 0.8625, 0.0162, 0.0375, 0.0646])
Proved so far: 3

Game: 14
Initialization done. Main goal is:
∀L1 L2. REV L1 L2 = REVERSE L1 ++ L2.
Proved in 21 steps.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 1, -1, 10]
Tactics: ['fs', 'fs', 'Induct_on', 'fs', 'Induct_on', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: 0
Proof trace: [('fs[FRONT_DEF, SUM, UNIQUE_DEF, REVERSE_DEF, LIST_BIND_def]', '∀L1 L2. REV L1 L2 = REVERSE L1 ++ L2'), ('Induct_on `L1`', '∀L1 L2. REV L1 L2 = REVERSE L1 ⧺ L2'), ('fs[PAD_RIGHT, LLEX_def, nub_def, UNIQUE_DEF, TL_DEF]', '∀L2. REV [] L2 = REVERSE [] ⧺ L2'), ('rpt strip_tac >> fs[LENGTH, SET_TO_LIST_primitive_def, INDEX_FIND_def, list_size_def, LIST_BIND_def]', '(∀L2. REV L1 L2 = REVERSE L1 ⧺ L2) ==> (∀h L2. REV (h::L1) L2 = REVERSE (h::L1) ⧺ L2)'), ('fs[FRONT_DEF, isPREFIX, REV_DEF, UNIQUE_DEF, LIST_APPLY_def]', '∀L2. REV [] L2 = L2'), ('rpt strip_tac >> fs[TL_DEF, EXISTS_DEF, REV_DEF, SHORTLEX_def, list_TY_DEF]', '(∀L2. REV L1 L2 = REVERSE L1 ⧺ L2) ==> (REV (h::L1) L2 = REVERSE L1 ⧺ [h] ⧺ L2)')]
Time: 8.168604079000033  
Induct args: ['@', '@', 'VL1']
Preferences: tensor([0.0097, 0.9517, 0.0068, 0.0126, 0.0192])
Proved so far: 4

Game: 15
Initialization done. Main goal is:
∀l1 x l2. EL (LENGTH l1) (l1 ++ [x] ++ l2) = x.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.46342481800002  
Induct args: []
Preferences: tensor([0.0038, 0.9767, 0.0046, 0.0065, 0.0085])
Proved so far: 4

Game: 16
Initialization done. Main goal is:
(¬LLEX R [] [] ∧ ¬LLEX R (h1::t1) []) ∧ LLEX R [] (h2::t2) ∧ (LLEX R (h1::t1) (h2::t2) ⇔ R h1 h2 ∨ h1 = h2 ∧ LLEX R t1 t2).
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[EXISTS_DEF, nub_def, oEL_def, LIST_TO_SET_DEF, list_case_def]', '(¬LLEX R [] [] ∧ ¬LLEX R (h1::t1) []) ∧ LLEX R [] (h2::t2) ∧ (LLEX R (h1::t1) (h2::t2) ⇔ R h1 h2 ∨ h1 = h2 ∧ LLEX R t1 t2)')]
Time: 0.5058967990000269  
Induct args: []
Preferences: tensor([0.0016, 0.9839, 0.0031, 0.0031, 0.0084])
Proved so far: 5

Game: 17
Initialization done. Main goal is:
(∀f. MAP2 f [] [] = []) ∧ ∀f h1 t1 h2 t2. MAP2 f (h1::t1) (h2::t2) = f h1 h2::MAP2 f t1 t2.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[TAKE_def, UNZIP, OPT_MMAP_def, SET_TO_LIST_primitive_def, LIST_APPLY_def]', '(∀f. MAP2 f [] [] = []) ∧ ∀f h1 t1 h2 t2. MAP2 f (h1::t1) (h2::t2) = f h1 h2::MAP2 f t1 t2')]
Time: 0.5075785950000409  
Induct args: []
Preferences: tensor([0.0013, 0.9774, 0.0037, 0.0039, 0.0138])
Proved so far: 6

Game: 18
Initialization done. Main goal is:
∀ls f. (∀x y. MEM x ls ∧ MEM y ls ∧ f x = f y ⇒ x = y) ∧ ALL_DISTINCT ls ⇒ ALL_DISTINCT (MAP f ls).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.51806548899998  
Induct args: []
Preferences: tensor([0.0033, 0.9724, 0.0065, 0.0060, 0.0119])
Proved so far: 6

Game: 19
Initialization done. Main goal is:
∀m n l. m + n < LENGTH l ⇒ EL m (DROP n l) = EL (m + n) l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.08598835800001  
Induct args: []
Preferences: tensor([0.0018, 0.9856, 0.0038, 0.0028, 0.0061])
Proved so far: 6

Game: 20
Initialization done. Main goal is:
l1 ++ [e] ++ l2 = m1 ++ m2 ⇔ (∃l. m1 = l1 ++ [e] ++ l ∧ l2 = l ++ m2) ∨ ∃l. l1 = m1 ++ l ∧ m2 = l ++ [e] ++ l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.356758538999998  
Induct args: []
Preferences: tensor([0.0025, 0.9803, 0.0049, 0.0047, 0.0077])
Proved so far: 6

Game: 21
Initialization done. Main goal is:
∀P L M. FILTER P (L ++ M) = FILTER P L ++ FILTER P M.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.916557964999924  
Induct args: []
Preferences: tensor([5.3078e-04, 9.9568e-01, 1.1209e-03, 1.0519e-03, 1.6157e-03])
Proved so far: 6

Game: 22
Initialization done. Main goal is:
([] ≼ l ⇔ T) ∧ (h::t ≼ [] ⇔ F) ∧ (h1::t1 ≼ h2::t2 ⇔ h1 = h2 ∧ t1 ≼ t2).
Proved in 25 steps.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 10]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -12
Proof trace: [('fs[PAD_LEFT, TAKE_def, list_case_def, LENGTH, FOLDL]', '([] ≼ l ⇔ T) ∧ (h::t ≼ [] ⇔ F) ∧ (h1::t1 ≼ h2::t2 ⇔ h1 = h2 ∧ t1 ≼ t2)'), ('fs[LLEX_def, INDEX_OF_def, splitAtPki_def, isPREFIX, INDEX_FIND_def]', '[] ≼ l ∧ (h1::t1 ≼ h2::t2 ⇔ h1 = h2 ∧ t1 ≼ t2)')]
Time: 10.121665155999949  
Induct args: []
Preferences: tensor([0.0016, 0.9871, 0.0023, 0.0028, 0.0062])
Proved so far: 7

Game: 23
Initialization done. Main goal is:
∀n l. n < LENGTH l ⇒ TAKE 1 (DROP n l) = [EL n l].
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 22.560505110999998  
Induct args: ['@']
Preferences: tensor([0.0011, 0.9895, 0.0020, 0.0021, 0.0053])
Proved so far: 7

Game: 24
Importing theories...
Removing simp lemmas...
Loading modules...
Configuration done.
Initialization done. Main goal is:
∀l. ALL_DISTINCT l ⇔ ∀n1 n2. n1 < LENGTH l ∧ n2 < LENGTH l ⇒ (EL n1 l = EL n2 l ⇔ n1 = n2).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 25.891061619000084  
Induct args: []
Preferences: tensor([4.6497e-04, 9.9720e-01, 1.0824e-03, 5.4630e-04, 7.0151e-04])
Proved so far: 7

Game: 25
Initialization done. Main goal is:
∀l1 l1'. LENGTH l1 = LENGTH l1' ⇒ ∀l2 l2'. LENGTH l2 = LENGTH l2' ⇒ (l1 ++ l2 = l1' ++ l2' ⇔ l1 = l1' ∧ l2 = l2').
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.041255617000047  
Induct args: ["Vl2'"]
Preferences: tensor([0.0025, 0.9729, 0.0090, 0.0057, 0.0100])
Proved so far: 7

Game: 26
Initialization done. Main goal is:
∀P l. ALL_DISTINCT l ⇒ ALL_DISTINCT (FILTER P l).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.754213548999928  
Induct args: ['@']
Preferences: tensor([0.0096, 0.9376, 0.0213, 0.0145, 0.0171])
Proved so far: 7

Game: 27
Initialization done. Main goal is:
f (splitAtPki P k l) = splitAtPki P ($o f ∘ k) l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.044388951999963  
Induct args: []
Preferences: tensor([0.0010, 0.9868, 0.0036, 0.0030, 0.0055])
Proved so far: 7

Game: 28
Initialization done. Main goal is:
∀ls. ls ≠ [] ⇒ MAP f (FRONT ls) = FRONT (MAP f ls).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.935194996000064  
Induct args: []
Preferences: tensor([0.0016, 0.9835, 0.0048, 0.0045, 0.0056])
Proved so far: 7

Game: 29
Initialization done. Main goal is:
LAST (h::t) = if t = [] then h else LAST t.
Proved in 16 steps.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 10]
Tactics: ['fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -5
Proof trace: [('fs[LAST_DEF, SHORTLEX_def, APPEND, splitAtPki_def, SNOC]', 'LAST (h::t) = if t = [] then h else LAST t')]
Time: 6.393112852000058  
Induct args: []
Preferences: tensor([0.0027, 0.9742, 0.0060, 0.0068, 0.0102])
Proved so far: 8

Game: 30
Initialization done. Main goal is:
∀xs ys xs1 ys1 f. LENGTH xs = LENGTH xs1 ⇒ MAP2 f (xs ++ ys) (xs1 ++ ys1) = MAP2 f xs xs1 ++ MAP2 f ys ys1.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.23008356999992  
Induct args: ['@']
Preferences: tensor([3.4255e-04, 9.9575e-01, 1.9189e-03, 9.3905e-04, 1.0486e-03])
Proved so far: 8

Game: 31
Initialization done. Main goal is:
LIST_BIND (MAP f l) g = LIST_BIND l (g ∘ f).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.33457470099995  
Induct args: []
Preferences: tensor([1.8143e-04, 9.9721e-01, 6.9982e-04, 7.5248e-04, 1.1516e-03])
Proved so far: 8

Game: 32
Initialization done. Main goal is:
l1 ++ [e] ++ l2 = m1 ++ m2 ⇔ (∃l. m1 = l1 ++ [e] ++ l ∧ l2 = l ++ m2) ∨ ∃l. l1 = m1 ++ l ∧ m2 = l ++ [e] ++ l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.342864938000048  
Induct args: []
Preferences: tensor([4.6309e-04, 9.9625e-01, 1.3200e-03, 1.2007e-03, 7.6450e-04])
Proved so far: 8

Game: 33
Initialization done. Main goal is:
[f] <*> [x] = [f x].
Proved in 50 steps.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 10]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -33
Proof trace: [('fs[LENGTH, LIST_GUARD_def, INDEX_OF_def, LEN_DEF, LIST_APPLY_def]', '[f] <*> [x] = [f x]'), ('fs[LIST_IGNORE_BIND_def, LIST_IGNORE_BIND_def, nub_def, EVERYi_def, LIST_BIND_def]', 'LIST_BIND [f] (combin$C MAP [x]) = [f x]'), ('fs[dropWhile_def, LIST_LIFT2_def, MAP, GENLIST_AUX, SUM]', 'FLAT (MAP (combin$C MAP [x]) [f]) = [f x]'), ('fs[LUPDATE_def, FLAT, ZIP_def, FLAT, FRONT_DEF]', 'FLAT [[f x]] = [f x]')]
Time: 20.356704252999975  
Induct args: []
Preferences: tensor([9.0914e-04, 9.9034e-01, 2.3152e-03, 3.0972e-03, 3.3413e-03])
Proved so far: 9

Game: 34
Initialization done. Main goal is:
total (RC R) ⇒ total (RC (LLEX R)).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.217736666000064  
Induct args: []
Preferences: tensor([0.0012, 0.9911, 0.0018, 0.0024, 0.0036])
Proved so far: 9

Game: 35
Initialization done. Main goal is:
∀l1 l2. l1 = REVERSE l2 ⇔ l2 = REVERSE l1.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.85032904100001  
Induct args: []
Preferences: tensor([0.0028, 0.9716, 0.0086, 0.0098, 0.0072])
Proved so far: 9

Game: 36
Initialization done. Main goal is:
total (RC R) ⇒ total (RC (SHORTLEX R)).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.927350866999973  
Induct args: []
Preferences: tensor([0.0014, 0.9908, 0.0019, 0.0026, 0.0033])
Proved so far: 9

Game: 37
Initialization done. Main goal is:
TAKE n (GENLIST f m) = GENLIST f (MIN n m).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.908088814000052  
Induct args: []
Preferences: tensor([6.8810e-04, 9.9362e-01, 1.9915e-03, 2.0310e-03, 1.6647e-03])
Proved so far: 9

Game: 38
Initialization done. Main goal is:
l1 ++ l2 = h::t ⇔ l1 = [] ∧ l2 = h::t ∨ ∃lt. l1 = h::lt ∧ t = lt ++ l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.493384413999934  
Induct args: []
Preferences: tensor([3.5212e-04, 9.9557e-01, 2.2911e-03, 1.1328e-03, 6.5765e-04])
Proved so far: 9

Game: 39
Initialization done. Main goal is:
MAP (λx. x) l = l ∧ MAP I l = l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.277635115999942  
Induct args: []
Preferences: tensor([8.6772e-04, 9.9458e-01, 1.2226e-03, 1.9013e-03, 1.4244e-03])
Proved so far: 9

Game: 40
Initialization done. Main goal is:
∀n f. NULL (GENLIST f n) ⇔ n = 0.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 22.051708528000063  
Induct args: []
Preferences: tensor([4.2085e-04, 9.9338e-01, 1.9772e-03, 1.9542e-03, 2.2724e-03])
Proved so far: 9

Game: 41
Initialization done. Main goal is:
∀c l. EXISTS (λx. c) l ⇔ l ≠ [] ∧ c.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[UNZIP, list_case_def, FOLDR, oHD_def, UNIQUE_DEF]', '∀c l. EXISTS (λx. c) l ⇔ l ≠ [] ∧ c')]
Time: 0.5047663000000284  
Induct args: []
Preferences: tensor([2.5533e-04, 9.9733e-01, 1.1448e-03, 4.0655e-04, 8.6262e-04])
Proved so far: 10

Game: 42
Initialization done. Main goal is:
∀x ls n. MEM x (DROP n ls) ⇔ ∃m. m + n < LENGTH ls ∧ x = EL (m + n) ls.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.43476237499999  
Induct args: []
Preferences: tensor([1.5998e-04, 9.9819e-01, 7.9103e-04, 4.3454e-04, 4.2690e-04])
Proved so far: 10

Game: 43
Initialization done. Main goal is:
∀l. ALL_DISTINCT (nub l).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.738921902000016  
Induct args: []
Preferences: tensor([0.0194, 0.8991, 0.0324, 0.0240, 0.0251])
Proved so far: 10

Game: 44
Initialization done. Main goal is:
(∀x. LAST [x] = x) ∧ ∀h1 h2 t. LAST (h1::h2::t) = LAST (h2::t).
Proved in 3 steps.
Rewards: [-1, -1, 10]
Tactics: ['fs', 'fs', 'fs']
Total: 8
Proof trace: [('fs[INDEX_OF_def, SET_TO_LIST_primitive_def, LRC_def, OPT_MMAP_def, LAST_DEF]', '(∀x. LAST [x] = x) ∧ ∀h1 h2 t. LAST (h1::h2::t) = LAST (h2::t)')]
Time: 1.355712216000029  
Induct args: []
Preferences: tensor([1.9613e-04, 9.9879e-01, 4.0434e-04, 3.0619e-04, 3.0653e-04])
Proved so far: 11

Game: 45
Initialization done. Main goal is:
∀m n. TAKE n (TAKE m l) = TAKE (MIN n m) l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.60360253300007  
Induct args: []
Preferences: tensor([5.1769e-04, 9.9342e-01, 3.0965e-03, 1.5531e-03, 1.4150e-03])
Proved so far: 11

Game: 46
Initialization done. Main goal is:
(∀l. P l) ⇔ P [] ∧ ∀h t. P (h::t).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.20397742299997  
Induct args: []
Preferences: tensor([9.6588e-05, 9.9894e-01, 2.2540e-04, 2.7965e-04, 4.5361e-04])
Proved so far: 11

Game: 47
Initialization done. Main goal is:
∀f ls a. FOLDR (λx y. f x::y) a ls = MAP f ls ++ a.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.922391687000072  
Induct args: []
Preferences: tensor([4.5800e-05, 9.9933e-01, 4.0192e-04, 1.2379e-04, 1.0198e-04])
Proved so far: 11

Game: 48
Initialization done. Main goal is:
LIST_REL (λa b. P a b ∧ Q a b) l1 l2 ⇔ LIST_REL (λa b. P a b) l1 l2 ∧ LIST_REL (λa b. Q a b) l1 l2.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.969943575000116  
Induct args: []
Preferences: tensor([6.0227e-05, 9.9931e-01, 2.4865e-04, 1.8798e-04, 1.8903e-04])
Proved so far: 11

Game: 49
Importing theories...
Removing simp lemmas...
Loading modules...
Configuration done.
Initialization done. Main goal is:
∀n l. n < LENGTH l ⇒ ∀f. EL n (MAP f l) = f (EL n l).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 25.94425693900007  
Induct args: []
Preferences: tensor([1.5895e-04, 9.9775e-01, 1.1583e-03, 4.3150e-04, 5.0523e-04])
Proved so far: 11

Game: 50
Initialization done. Main goal is:
∀xs ys xs1 ys1 f. LENGTH xs = LENGTH xs1 ⇒ MAP2 f (xs ++ ys) (xs1 ++ ys1) = MAP2 f xs xs1 ++ MAP2 f ys ys1.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.57127014599996  
Induct args: []
Preferences: tensor([3.9636e-05, 9.9962e-01, 1.9735e-04, 1.0211e-04, 4.2534e-05])
Proved so far: 11

Game: 51
Initialization done. Main goal is:
∀P1 P2 l. EVERY P1 l ⇒ EVERY P1 (FILTER P2 l).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.537012732999983  
Induct args: []
Preferences: tensor([1.6706e-04, 9.9757e-01, 1.0443e-03, 7.1460e-04, 5.0540e-04])
Proved so far: 11

Game: 52
Initialization done. Main goal is:
∀n l. TAKE n l ++ DROP n l = l.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.50515695099989  
Induct args: []
Preferences: tensor([3.0521e-04, 9.9674e-01, 9.8406e-04, 8.9809e-04, 1.0676e-03])
Proved so far: 11

Game: 53
Initialization done. Main goal is:
(∀l. LENGTH l = 0 ⇔ l = []) ∧ (∀l n. LENGTH l = SUC n ⇔ ∃h l'. LENGTH l' = n ∧ l = h::l') ∧ ∀l n1 n2. LENGTH l = n1 + n2 ⇔ ∃l1 l2. LENGTH l1 = n1 ∧ LENGTH l2 = n2 ∧ l = l1 ++ l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.149130496999987  
Induct args: []
Preferences: tensor([1.6966e-04, 9.9833e-01, 7.1684e-04, 3.7703e-04, 4.0393e-04])
Proved so far: 11

Game: 54
Initialization done. Main goal is:
∀l1 l2. LENGTH l1 = LENGTH l2 ∧ (∀x. x < LENGTH l1 ⇒ EL x l1 = EL x l2) ⇒ l1 = l2.
Failed.
Rewards: [-1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.73708157100009  
Induct args: ['@']
Preferences: tensor([0.0011, 0.9907, 0.0045, 0.0017, 0.0020])
Proved so far: 11

Game: 55
Initialization done. Main goal is:
∀x xs. LENGTH (FRONT (x::xs)) = LENGTH xs.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.875500426999906  
Induct args: []
Preferences: tensor([6.3563e-05, 9.9954e-01, 1.4789e-04, 1.2954e-04, 1.1451e-04])
Proved so far: 11

Game: 56
Initialization done. Main goal is:
∀n. EXISTS P (GENLIST f n) ⇔ ∃i. i < n ∧ P (f i).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.331565296999997  
Induct args: []
Preferences: tensor([9.9848e-05, 9.9918e-01, 2.0547e-04, 2.2973e-04, 2.8952e-04])
Proved so far: 11

Game: 57
Initialization done. Main goal is:
∀n. TAKE n [] = [].
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[LUPDATE_def, DROP_def, nub_def, list_TY_DEF, ZIP_def]', '∀n. TAKE n [] = []')]
Time: 0.48719672000015635  
Induct args: []
Preferences: tensor([7.0960e-04, 9.9536e-01, 1.1809e-03, 1.5279e-03, 1.2214e-03])
Proved so far: 12

Game: 58
Initialization done. Main goal is:
GENLIST f 0 = [] ∧ GENLIST f (NUMERAL n) = GENLIST_AUX f (NUMERAL n) [].
Failed.
Rewards: [-1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.690132962000007  
Induct args: []
Preferences: tensor([2.5034e-04, 9.9746e-01, 4.4779e-04, 7.1432e-04, 1.1230e-03])
Proved so far: 12

Game: 59
Initialization done. Main goal is:
∀l. ALL_DISTINCT l ⇔ ∀n1 n2. n1 < LENGTH l ∧ n2 < LENGTH l ⇒ (EL n1 l = EL n2 l ⇔ n1 = n2).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.83723404599982  
Induct args: []
Preferences: tensor([3.0468e-05, 9.9985e-01, 4.3618e-05, 4.8801e-05, 3.0041e-05])
Proved so far: 12

Game: 60
Initialization done. Main goal is:
∀L. LENGTH L = LEN L 0.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.842965305999996  
Induct args: []
Preferences: tensor([0.0012, 0.9936, 0.0015, 0.0016, 0.0021])
Proved so far: 12

Game: 61
Initialization done. Main goal is:
∀l f. ¬NULL l ⇒ MAP f (TL l) = TL (MAP f l).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.92455503500014  
Induct args: []
Preferences: tensor([7.1932e-05, 9.9924e-01, 2.0986e-04, 2.3151e-04, 2.4255e-04])
Proved so far: 12

Game: 62
Initialization done. Main goal is:
∀ls. ls ≠ [] ⇒ LAST (REVERSE ls) = HD ls.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.565578209000023  
Induct args: []
Preferences: tensor([1.5590e-04, 9.9872e-01, 4.0728e-04, 4.1356e-04, 3.0747e-04])
Proved so far: 12

Game: 63
Initialization done. Main goal is:
∀P. (∀l. LENGTH l = 0 ⇒ P l) ⇔ P [].
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[DROP_def, LIST_GUARD_def, FOLDR, INDEX_OF_def, list_size_def]', '∀P. (∀l. LENGTH l = 0 ⇒ P l) ⇔ P []')]
Time: 0.5320376779998242  
Induct args: []
Preferences: tensor([2.4416e-04, 9.9761e-01, 7.2987e-04, 8.4427e-04, 5.6922e-04])
Proved so far: 13

Game: 64
Initialization done. Main goal is:
SET_TO_LIST ∅ = [].
Failed.
Rewards: [-1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.002756125999895  
Induct args: []
Preferences: tensor([2.0850e-05, 9.9988e-01, 2.8732e-05, 4.0422e-05, 2.5962e-05])
Proved so far: 13

Game: 65
Initialization done. Main goal is:
∀f g l. MAP f (MAP g l) = MAP (f ∘ g) l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.63919418399996  
Induct args: []
Preferences: tensor([2.3128e-05, 9.9975e-01, 6.8481e-05, 9.1494e-05, 6.8395e-05])
Proved so far: 13

Game: 66
Initialization done. Main goal is:
∀l1 l2 P k. EVERYi (λi. $~ ∘ P i) l1 ∧ (0 < LENGTH l2 ⇒ P (LENGTH l1) (HD l2)) ⇒ splitAtPki P k (l1 ++ l2) = k l1 l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.81475784899999  
Induct args: []
Preferences: tensor([1.4167e-04, 9.9889e-01, 3.7008e-04, 3.1363e-04, 2.8888e-04])
Proved so far: 13

Game: 67
Initialization done. Main goal is:
∀s. FINITE s ⇒ ALL_DISTINCT (SET_TO_LIST s).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.25460425899996  
Induct args: []
Preferences: tensor([1.4991e-05, 9.9991e-01, 2.7871e-05, 3.1197e-05, 2.0327e-05])
Proved so far: 13

Game: 68
Initialization done. Main goal is:
(LIST_REL R [] [] ⇔ T) ∧ (LIST_REL R (a::as) [] ⇔ F) ∧ (LIST_REL R [] (b::bs) ⇔ F) ∧ (LIST_REL R (a::as) (b::bs) ⇔ R a b ∧ LIST_REL R as bs).
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[LIST_TO_SET_DEF, dropWhile_def, FOLDL, LLEX_def, LEN_DEF]', '(LIST_REL R [] [] ⇔ T) ∧ (LIST_REL R (a::as) [] ⇔ F) ∧ (LIST_REL R [] (b::bs) ⇔ F) ∧ (LIST_REL R (a::as) (b::bs) ⇔ R a b ∧ LIST_REL R as bs)')]
Time: 0.5420374510001693  
Induct args: []
Preferences: tensor([4.9567e-05, 9.9955e-01, 1.1975e-04, 1.7617e-04, 1.0355e-04])
Proved so far: 14

Game: 69
Initialization done. Main goal is:
(∀x y. R1 x y ⇒ R2 x y) ⇒ LIST_REL R1 l1 l2 ⇒ LIST_REL R2 l1 l2.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.900487802000043  
Induct args: []
Preferences: tensor([1.8529e-04, 9.9851e-01, 5.2435e-04, 4.6094e-04, 3.2189e-04])
Proved so far: 14

Game: 70
Initialization done. Main goal is:
∀l. NULL l ⇔ l = [].
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.323154153999894  
Induct args: []
Preferences: tensor([0.0011, 0.9933, 0.0016, 0.0020, 0.0020])
Proved so far: 14

Game: 71
Initialization done. Main goal is:
∀l. ¬NULL l ⇔ ∃e. MEM e l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.95299868699999  
Induct args: []
Preferences: tensor([2.0383e-04, 9.9816e-01, 4.1152e-04, 5.2876e-04, 6.9314e-04])
Proved so far: 14

Game: 72
Initialization done. Main goal is:
∀l x. MEM x l ⇔ ∃n. n < LENGTH l ∧ x = EL n l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.885878808999905  
Induct args: []
Preferences: tensor([1.1720e-04, 9.9888e-01, 4.4528e-04, 3.7298e-04, 1.8226e-04])
Proved so far: 14

Game: 73
Initialization done. Main goal is:
LIST_BIND (LIST_BIND l g) f = LIST_BIND l (combin$C LIST_BIND f ∘ g).
Failed.
Rewards: [-1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.68812785399996  
Induct args: []
Preferences: tensor([2.3429e-05, 9.9975e-01, 5.8802e-05, 9.7001e-05, 7.0760e-05])
Proved so far: 14

Game: 74
Importing theories...
Removing simp lemmas...
Loading modules...
Configuration done.
Initialization done. Main goal is:
(∀x y. R1 x y ⇒ R2 x y) ⇒ LLEX R1 x y ⇒ LLEX R2 x y.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 25.097207160999915  
Induct args: []
Preferences: tensor([1.1394e-04, 9.9923e-01, 2.4700e-04, 2.3074e-04, 1.8127e-04])
Proved so far: 14

Game: 75
Initialization done. Main goal is:
MAP f (FLAT l) = FLAT (MAP (MAP f) l).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.48677984699998  
Induct args: []
Preferences: tensor([1.4927e-04, 9.9903e-01, 2.4662e-04, 3.2496e-04, 2.4570e-04])
Proved so far: 14

Game: 76
Initialization done. Main goal is:
NRC R n x y ⇔ ∃ls. LRC R ls x y ∧ LENGTH ls = n.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.483682916000134  
Induct args: []
Preferences: tensor([4.6933e-05, 9.9962e-01, 1.1057e-04, 1.0133e-04, 1.2548e-04])
Proved so far: 14

Game: 77
Initialization done. Main goal is:
∀f1 f2 l1 l2. MAP f1 l1 = MAP f2 l2 ⇔ LENGTH l1 = LENGTH l2 ∧ LIST_REL (λx y. f1 x = f2 y) l1 l2.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.97052434599982  
Induct args: []
Preferences: tensor([6.1750e-05, 9.9946e-01, 1.4008e-04, 2.1277e-04, 1.2628e-04])
Proved so far: 14

Game: 78
Initialization done. Main goal is:
∀l1 l2. REVERSE l1 = l2 ⇔ l1 = REVERSE l2.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.71031689000006  
Induct args: []
Preferences: tensor([3.2642e-04, 9.9578e-01, 1.3668e-03, 1.2562e-03, 1.2741e-03])
Proved so far: 14

Game: 79
Initialization done. Main goal is:
∀x l. FRONT (SNOC x l) = l.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.66455014600001  
Induct args: []
Preferences: tensor([3.3595e-04, 9.9689e-01, 6.9524e-04, 6.2741e-04, 1.4541e-03])
Proved so far: 14

Game: 80
Initialization done. Main goal is:
(¬LLEX R [] [] ∧ ¬LLEX R (h1::t1) []) ∧ LLEX R [] (h2::t2) ∧ (LLEX R (h1::t1) (h2::t2) ⇔ R h1 h2 ∨ h1 = h2 ∧ LLEX R t1 t2).
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[INDEX_OF_def, REVERSE_DEF, NULL_DEF, EVERYi_def, TAKE_def]', '(¬LLEX R [] [] ∧ ¬LLEX R (h1::t1) []) ∧ LLEX R [] (h2::t2) ∧ (LLEX R (h1::t1) (h2::t2) ⇔ R h1 h2 ∨ h1 = h2 ∧ LLEX R t1 t2)')]
Time: 0.5070414650001567  
Induct args: []
Preferences: tensor([4.3001e-05, 9.9971e-01, 8.1916e-05, 9.5641e-05, 7.1214e-05])
Proved so far: 15

Game: 81
Initialization done. Main goal is:
∀xs n x. LUPDATE x n xs = [] ⇔ xs = [].
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[NULL_DEF, list_TY_DEF, LAST_DEF, FOLDR, EL]', '∀xs n x. LUPDATE x n xs = [] ⇔ xs = []')]
Time: 0.47717378600009397  
Induct args: []
Preferences: tensor([9.0234e-05, 9.9906e-01, 2.4301e-04, 3.2071e-04, 2.8879e-04])
Proved so far: 16

Game: 82
Initialization done. Main goal is:
∀P L x. MEM x (FILTER P L) ⇔ P x ∧ MEM x L.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.712896405000038  
Induct args: []
Preferences: tensor([4.2375e-04, 9.9645e-01, 1.2357e-03, 1.1786e-03, 7.1434e-04])
Proved so far: 16

Game: 83
Initialization done. Main goal is:
REVERSE l = [] ⇔ l = [].
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.144903369000076  
Induct args: []
Preferences: tensor([9.8059e-04, 9.9319e-01, 1.3808e-03, 2.4707e-03, 1.9820e-03])
Proved so far: 16

Game: 84
Initialization done. Main goal is:
(∀x. MEM x [] ⇔ F) ∧ ∀x h t. MEM x (h::t) ⇔ x = h ∨ MEM x t.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[OPT_MMAP_def, FLAT, PAD_RIGHT, dropWhile_def, nub_def]', '(∀x. MEM x [] ⇔ F) ∧ ∀x h t. MEM x (h::t) ⇔ x = h ∨ MEM x t')]
Time: 0.5355499909999253  
Induct args: []
Preferences: tensor([2.8678e-05, 9.9984e-01, 2.8132e-05, 4.1996e-05, 5.6613e-05])
Proved so far: 17

Game: 85
Initialization done. Main goal is:
∀l1 l2. SUM (l1 ++ l2) = SUM l1 + SUM l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.474682577000067  
Induct args: []
Preferences: tensor([5.3329e-04, 9.9566e-01, 7.3268e-04, 8.2718e-04, 2.2455e-03])
Proved so far: 17

Game: 86
Initialization done. Main goal is:
∀l1 l2. LENGTH l1 = LENGTH l2 ⇒ LENGTH (ZIP (l1,l2)) = LENGTH l1 ∧ LENGTH (ZIP (l1,l2)) = LENGTH l2.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[INDEX_FIND_def, list_size_def, FOLDR, LEN_DEF, HD]', '∀l1 l2. LENGTH l1 = LENGTH l2 ⇒ LENGTH (ZIP (l1,l2)) = LENGTH l1 ∧ LENGTH (ZIP (l1,l2)) = LENGTH l2')]
Time: 0.5049166539999987  
Induct args: []
Preferences: tensor([4.0549e-05, 9.9947e-01, 2.1848e-04, 1.2024e-04, 1.5337e-04])
Proved so far: 18

Game: 87
Initialization done. Main goal is:
∀xs ys. LENGTH (MAP2 f xs ys) = MIN (LENGTH xs) (LENGTH ys).
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[ZIP_def, LIST_BIND_def, GENLIST_AUX, EVERYi_def, LIST_LIFT2_def]', '∀xs ys. LENGTH (MAP2 f xs ys) = MIN (LENGTH xs) (LENGTH ys)')]
Time: 0.481900762000123  
Induct args: []
Preferences: tensor([1.8545e-05, 9.9985e-01, 5.1683e-05, 3.9259e-05, 4.4983e-05])
Proved so far: 19

Game: 88
Initialization done. Main goal is:
∀xs n y. oEL n xs = SOME y ⇔ n < LENGTH xs ∧ y = EL n xs.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.82759015900001  
Induct args: []
Preferences: tensor([2.2449e-05, 9.9986e-01, 5.3415e-05, 4.0034e-05, 2.8076e-05])
Proved so far: 19

Game: 89
Initialization done. Main goal is:
∀l1 l1'. LENGTH l1 = LENGTH l1' ⇒ ∀l2 l2'. LENGTH l2 = LENGTH l2' ⇒ (l1 ++ l2 = l1' ++ l2' ⇔ l1 = l1' ∧ l2 = l2').
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.424242565999975  
Induct args: []
Preferences: tensor([4.0674e-05, 9.9970e-01, 9.9124e-05, 1.0640e-04, 5.5619e-05])
Proved so far: 19

Game: 90
Initialization done. Main goal is:
∀f ls s. FOLDL (λs (x,y). s ∪ f x y) s ls = s ∪ BIGUNION (IMAGE (UNCURRY f) (set ls)).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.100595376  
Induct args: []
Preferences: tensor([8.2345e-06, 9.9994e-01, 2.3485e-05, 1.5488e-05, 1.3923e-05])
Proved so far: 19

Game: 91
Initialization done. Main goal is:
∀xs i n x. oEL n (LUPDATE x i xs) = if i ≠ n then oEL n xs else if i < LENGTH xs then SOME x else NONE.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.288452993999954  
Induct args: []
Preferences: tensor([1.2909e-05, 9.9988e-01, 5.1796e-05, 3.3474e-05, 1.9095e-05])
Proved so far: 19

Game: 92
Initialization done. Main goal is:
∀h1 h2. h1 ≠ h2 ⇒ ∀l1 l2. h1::l1 ≠ h2::l2.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[SET_TO_LIST_primitive_def, EVERY_DEF, TAKE_def, FIND_def, REVERSE_DEF]', '∀h1 h2. h1 ≠ h2 ⇒ ∀l1 l2. h1::l1 ≠ h2::l2')]
Time: 0.48903461100007917  
Induct args: []
Preferences: tensor([2.5838e-05, 9.9983e-01, 7.8958e-05, 3.9955e-05, 2.4933e-05])
Proved so far: 20

Game: 93
Initialization done. Main goal is:
(∀x. MEM x ls ⇒ R x x) ⇒ LIST_REL R ls ls.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.64909809100004  
Induct args: []
Preferences: tensor([2.3809e-04, 9.9839e-01, 4.5419e-04, 4.1650e-04, 5.0459e-04])
Proved so far: 20

Game: 94
Initialization done. Main goal is:
MEM e l ⇔ ∃pfx sfx. l = pfx ++ [e] ++ sfx ∧ ¬MEM e pfx.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.638949897999964  
Induct args: []
Preferences: tensor([7.0317e-05, 9.9958e-01, 1.3066e-04, 8.7075e-05, 1.3236e-04])
Proved so far: 20

Game: 95
Initialization done. Main goal is:
∀l1 x l2. EL (LENGTH l1) (l1 ++ [x] ++ l2) = x.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.655149330999848  
Induct args: []
Preferences: tensor([1.1948e-04, 9.9915e-01, 2.2826e-04, 2.8034e-04, 2.1950e-04])
Proved so far: 20

Game: 96
Initialization done. Main goal is:
fs <*> [x] = [(λf. f x)] <*> fs.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -47
Time: 20.489159536999978  
Induct args: []
Preferences: tensor([2.4541e-05, 9.9982e-01, 4.4688e-05, 5.3965e-05, 5.2259e-05])
Proved so far: 20

Game: 97
Initialization done. Main goal is:
∀L. REVERSE L = REV L [].
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.669984109000097  
Induct args: []
Preferences: tensor([5.8634e-04, 9.9680e-01, 7.8295e-04, 7.5565e-04, 1.0727e-03])
Proved so far: 20

Game: 98
Initialization done. Main goal is:
(∀l. TAKE 0 l = []) ∧ (∀n. TAKE (NUMERAL (BIT1 n)) [] = []) ∧ (∀n. TAKE (NUMERAL (BIT2 n)) [] = []) ∧ (∀n h t. TAKE (NUMERAL (BIT1 n)) (h::t) = h::TAKE (NUMERAL (BIT1 n) − 1) t) ∧ ∀n h t. TAKE (NUMERAL (BIT2 n)) (h::t) = h::TAKE (NUMERAL (BIT1 n)) t.
Failed.
Rewards: [1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -47
Time: 21.213175051000007  
Induct args: ['@']
Preferences: tensor([2.3182e-04, 9.9815e-01, 4.0378e-04, 6.5265e-04, 5.6442e-04])
Proved so far: 20

Game: 99
Importing theories...
Removing simp lemmas...
Loading modules...
Configuration done.
Initialization done. Main goal is:
∀ls f. (∀x y. MEM x ls ∧ MEM y ls ∧ f x = f y ⇒ x = y) ∧ ALL_DISTINCT ls ⇒ ALL_DISTINCT (MAP f ls).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 25.53702698699999  
Induct args: []
Preferences: tensor([1.2209e-04, 9.9906e-01, 3.9622e-04, 2.5920e-04, 1.6739e-04])
Proved so far: 20

Game: 100
Initialization done. Main goal is:
∀f g ls. SUM (MAP (λx. f x + g x) ls) = SUM (MAP f ls) + SUM (MAP g ls).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.781048288999955  
Induct args: []
Preferences: tensor([9.4141e-06, 9.9992e-01, 2.3345e-05, 2.1951e-05, 2.0747e-05])
Proved so far: 20

Game: 101
Initialization done. Main goal is:
∀n l. n < LENGTH l ⇒ EL n (REVERSE l) = EL (PRE (LENGTH l − n)) l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.097363817000087  
Induct args: []
Preferences: tensor([1.2547e-04, 9.9878e-01, 3.6714e-04, 2.6896e-04, 4.5941e-04])
Proved so far: 20

Game: 102
Initialization done. Main goal is:
∀l1 x l2. l1 ++ SNOC x l2 = SNOC x (l1 ++ l2).
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[SNOC, PAD_RIGHT, EVERY_DEF, LIST_APPLY_def, PAD_RIGHT]', '∀l1 x l2. l1 ++ SNOC x l2 = SNOC x (l1 ++ l2)')]
Time: 0.4835749270000633  
Induct args: []
Preferences: tensor([7.1023e-05, 9.9905e-01, 1.8718e-04, 3.0244e-04, 3.9141e-04])
Proved so far: 21

Game: 103
Initialization done. Main goal is:
∀s. FINITE s ⇒ ∀x. MEM x (SET_TO_LIST s) ⇔ x ∈ s.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[FOLDR, TAKE_def, LUPDATE_def, LUPDATE_def, dropWhile_def]', '∀s. FINITE s ⇒ ∀x. MEM x (SET_TO_LIST s) ⇔ x ∈ s')]
Time: 0.4827046430000337  
Induct args: []
Preferences: tensor([1.4516e-04, 9.9899e-01, 2.6090e-04, 3.0232e-04, 3.0015e-04])
Proved so far: 22

Game: 104
Initialization done. Main goal is:
LIST_BIND [x] f = f x.
Proved in 36 steps.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 10]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -21
Proof trace: [('fs[FOLDL, REVERSE_DEF, LIST_BIND_def, DROP_def, UNIQUE_DEF]', 'LIST_BIND [x] f = f x'), ('fs[LUPDATE_def, MAP, EVERYi_def, DROP_def, list_size_def]', 'FLAT (MAP f [x]) = f x'), ('fs[PAD_RIGHT, FLAT, FOLDR, NULL_DEF, DROP_def]', 'FLAT [f x] = f x')]
Time: 14.592848351999692  
Induct args: []
Preferences: tensor([9.4122e-04, 9.9351e-01, 7.4475e-04, 1.4169e-03, 3.3887e-03])
Proved so far: 23

Game: 105
Initialization done. Main goal is:
∀P Q l1 l2. (∀x. MEM x (ZIP (l1,l2)) ∧ UNCURRY P x ⇒ UNCURRY Q x) ∧ LIST_REL P l1 l2 ⇒ LIST_REL Q l1 l2.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.241411380000045  
Induct args: []
Preferences: tensor([0.0010, 0.9934, 0.0018, 0.0022, 0.0015])
Proved so far: 23

Game: 106
Initialization done. Main goal is:
∀x y. LIST_REL R x y ⇒ LENGTH x = LENGTH y.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.45886483000004  
Induct args: []
Preferences: tensor([9.2111e-05, 9.9914e-01, 2.3454e-04, 2.1614e-04, 3.1657e-04])
Proved so far: 23

Game: 107
Initialization done. Main goal is:
GENLIST f 0 = [] ∧ GENLIST f (NUMERAL n) = GENLIST_AUX f (NUMERAL n) [].
Failed.
Rewards: [-1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.692984786000125  
Induct args: []
Preferences: tensor([2.4033e-04, 9.9747e-01, 4.4186e-04, 5.0139e-04, 1.3512e-03])
Proved so far: 23

Game: 108
Initialization done. Main goal is:
∀n. EVERY P (GENLIST f n) ⇔ ∀i. i < n ⇒ P (f i).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.781409362999966  
Induct args: []
Preferences: tensor([8.2200e-05, 9.9925e-01, 1.4564e-04, 1.6912e-04, 3.5390e-04])
Proved so far: 23

Game: 109
Initialization done. Main goal is:
∀ys x i k. EL i (LUPDATE x k ys) = if i = k ∧ k < LENGTH ys then x else EL i ys.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.466487227000016  
Induct args: []
Preferences: tensor([3.0602e-05, 9.9976e-01, 4.6194e-05, 5.9663e-05, 1.0121e-04])
Proved so far: 23

Game: 110
Initialization done. Main goal is:
∀l. ¬NULL l ⇔ ∃e. MEM e l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.581786359000034  
Induct args: []
Preferences: tensor([2.0646e-04, 9.9808e-01, 4.1623e-04, 4.3195e-04, 8.7016e-04])
Proved so far: 23

Game: 111
Initialization done. Main goal is:
∀l f x. MEM x (MAP f l) ⇔ ∃y. x = f y ∧ MEM y l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.67056355500017  
Induct args: []
Preferences: tensor([5.5695e-05, 9.9943e-01, 2.2236e-04, 1.7259e-04, 1.1889e-04])
Proved so far: 23

Game: 112
Initialization done. Main goal is:
¬SHORTLEX R l [].
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[FOLDL, LIST_GUARD_def, TAKE_def, EVERYi_def, FOLDL]', '¬SHORTLEX R l []')]
Time: 0.482606062999821  
Induct args: []
Preferences: tensor([0.0013, 0.9921, 0.0017, 0.0029, 0.0020])
Proved so far: 24

Game: 113
Initialization done. Main goal is:
MAP f l = h::t ⇔ ∃x0 t0. l = x0::t0 ∧ h = f x0 ∧ t = MAP f t0.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.732357157000024  
Induct args: []
Preferences: tensor([1.9131e-04, 9.9930e-01, 1.1757e-04, 1.6496e-04, 2.2125e-04])
Proved so far: 24

Game: 114
Initialization done. Main goal is:
∀n f g. GENLIST f n = GENLIST g n ⇔ ∀x. x < n ⇒ f x = g x.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.211651803000223  
Induct args: []
Preferences: tensor([4.2463e-05, 9.9964e-01, 7.9757e-05, 1.1281e-04, 1.2915e-04])
Proved so far: 24

Game: 115
Initialization done. Main goal is:
REVERSE l = [] ⇔ l = [].
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.357723022999835  
Induct args: ['Cmin$=']
Preferences: tensor([6.0457e-04, 9.9613e-01, 8.7524e-04, 8.6881e-04, 1.5232e-03])
Proved so far: 24

Game: 116
Initialization done. Main goal is:
∀x y a b. SNOC x y = SNOC a b ⇔ x = a ∧ y = b.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.01742421300014  
Induct args: []
Preferences: tensor([3.9127e-05, 9.9957e-01, 1.3372e-04, 8.8450e-05, 1.7328e-04])
Proved so far: 24

Game: 117
Initialization done. Main goal is:
¬SHORTLEX R l [].
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[ZIP_def, FRONT_DEF, FIND_def, SUM, SUM]', '¬SHORTLEX R l []')]
Time: 0.48912855599974137  
Induct args: []
Preferences: tensor([0.0017, 0.9889, 0.0022, 0.0038, 0.0033])
Proved so far: 25

Game: 118
Initialization done. Main goal is:
∀P. P [] ∧ (∀l. P l ⇒ ∀x. P (SNOC x l)) ⇒ ∀l. P l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.42328569700021  
Induct args: []
Preferences: tensor([5.8055e-05, 9.9962e-01, 1.1868e-04, 6.2360e-05, 1.3970e-04])
Proved so far: 25

Game: 119
Initialization done. Main goal is:
TAKE n l = [] ⇔ n = 0 ∨ l = [].
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[REV_DEF, LLEX_def, LEN_DEF, oHD_def, OPT_MMAP_def]', 'TAKE n l = [] ⇔ n = 0 ∨ l = []')]
Time: 0.48438368300003276  
Induct args: []
Preferences: tensor([4.1095e-04, 9.9673e-01, 7.9805e-04, 8.2029e-04, 1.2384e-03])
Proved so far: 26

Game: 120
Initialization done. Main goal is:
∀l1 l1' l2 l2' f f'. l1 = l1' ∧ l2 = l2' ∧ (∀x y. MEM x l1' ∧ MEM y l2' ⇒ f x y = f' x y) ⇒ MAP2 f l1 l2 = MAP2 f' l1' l2'.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.760372476000157  
Induct args: []
Preferences: tensor([5.2611e-05, 9.9941e-01, 2.2712e-04, 1.2881e-04, 1.8466e-04])
Proved so far: 26

Game: 121
Initialization done. Main goal is:
∀R l1 l2. LIST_REL R l1 l2 ⇔ LENGTH l1 = LENGTH l2 ∧ EVERY (UNCURRY R) (ZIP (l1,l2)).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.56774445300016  
Induct args: []
Preferences: tensor([4.2127e-04, 9.9660e-01, 1.4019e-03, 9.2165e-04, 6.5927e-04])
Proved so far: 26

Game: 122
Initialization done. Main goal is:
(∀x xs. FRONT (x::xs) = [] ⇔ xs = []) ∧ (∀x xs. [] = FRONT (x::xs) ⇔ xs = []) ∧ ∀x xs. NULL (FRONT (x::xs)) ⇔ NULL xs.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.092589417  
Induct args: []
Preferences: tensor([0.0011, 0.9898, 0.0027, 0.0031, 0.0033])
Proved so far: 26

Game: 123
Initialization done. Main goal is:
∀m n. TAKE n (TAKE m l) = TAKE (MIN n m) l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.756746180999926  
Induct args: []
Preferences: tensor([3.3732e-04, 9.9616e-01, 1.5478e-03, 8.8511e-04, 1.0670e-03])
Proved so far: 26

Game: 124
Importing theories...
Removing simp lemmas...
Loading modules...
Configuration done.
Initialization done. Main goal is:
∀f l1 l2. INJ f (set l1 ∪ set l2) 𝕌(:β) ⇒ (MAP f l1 = MAP f l2 ⇔ l1 = l2).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 25.542059189000156  
Induct args: []
Preferences: tensor([8.7052e-05, 9.9929e-01, 2.2896e-04, 2.1678e-04, 1.8076e-04])
Proved so far: 26

Game: 125
Initialization done. Main goal is:
∀f x l. MAP f (SNOC x l) = SNOC (f x) (MAP f l).
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[EVERYi_def, LRC_def, SUM, list_size_def, OPT_MMAP_def]', '∀f x l. MAP f (SNOC x l) = SNOC (f x) (MAP f l)')]
Time: 0.5680960419999792  
Induct args: []
Preferences: tensor([8.7378e-05, 9.9947e-01, 1.6904e-04, 1.3238e-04, 1.3690e-04])
Proved so far: 27

Game: 126
Initialization done. Main goal is:
(∀x y. R1 x y ⇒ R2 y x) ⇒ ∀x y. LIST_REL R1 x y ⇒ LIST_REL R2 y x.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.636771917999795  
Induct args: []
Preferences: tensor([6.7289e-05, 9.9948e-01, 1.1852e-04, 1.2896e-04, 2.0619e-04])
Proved so far: 27

Game: 127
Initialization done. Main goal is:
(∀l. LENGTH l = 0 ⇔ l = []) ∧ (∀l n. LENGTH l = SUC n ⇔ ∃h l'. LENGTH l' = n ∧ l = h::l') ∧ ∀l n1 n2. LENGTH l = n1 + n2 ⇔ ∃l1 l2. LENGTH l1 = n1 ∧ LENGTH l2 = n2 ∧ l = l1 ++ l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.35444240400011  
Induct args: []
Preferences: tensor([9.1350e-05, 9.9923e-01, 2.5539e-04, 1.7540e-04, 2.4840e-04])
Proved so far: 27

Game: 128
Initialization done. Main goal is:
∀xs1 zs. LIST_REL P zs (xs1 ++ xs2) ⇔ ∃ys1 ys2. zs = ys1 ++ ys2 ∧ LIST_REL P ys1 xs1 ∧ LIST_REL P ys2 xs2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.054252171999906  
Induct args: []
Preferences: tensor([2.9918e-05, 9.9970e-01, 1.1621e-04, 6.3181e-05, 8.7030e-05])
Proved so far: 27

Game: 129
Initialization done. Main goal is:
(∀i. i < LENGTH l ⇒ (P1 i (EL i l) ⇔ P2 i (EL i l))) ⇒ splitAtPki P1 k l = splitAtPki P2 k l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.13375370499989  
Induct args: []
Preferences: tensor([4.8860e-05, 9.9953e-01, 9.9545e-05, 7.5538e-05, 2.4451e-04])
Proved so far: 27

Game: 130
Initialization done. Main goal is:
INFINITE 𝕌(:α list).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs']
Total: -51
Time: 21.430164024000078  
Induct args: []
Preferences: tensor([0.0075, 0.9614, 0.0077, 0.0111, 0.0123])
Proved so far: 27

Game: 131
Initialization done. Main goal is:
∀l n1 n2. LENGTH l = n1 + n2 ⇔ ∃l1 l2. LENGTH l1 = n1 ∧ LENGTH l2 = n2 ∧ l = l1 ++ l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.763738442999966  
Induct args: []
Preferences: tensor([3.2872e-04, 9.9846e-01, 4.4058e-04, 2.2903e-04, 5.3874e-04])
Proved so far: 27

Game: 132
Initialization done. Main goal is:
∀n l. n < LENGTH l ⇒ ∀x. EL n (SNOC x l) = EL n l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.583783837000283  
Induct args: []
Preferences: tensor([2.1313e-04, 9.9825e-01, 7.5167e-04, 2.3777e-04, 5.5039e-04])
Proved so far: 27

Game: 133
Initialization done. Main goal is:
WF (λL1 L2. ∃h. L2 = h::L1).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.813456306000262  
Induct args: []
Preferences: tensor([5.8573e-04, 9.9661e-01, 7.7822e-04, 6.2916e-04, 1.4014e-03])
Proved so far: 27

Game: 134
Initialization done. Main goal is:
∀ys k x y. LUPDATE x k (SNOC y ys) = if k = LENGTH ys then SNOC x ys else SNOC y (LUPDATE x k ys).
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.053647631999866  
Induct args: []
Preferences: tensor([3.1112e-05, 9.9984e-01, 6.3095e-05, 1.8130e-05, 5.1797e-05])
Proved so far: 27

Game: 135
Initialization done. Main goal is:
∀L. SUM L = SUM_ACC L 0.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.61798482899985  
Induct args: []
Preferences: tensor([2.0021e-03, 9.9123e-01, 2.1014e-03, 9.1330e-04, 3.7532e-03])
Proved so far: 27

Game: 136
Initialization done. Main goal is:
∀R l1 l2. LIST_REL R l1 l2 ⇔ LENGTH l1 = LENGTH l2 ∧ ∀n. n < LENGTH l1 ⇒ R (EL n l1) (EL n l2).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.08158794100018  
Induct args: []
Preferences: tensor([1.0367e-03, 9.9620e-01, 1.2694e-03, 5.9819e-04, 8.9313e-04])
Proved so far: 27

Game: 137
Initialization done. Main goal is:
l1 ++ l2 = h::t ⇔ l1 = [] ∧ l2 = h::t ∨ ∃lt. l1 = h::lt ∧ t = lt ++ l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.19651110599989  
Induct args: []
Preferences: tensor([1.0014e-03, 9.9572e-01, 1.7355e-03, 6.5771e-04, 8.8171e-04])
Proved so far: 27

Game: 138
Initialization done. Main goal is:
EL (NUMERAL (BIT1 n)) l = EL (PRE (NUMERAL (BIT1 n))) (TL l) ∧ EL (NUMERAL (BIT2 n)) l = EL (NUMERAL (BIT1 n)) (TL l).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.06034059400008  
Induct args: []
Preferences: tensor([6.6195e-04, 9.9848e-01, 2.4594e-04, 1.9129e-04, 4.1941e-04])
Proved so far: 27

Game: 139
Initialization done. Main goal is:
∀l1 l2 f f'. l1 = l2 ∧ (∀x. MEM x l2 ⇒ f x = f' x) ⇒ MAP f l1 = MAP f' l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.783490203000383  
Induct args: []
Preferences: tensor([1.0391e-03, 9.9663e-01, 1.0832e-03, 4.3335e-04, 8.1304e-04])
Proved so far: 27

Game: 140
Initialization done. Main goal is:
∀ls. ls ≠ [] ⇒ MAP f (FRONT ls) = FRONT (MAP f ls).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.98261365999997  
Induct args: []
Preferences: tensor([1.3429e-03, 9.9577e-01, 7.3132e-04, 6.4483e-04, 1.5132e-03])
Proved so far: 27

Game: 141
Initialization done. Main goal is:
∀l1 l2. l1 = l2 ⇔ LENGTH l1 = LENGTH l2 ∧ ∀x. x < LENGTH l1 ⇒ EL x l1 = EL x l2.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.92532958999982  
Induct args: []
Preferences: tensor([0.0025, 0.9919, 0.0016, 0.0015, 0.0026])
Proved so far: 27

Game: 142
Initialization done. Main goal is:
LIST_REL R xs (h::t) ⇔ ∃h' t'. xs = h'::t' ∧ R h' h ∧ LIST_REL R t' t.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[splitAtPki_def, SUM, EVERYi_def, isPREFIX, nub_def]', "LIST_REL R xs (h::t) ⇔ ∃h' t'. xs = h'::t' ∧ R h' h ∧ LIST_REL R t' t")]
Time: 0.5215896050003721  
Induct args: []
Preferences: tensor([1.7222e-04, 9.9949e-01, 6.9587e-05, 7.2960e-05, 1.9161e-04])
Proved so far: 28

Game: 143
Initialization done. Main goal is:
∀m n l. m + n < LENGTH l ⇒ EL m (DROP n l) = EL (m + n) l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.61168803999999  
Induct args: []
Preferences: tensor([4.2758e-04, 9.9903e-01, 2.0387e-04, 1.1316e-04, 2.2609e-04])
Proved so far: 28

Game: 144
Initialization done. Main goal is:
REVERSE l = [] ⇔ l = [].
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.768922487000054  
Induct args: []
Preferences: tensor([0.0030, 0.9860, 0.0024, 0.0017, 0.0069])
Proved so far: 28

Game: 145
Initialization done. Main goal is:
∀M M' v f. M = M' ∧ (M' = [] ⇒ v = v') ∧ (∀a0 a1. M' = a0::a1 ⇒ f a0 a1 = f' a0 a1) ⇒ list_CASE M v f = list_CASE M' v' f'.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.923226691999844  
Induct args: []
Preferences: tensor([4.9608e-04, 9.9853e-01, 3.8301e-04, 2.1626e-04, 3.7179e-04])
Proved so far: 28

Game: 146
Initialization done. Main goal is:
TAKE 0 l = [].
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[LIST_APPLY_def, UNZIP, FRONT_DEF, LENGTH, REVERSE_DEF]', 'TAKE 0 l = []')]
Time: 0.4841819819998818  
Induct args: []
Preferences: tensor([0.0055, 0.9833, 0.0025, 0.0038, 0.0049])
Proved so far: 29

Game: 147
Initialization done. Main goal is:
BIGUNION (IMAGE f (set ls)) ⊆ s ⇔ ∀x. MEM x ls ⇒ f x ⊆ s.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.723496475000047  
Induct args: []
Preferences: tensor([7.2905e-04, 9.9704e-01, 5.5426e-04, 5.2084e-04, 1.1554e-03])
Proved so far: 29

Game: 148
Initialization done. Main goal is:
FINITE s ⇒ SET_TO_LIST s = if s = ∅ then [] else CHOICE s::SET_TO_LIST (REST s).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.9493527919999  
Induct args: ['Cmin$==>']
Preferences: tensor([2.8559e-03, 9.9155e-01, 1.2673e-03, 9.4859e-04, 3.3799e-03])
Proved so far: 29

Game: 149
Importing theories...
Removing simp lemmas...
Loading modules...
Configuration done.
Initialization done. Main goal is:
MAP f l = l1 ++ l2 ⇔ ∃l10 l20. l = l10 ++ l20 ∧ l1 = MAP f l10 ∧ l2 = MAP f l20.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 25.591668204000143  
Induct args: []
Preferences: tensor([1.0613e-03, 9.9768e-01, 2.6020e-04, 4.0884e-04, 5.9341e-04])
Proved so far: 29

Game: 150
Initialization done. Main goal is:
∀P l1 l2 v1 v2 n. P v1 v2 ∧ LIST_REL P l1 l2 ⇒ LIST_REL P (LUPDATE v1 n l1) (LUPDATE v2 n l2).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.983619911000005  
Induct args: []
Preferences: tensor([3.1828e-03, 9.9415e-01, 1.0152e-03, 5.9236e-04, 1.0617e-03])
Proved so far: 29

Game: 151
Initialization done. Main goal is:
LIST_REL (λa b. P a b ∧ Q a b) l1 l2 ⇔ LIST_REL (λa b. P a b) l1 l2 ∧ LIST_REL (λa b. Q a b) l1 l2.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.6986784300002  
Induct args: []
Preferences: tensor([4.3119e-04, 9.9874e-01, 2.1302e-04, 1.9323e-04, 4.1840e-04])
Proved so far: 29

Game: 152
Initialization done. Main goal is:
(∀x. FRONT [x] = []) ∧ ∀x y z. FRONT (x::y::z) = x::FRONT (y::z).
Proved in 16 steps.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 10]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -5
Proof trace: [('fs[SET_TO_LIST_primitive_def, FRONT_DEF, PAD_LEFT, FOLDR, splitAtPki_def]', '(∀x. FRONT [x] = []) ∧ ∀x y z. FRONT (x::y::z) = x::FRONT (y::z)')]
Time: 6.565143798999998  
Induct args: []
Preferences: tensor([0.0036, 0.9907, 0.0019, 0.0011, 0.0027])
Proved so far: 30

Game: 153
Initialization done. Main goal is:
EL (NUMERAL (BIT1 n)) l = EL (PRE (NUMERAL (BIT1 n))) (TL l) ∧ EL (NUMERAL (BIT2 n)) l = EL (NUMERAL (BIT1 n)) (TL l).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.970139995999943  
Induct args: []
Preferences: tensor([1.2115e-03, 9.9760e-01, 3.4002e-04, 2.6384e-04, 5.8058e-04])
Proved so far: 30

Game: 154
Initialization done. Main goal is:
(∀l. TAKE 0 l = []) ∧ (∀n. TAKE (NUMERAL (BIT1 n)) [] = []) ∧ (∀n. TAKE (NUMERAL (BIT2 n)) [] = []) ∧ (∀n h t. TAKE (NUMERAL (BIT1 n)) (h::t) = h::TAKE (NUMERAL (BIT1 n) − 1) t) ∧ ∀n h t. TAKE (NUMERAL (BIT2 n)) (h::t) = h::TAKE (NUMERAL (BIT1 n)) t.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -47
Time: 21.344642542999736  
Induct args: []
Preferences: tensor([0.0080, 0.9467, 0.0065, 0.0070, 0.0318])
Proved so far: 30

Game: 155
Initialization done. Main goal is:
∀P L M. FILTER P (L ++ M) = FILTER P L ++ FILTER P M.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.525261191000027  
Induct args: []
Preferences: tensor([3.8614e-04, 9.9902e-01, 2.3286e-04, 1.5554e-04, 2.0659e-04])
Proved so far: 30

Game: 156
Initialization done. Main goal is:
∀l1 l2. SUM (l1 ++ l2) = SUM l1 + SUM l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.73751010199976  
Induct args: ['Cbool$!']
Preferences: tensor([0.0040, 0.9820, 0.0024, 0.0024, 0.0092])
Proved so far: 30

Game: 157
Initialization done. Main goal is:
∀n. TAKE n [] = [].
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[list_case_def, dropWhile_def, UNIQUE_DEF, LRC_def, FLAT]', '∀n. TAKE n [] = []')]
Time: 0.5091058459997839  
Induct args: []
Preferences: tensor([0.0104, 0.9712, 0.0054, 0.0043, 0.0086])
Proved so far: 31

Game: 158
Initialization done. Main goal is:
∀a b c d x. a ++ [x] ++ b = c ++ [x] ++ d ∧ ¬MEM x b ∧ ¬MEM x a ⇒ a = c ∧ b = d.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -45
Time: 47.485289599000225  
Induct args: ['Vd']
Preferences: tensor([2.6859e-03, 9.9368e-01, 1.3138e-03, 6.6246e-04, 1.6547e-03])
Proved so far: 31

Game: 159
Initialization done. Main goal is:
∀l. NULL l ⇔ l = [].
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'metis_tac', 'fs', 'fs']
Total: -49
Time: 21.218775035999897  
Induct args: ['|']
Preferences: tensor([0.0126, 0.9718, 0.0032, 0.0043, 0.0081])
Proved so far: 31

Game: 160
Initialization done. Main goal is:
∀l1 l2. LENGTH l1 = LENGTH l2 ∧ (∀x. x < LENGTH l1 ⇒ EL x l1 = EL x l2) ⇒ l1 = l2.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.00492076799992  
Induct args: []
Preferences: tensor([0.0083, 0.9726, 0.0026, 0.0070, 0.0095])
Proved so far: 31

Game: 161
Initialization done. Main goal is:
(LIST_REL P (MAP f l1) l2 ⇔ LIST_REL (λx y. P (f x) y) l1 l2) ∧ (LIST_REL Q l1 (MAP g l2) ⇔ LIST_REL (λx y. Q x (g y)) l1 l2).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.519417870000325  
Induct args: []
Preferences: tensor([0.0060, 0.9788, 0.0049, 0.0046, 0.0057])
Proved so far: 31

Game: 162
Initialization done. Main goal is:
oHD [] = NONE ∧ oHD (h::t) = SOME h.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[LIST_GUARD_def, LLEX_def, UNIQUE_DEF, nub_def, oHD_def]', 'oHD [] = NONE ∧ oHD (h::t) = SOME h')]
Time: 0.529126763000022  
Induct args: []
Preferences: tensor([0.0168, 0.9340, 0.0116, 0.0134, 0.0242])
Proved so far: 32

Game: 163
Initialization done. Main goal is:
FINITE s ⇒ SET_TO_LIST s = if s = ∅ then [] else CHOICE s::SET_TO_LIST (REST s).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -47
Time: 22.536146603999896  
Induct args: []
Preferences: tensor([0.0193, 0.9592, 0.0072, 0.0063, 0.0080])
Proved so far: 32

Game: 164
Initialization done. Main goal is:
(∀x. LAST [x] = x) ∧ ∀x y z. LAST (x::y::z) = LAST (y::z).
Proved in 17 steps.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 10]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -6
Proof trace: [('fs[ALL_DISTINCT, INDEX_OF_def, OPT_MMAP_def, LAST_DEF, LIST_LIFT2_def]', '(∀x. LAST [x] = x) ∧ ∀x y z. LAST (x::y::z) = LAST (y::z)')]
Time: 6.973870019999595  
Induct args: []
Preferences: tensor([0.0106, 0.9746, 0.0056, 0.0038, 0.0055])
Proved so far: 33

Game: 165
Initialization done. Main goal is:
(∀P ys. LIST_REL P [] ys ⇔ ys = []) ∧ (∀P yys x xs. LIST_REL P (x::xs) yys ⇔ ∃y ys. yys = y::ys ∧ P x y ∧ LIST_REL P xs ys) ∧ (∀P xs. LIST_REL P xs [] ⇔ xs = []) ∧ ∀P xxs y ys. LIST_REL P xxs (y::ys) ⇔ ∃x xs. xxs = x::xs ∧ P x y ∧ LIST_REL P xs ys.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[INDEX_OF_def, LAST_DEF, INDEX_FIND_def, UNZIP, ZIP_def]', '(∀P ys. LIST_REL P [] ys ⇔ ys = []) ∧ (∀P yys x xs. LIST_REL P (x::xs) yys ⇔ ∃y ys. yys = y::ys ∧ P x y ∧ LIST_REL P xs ys) ∧ (∀P xs. LIST_REL P xs [] ⇔ xs = []) ∧ ∀P xxs y ys. LIST_REL P xxs (y::ys) ⇔ ∃x xs. xxs = x::xs ∧ P x y ∧ LIST_REL P xs ys')]
Time: 0.500947116000134  
Induct args: []
Preferences: tensor([0.0107, 0.9756, 0.0068, 0.0032, 0.0037])
Proved so far: 34

Game: 166
Initialization done. Main goal is:
∀xs n x. LUPDATE x n xs = [] ⇔ xs = [].
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[LIST_LIFT2_def, OPT_MMAP_def, LIST_IGNORE_BIND_def, UNIQUE_DEF, GENLIST_AUX]', '∀xs n x. LUPDATE x n xs = [] ⇔ xs = []')]
Time: 0.5029969689999234  
Induct args: []
Preferences: tensor([0.0075, 0.9697, 0.0075, 0.0047, 0.0106])
Proved so far: 35

Game: 167
Initialization done. Main goal is:
(¬LLEX R [] [] ∧ ¬LLEX R (h1::t1) []) ∧ LLEX R [] (h2::t2) ∧ (LLEX R (h1::t1) (h2::t2) ⇔ R h1 h2 ∨ h1 = h2 ∧ LLEX R t1 t2).
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[splitAtPki_def, EVERYi_def, LIST_GUARD_def, LRC_def, FILTER]', '(¬LLEX R [] [] ∧ ¬LLEX R (h1::t1) []) ∧ LLEX R [] (h2::t2) ∧ (LLEX R (h1::t1) (h2::t2) ⇔ R h1 h2 ∨ h1 = h2 ∧ LLEX R t1 t2)')]
Time: 0.4948106120000375  
Induct args: []
Preferences: tensor([0.0120, 0.9673, 0.0105, 0.0038, 0.0064])
Proved so far: 36

Game: 168
Initialization done. Main goal is:
TAKE 0 l = [].
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[FIND_def, oHD_def, FOLDR, FOLDL, SUM]', 'TAKE 0 l = []')]
Time: 0.48023553300026833  
Induct args: []
Preferences: tensor([0.0323, 0.9117, 0.0146, 0.0227, 0.0187])
Proved so far: 37

Game: 169
Initialization done. Main goal is:
∀P l. EXISTS P l ⇔ ∃e. MEM e l ∧ P e.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.466835044000163  
Induct args: []
Preferences: tensor([1.9930e-03, 9.9382e-01, 1.3033e-03, 6.5289e-04, 2.2313e-03])
Proved so far: 37

Game: 170
Initialization done. Main goal is:
(∀x. P x ⇒ Q x) ⇒ EXISTS P l ⇒ EXISTS Q l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'strip_tac', 'Induct_on', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs']
Total: -47
Time: 20.980593537999994  
Induct args: ['VQ', '@']
Preferences: tensor([0.1119, 0.6770, 0.0907, 0.0475, 0.0729])
Proved so far: 37

Game: 171
Initialization done. Main goal is:
∀f e x l. FOLDL f e (SNOC x l) = f (FOLDL f e l) x.
Failed.
Rewards: [-1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs']
Total: -49
Time: 19.788187678000213  
Induct args: ['Cbool$!', 'Vx']
Preferences: tensor([0.0289, 0.9084, 0.0288, 0.0109, 0.0231])
Proved so far: 37

Game: 172
Initialization done. Main goal is:
∀l1 l2 P. LENGTH l1 = LENGTH l2 ⇒ (EVERY (λx. P (FST x)) (ZIP (l1,l2)) ⇔ EVERY P l1).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.291401524999856  
Induct args: ['@']
Preferences: tensor([5.6182e-03, 9.8770e-01, 9.8668e-04, 1.7931e-03, 3.8972e-03])
Proved so far: 37

Game: 173
Initialization done. Main goal is:
∀ts tt n. n < MIN (LENGTH ts) (LENGTH tt) ⇒ EL n (MAP2 f ts tt) = f (EL n ts) (EL n tt).
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -47
Time: 20.651321710000047  
Induct args: []
Preferences: tensor([0.0279, 0.9436, 0.0145, 0.0073, 0.0068])
Proved so far: 37

Game: 174
Importing theories...
Removing simp lemmas...
Loading modules...
Configuration done.
Initialization done. Main goal is:
∀e L. UNIQUE e L ⇔ LENGTH (FILTER ($= e) L) = 1.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -47
Time: 25.07641321400024  
Induct args: ['@', 'Cbool$!']
Preferences: tensor([2.9752e-03, 9.9357e-01, 1.6870e-03, 8.3753e-04, 9.3017e-04])
Proved so far: 37

Game: 175
Initialization done. Main goal is:
∀l. NULL l ⇔ l = [].
Proved in 11 steps.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 10]
Tactics: ['strip_tac', 'fs', 'fs', 'fs', 'Induct_on', 'metis_tac', 'fs', 'fs', 'Induct_on', 'fs', 'fs']
Total: 6
Proof trace: [('strip_tac', '∀l. NULL l ⇔ l = []'), ('Induct_on `l`', 'NULL l ⇔ l = []'), ('fs[LIST_GUARD_def, FIND_def, LIST_IGNORE_BIND_def, splitAtPki_def, GENLIST_AUX]', 'NULL [] ⇔ [] = []'), ('rpt strip_tac >> fs[FOLDR, EVERYi_def, dropWhile_def, APPEND, LIST_APPLY_def]', '(NULL l ⇔ l = []) ==> (∀h. NULL (h::l) ⇔ h::l = [])')]
Time: 5.112131958000191  
Induct args: ['Cmin$=', 'Vl']
Preferences: tensor([0.0213, 0.9613, 0.0062, 0.0046, 0.0067])
Proved so far: 38

Game: 176
Initialization done. Main goal is:
∀c l. EXISTS (λx. c) l ⇔ l ≠ [] ∧ c.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[FLAT, dropWhile_def, list_case_def, SNOC, ALL_DISTINCT]', '∀c l. EXISTS (λx. c) l ⇔ l ≠ [] ∧ c')]
Time: 0.49597312400010196  
Induct args: []
Preferences: tensor([0.0103, 0.9796, 0.0042, 0.0020, 0.0039])
Proved so far: 39

Game: 177
Initialization done. Main goal is:
∀P l. FILTER P l ≠ l ⇔ ∃x. MEM x l ∧ ¬P x.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.0024270670001  
Induct args: []
Preferences: tensor([0.0101, 0.9739, 0.0089, 0.0046, 0.0025])
Proved so far: 39

Game: 178
Initialization done. Main goal is:
∀P. P [] ∧ (∀l. P l ⇒ ∀a. P (a::l)) ⇒ ∀l. P l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.83029369499991  
Induct args: []
Preferences: tensor([0.0103, 0.9825, 0.0033, 0.0016, 0.0023])
Proved so far: 39

Game: 179
Initialization done. Main goal is:
(∃ls. P ls) ⇔ ∃n f. P (GENLIST f n).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp']
Total: -51
Time: 21.18632604000004  
Induct args: []
Preferences: tensor([0.0123, 0.9650, 0.0042, 0.0056, 0.0129])
Proved so far: 39

Game: 180
Initialization done. Main goal is:
LENGTH (TAKE n xs) = if n ≤ LENGTH xs then n else LENGTH xs.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.56029304699996  
Induct args: []
Preferences: tensor([0.0221, 0.9653, 0.0039, 0.0034, 0.0053])
Proved so far: 39

Game: 181
Initialization done. Main goal is:
∀l1 l1' l2 l2' f f'. l1 = l1' ∧ l2 = l2' ∧ (∀x y. MEM x l1' ∧ MEM y l2' ⇒ f x y = f' x y) ⇒ MAP2 f l1 l2 = MAP2 f' l1' l2'.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.824414330999844  
Induct args: []
Preferences: tensor([0.0100, 0.9806, 0.0061, 0.0013, 0.0020])
Proved so far: 39

Game: 182
Initialization done. Main goal is:
∀xs1 zs. LIST_REL P zs (xs1 ++ xs2) ⇔ ∃ys1 ys2. zs = ys1 ++ ys2 ∧ LIST_REL P ys1 xs1 ∧ LIST_REL P ys2 xs2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac']
Total: -47
Time: 21.000375761000214  
Induct args: []
Preferences: tensor([0.0214, 0.9679, 0.0068, 0.0017, 0.0022])
Proved so far: 39

Game: 183
Initialization done. Main goal is:
(∃l. P l) ⇔ P [] ∨ ∃h t. P (h::t).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.194359178000013  
Induct args: []
Preferences: tensor([0.0274, 0.9563, 0.0058, 0.0028, 0.0077])
Proved so far: 39

Game: 184
Initialization done. Main goal is:
∀l. ZIP (UNZIP l) = l.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[LIST_LIFT2_def, FOLDL, UNZIP, LIST_LIFT2_def, PAD_LEFT]', '∀l. ZIP (UNZIP l) = l')]
Time: 0.5596329139998488  
Induct args: []
Preferences: tensor([0.0832, 0.8174, 0.0433, 0.0135, 0.0426])
Proved so far: 40

Game: 185
Initialization done. Main goal is:
∀xs x y ys. LUPDATE x (LENGTH xs) (xs ++ y::ys) = xs ++ x::ys.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.834771016000104  
Induct args: []
Preferences: tensor([0.0106, 0.9684, 0.0139, 0.0019, 0.0053])
Proved so far: 40

Game: 186
Initialization done. Main goal is:
list_CASE = (λl b f. if NULL l then b else f (HD l) (TL l)).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.611752438000167  
Induct args: []
Preferences: tensor([0.0110, 0.9688, 0.0101, 0.0021, 0.0080])
Proved so far: 40

Game: 187
Initialization done. Main goal is:
∀xs ys xs1 ys1 f. LENGTH xs = LENGTH xs1 ⇒ MAP2 f (xs ++ ys) (xs1 ++ ys1) = MAP2 f xs xs1 ++ MAP2 f ys ys1.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'Induct_on', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -43
Time: 20.57211945300014  
Induct args: ['@']
Preferences: tensor([0.0094, 0.9715, 0.0138, 0.0022, 0.0031])
Proved so far: 40

Game: 188
Initialization done. Main goal is:
∀e L. UNIQUE e L ⇔ LENGTH (FILTER ($= e) L) = 1.
Failed.
Rewards: [-1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -47
Time: 20.844367986999714  
Induct args: []
Preferences: tensor([5.6149e-04, 9.9855e-01, 5.2688e-04, 1.8129e-04, 1.7752e-04])
Proved so far: 40

Game: 189
Initialization done. Main goal is:
∀l n1 n2. ALL_DISTINCT l ∧ n1 < LENGTH l ∧ n2 < LENGTH l ⇒ (EL n1 l = EL n2 l ⇔ n1 = n2).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.595843525999953  
Induct args: []
Preferences: tensor([2.4214e-03, 9.9569e-01, 1.2510e-03, 3.5948e-04, 2.8283e-04])
Proved so far: 40

Game: 190
Initialization done. Main goal is:
∀f g. MAP (f ∘ g) = MAP f ∘ MAP g.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.76647267999988  
Induct args: []
Preferences: tensor([1.7747e-03, 9.9333e-01, 2.5298e-03, 8.2613e-04, 1.5379e-03])
Proved so far: 40

Game: 191
Initialization done. Main goal is:
REVERSE l = [] ⇔ l = [].
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'Induct_on', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs']
Total: -45
Time: 20.85057023499985  
Induct args: ['@', 'Clist$NIL', '@', 'Clist$REVERSE']
Preferences: tensor([0.0251, 0.9086, 0.0221, 0.0114, 0.0328])
Proved so far: 40

Game: 192
Initialization done. Main goal is:
GENLIST f 0 = [] ∧ GENLIST f (NUMERAL n) = GENLIST_AUX f (NUMERAL n) [].
Failed.
Rewards: [-1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.08945428600009  
Induct args: ['@', '@']
Preferences: tensor([0.0142, 0.9379, 0.0145, 0.0055, 0.0279])
Proved so far: 40

Game: 193
Initialization done. Main goal is:
∀P l. ¬EVERY P l ⇔ EXISTS ($~ ∘ P) l.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[INDEX_FIND_def, LUPDATE_def, INDEX_OF_def, REV_DEF, UNZIP]', '∀P l. ¬EVERY P l ⇔ EXISTS ($~ ∘ P) l')]
Time: 0.5230285409998032  
Induct args: []
Preferences: tensor([0.0025, 0.9808, 0.0096, 0.0012, 0.0058])
Proved so far: 41

Game: 194
Initialization done. Main goal is:
MAP2 f x [] = [].
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[EVERYi_def, oEL_def, LRC_def, LIST_BIND_def, ZIP_def]', 'MAP2 f x [] = []')]
Time: 0.5125851180000609  
Induct args: []
Preferences: tensor([0.0376, 0.8914, 0.0245, 0.0110, 0.0356])
Proved so far: 42

Game: 195
Initialization done. Main goal is:
splitAtPki P k (MAP f l) = splitAtPki (combin$C ($o ∘ P) f) (combin$C ($o ∘ k ∘ MAP f) (MAP f)) l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.91893588999983  
Induct args: []
Preferences: tensor([7.7646e-04, 9.9807e-01, 6.9812e-04, 1.8649e-04, 2.6427e-04])
Proved so far: 42

Game: 196
Initialization done. Main goal is:
∀P l. FILTER P l ≠ [] ⇔ ∃x. MEM x l ∧ P x.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.880287773999953  
Induct args: []
Preferences: tensor([0.0048, 0.9843, 0.0076, 0.0018, 0.0016])
Proved so far: 42

Game: 197
Initialization done. Main goal is:
(∀l1 l2. l1 ++ l2 = l1 ⇔ l2 = []) ∧ (∀l1 l2. l1 ++ l2 = l2 ⇔ l1 = []) ∧ (∀l1 l2. l1 = l1 ++ l2 ⇔ l2 = []) ∧ ∀l1 l2. l2 = l1 ++ l2 ⇔ l1 = [].
Proved in 6 steps.
Rewards: [1, -1, -1, -1, -1, 10]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac']
Total: 7
Proof trace: [('fs[ZIP_def, TL_DEF, APPEND, FOLDR, NULL_DEF]', '(∀l1 l2. l1 ++ l2 = l1 ⇔ l2 = []) ∧ (∀l1 l2. l1 ++ l2 = l2 ⇔ l1 = []) ∧ (∀l1 l2. l1 = l1 ++ l2 ⇔ l2 = []) ∧ ∀l1 l2. l2 = l1 ++ l2 ⇔ l1 = []'), ('metis_tac[APPEND, list_TY_DEF, UNZIP, OPT_MMAP_def, EL]', '(∀l2. [] = l2 ⇔ l2 = []) ∧ ∀l1. [] = l1 ⇔ l1 = []')]
Time: 2.568646377999812  
Induct args: []
Preferences: tensor([2.1462e-03, 9.9432e-01, 1.6807e-03, 4.2611e-04, 1.4308e-03])
Proved so far: 43

Game: 198
Initialization done. Main goal is:
list_CASE x v f = v' ⇔ x = [] ∧ v = v' ∨ ∃a l. x = a::l ∧ f a l = v'.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.645968522000203  
Induct args: []
Preferences: tensor([0.0214, 0.9589, 0.0105, 0.0039, 0.0053])
Proved so far: 43

Game: 199
Importing theories...
Removing simp lemmas...
Loading modules...
Configuration done.
Initialization done. Main goal is:
(∀l. LENGTH l = 0 ⇔ l = []) ∧ (∀l n. LENGTH l = SUC n ⇔ ∃h l'. LENGTH l' = n ∧ l = h::l') ∧ ∀l n1 n2. LENGTH l = n1 + n2 ⇔ ∃l1 l2. LENGTH l1 = n1 ∧ LENGTH l2 = n2 ∧ l = l1 ++ l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 25.64415495000003  
Induct args: []
Preferences: tensor([0.0049, 0.9852, 0.0058, 0.0020, 0.0020])
Proved so far: 43

Game: 200
Initialization done. Main goal is:
∀n l. TAKE n l ++ DROP n l = l.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.616068767000343  
Induct args: []
Preferences: tensor([0.0091, 0.9683, 0.0094, 0.0058, 0.0074])
Proved so far: 43

Game: 201
Initialization done. Main goal is:
UNZIP [] = ([],[]) ∧ UNZIP ((x,y)::t) = (let (L1,L2) = UNZIP t in (x::L1,y::L2)).
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.56023185899994  
Induct args: []
Preferences: tensor([0.0067, 0.9812, 0.0050, 0.0040, 0.0031])
Proved so far: 43

Game: 202
Initialization done. Main goal is:
∀l. l ++ [] = l.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[isPREFIX, DROP_def, FILTER, INDEX_FIND_def, SUM]', '∀l. l ++ [] = l')]
Time: 0.4999745999998595  
Induct args: []
Preferences: tensor([0.0769, 0.8296, 0.0318, 0.0182, 0.0435])
Proved so far: 44

Game: 203
Initialization done. Main goal is:
∀l1 l2. SHORTLEX R l1 l2 ⇒ LENGTH l1 ≤ LENGTH l2.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.39824026799988  
Induct args: []
Preferences: tensor([0.0174, 0.9052, 0.0328, 0.0146, 0.0299])
Proved so far: 44

Game: 204
Initialization done. Main goal is:
∀y x l. MEM y (SNOC x l) ⇔ y = x ∨ MEM y l.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[FRONT_DEF, INDEX_FIND_def, LLEX_def, LEN_DEF, SUM]', '∀y x l. MEM y (SNOC x l) ⇔ y = x ∨ MEM y l')]
Time: 0.5226271730002736  
Induct args: []
Preferences: tensor([0.0240, 0.9597, 0.0121, 0.0023, 0.0020])
Proved so far: 45

Game: 205
Initialization done. Main goal is:
∀P. (∀f a b bs c cs. P f (f a b c) bs cs ⇒ P f a (b::bs) (c::cs)) ∧ (∀f a cs. P f a [] cs) ∧ (∀f a v6 v7. P f a (v6::v7) []) ⇒ ∀v v1 v2 v3. P v v1 v2 v3.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs']
Total: -51
Time: 21.587782671999776  
Induct args: []
Preferences: tensor([0.0542, 0.9022, 0.0191, 0.0067, 0.0178])
Proved so far: 45

Game: 206
Initialization done. Main goal is:
∀f n. set (GENLIST f n) = IMAGE f (count n).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.383483311999953  
Induct args: []
Preferences: tensor([0.0366, 0.9399, 0.0119, 0.0046, 0.0070])
Proved so far: 45

Game: 207
Initialization done. Main goal is:
∀n l. n < LENGTH l ⇒ ∀x. EL n (SNOC x l) = EL n l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -45
Time: 21.51987565899981  
Induct args: ['Vn', '|']
Preferences: tensor([0.0198, 0.9519, 0.0088, 0.0068, 0.0127])
Proved so far: 45

Game: 208
Initialization done. Main goal is:
∀l1 l1' l2 l2' P P'. l1 = l1' ∧ l2 = l2' ∧ (∀x y. MEM x l1' ∧ MEM y l2' ⇒ (P x y ⇔ P' x y)) ⇒ (LIST_REL P l1 l2 ⇔ LIST_REL P' l1' l2').
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'strip_tac', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -41
Time: 21.187183707999793  
Induct args: ["Vl1'"]
Preferences: tensor([0.0147, 0.9700, 0.0074, 0.0030, 0.0049])
Proved so far: 45

Game: 209
Initialization done. Main goal is:
[f] <*> l = MAP f l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['metis_tac', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'Induct_on', 'fs', 'simp', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs']
Total: -47
Time: 20.327787725000235  
Induct args: ['Cmin$=', '@', 'Clist$LIST_BIND', '@']
Preferences: tensor([0.0451, 0.8905, 0.0181, 0.0056, 0.0407])
Proved so far: 45

Game: 210
Initialization done. Main goal is:
(∀e n. LUPDATE e n [] = []) ∧ (∀e x l. LUPDATE e 0 (x::l) = e::l) ∧ (∀e n x l. LUPDATE e (NUMERAL (BIT1 n)) (x::l) = x::LUPDATE e (NUMERAL (BIT1 n) − 1) l) ∧ ∀e n x l. LUPDATE e (NUMERAL (BIT2 n)) (x::l) = x::LUPDATE e (NUMERAL (BIT1 n)) l.
Failed.
Rewards: [1, -1, -1, -1, -1, 1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'simp', 'strip_tac', 'fs', 'fs', 'fs', 'strip_tac', 'simp', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'strip_tac', 'simp', 'fs', 'fs', 'fs']
Total: -35
Time: 20.7438144810003  
Induct args: []
Preferences: tensor([0.2143, 0.6751, 0.0752, 0.0095, 0.0260])
Proved so far: 45

Game: 211
Initialization done. Main goal is:
∀x. ALL_DISTINCT [x].
Proved in 17 steps.
Rewards: [-1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 10]
Tactics: ['metis_tac', 'fs', 'strip_tac', 'simp', 'simp', 'fs', 'Induct_on', 'fs', 'fs', 'Induct_on', 'fs', 'metis_tac', 'Induct_on', 'simp', 'simp', 'fs', 'simp']
Total: -4
Proof trace: [('strip_tac', '∀x. ALL_DISTINCT [x]'), ('simp[FOLDR, ALL_DISTINCT, list_case_def, OPT_MMAP_def, LIST_APPLY_def]', 'ALL_DISTINCT [x]')]
Time: 7.939149160999932  
Induct args: ['@', '@', '@']
Preferences: tensor([0.2490, 0.4598, 0.0776, 0.0804, 0.1332])
Proved so far: 46

Game: 212
Initialization done. Main goal is:
(∀l. LENGTH l = 0 ⇔ l = []) ∧ (∀l n. LENGTH l = SUC n ⇔ ∃h l'. LENGTH l' = n ∧ l = h::l') ∧ ∀l n1 n2. LENGTH l = n1 + n2 ⇔ ∃l1 l2. LENGTH l1 = n1 ∧ LENGTH l2 = n2 ∧ l = l1 ++ l2.
Failed.
Rewards: [1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'Induct_on', 'strip_tac', 'fs', 'fs', 'fs', 'strip_tac', 'simp', 'fs', 'fs', 'metis_tac', 'simp', 'fs', 'fs', 'strip_tac', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -39
Time: 21.983458535999944  
Induct args: ['Vn2']
Preferences: tensor([0.0469, 0.9044, 0.0335, 0.0035, 0.0117])
Proved so far: 46

Game: 213
Initialization done. Main goal is:
∀l n. LENGTH l = SUC n ⇔ ∃h l'. LENGTH l' = n ∧ l = h::l'.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.765775294999912  
Induct args: []
Preferences: tensor([0.0363, 0.9218, 0.0262, 0.0061, 0.0097])
Proved so far: 46

Game: 214
Initialization done. Main goal is:
(∀l. LENGTH l = 0 ⇔ l = []) ∧ (∀l n. LENGTH l = SUC n ⇔ ∃h l'. LENGTH l' = n ∧ l = h::l') ∧ ∀l n1 n2. LENGTH l = n1 + n2 ⇔ ∃l1 l2. LENGTH l1 = n1 ∧ LENGTH l2 = n2 ∧ l = l1 ++ l2.
Failed.
Rewards: [1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -47
Time: 21.02658473299971  
Induct args: []
Preferences: tensor([0.0152, 0.9781, 0.0035, 0.0012, 0.0020])
Proved so far: 46

Game: 215
Initialization done. Main goal is:
oEL n (TAKE m xs) = SOME x ⇒ oEL n xs = SOME x.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'Induct_on', 'metis_tac', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'Induct_on', 'metis_tac', 'simp', 'Induct_on', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs']
Total: -43
Time: 21.393338667999615  
Induct args: ['Clist$oEL', '@', '@', 'Vxs', 'Cmin$=']
Preferences: tensor([0.1302, 0.6665, 0.0612, 0.0082, 0.1340])
Proved so far: 46

Game: 216
Initialization done. Main goal is:
(∀l. TAKE 0 l = []) ∧ (∀n. TAKE (NUMERAL (BIT1 n)) [] = []) ∧ (∀n. TAKE (NUMERAL (BIT2 n)) [] = []) ∧ (∀n h t. TAKE (NUMERAL (BIT1 n)) (h::t) = h::TAKE (NUMERAL (BIT1 n) − 1) t) ∧ ∀n h t. TAKE (NUMERAL (BIT2 n)) (h::t) = h::TAKE (NUMERAL (BIT1 n)) t.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'simp', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'simp', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'Induct_on', 'simp', 'metis_tac', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -47
Time: 21.22000058699996  
Induct args: ['Cbool$!', 'Vt', 'Vh', '@', 'Cbool$!']
Preferences: tensor([0.1119, 0.6929, 0.0360, 0.0170, 0.1422])
Proved so far: 46

Game: 217
Initialization done. Main goal is:
∀n. DROP n [] = [].
Proved in 22 steps.
Rewards: [-1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 10]
Tactics: ['fs', 'Induct_on', 'fs', 'simp', 'Induct_on', 'fs', 'strip_tac', 'simp', 'fs', 'simp', 'fs', 'simp', 'strip_tac', 'simp', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs']
Total: -9
Proof trace: [('strip_tac', '∀n. DROP n [] = []'), ('fs[LIST_GUARD_def, DROP_def, LEN_DEF, splitAtPki_def, REVERSE_DEF]', 'DROP n [] = []')]
Time: 8.530877624999903  
Induct args: ['@', '@']
Preferences: tensor([0.3338, 0.5575, 0.0303, 0.0167, 0.0618])
Proved so far: 47

Game: 218
Initialization done. Main goal is:
(∀l. DROP 0 l = l) ∧ (∀n. DROP (NUMERAL (BIT1 n)) [] = []) ∧ (∀n. DROP (NUMERAL (BIT2 n)) [] = []) ∧ (∀n h t. DROP (NUMERAL (BIT1 n)) (h::t) = DROP (NUMERAL (BIT1 n) − 1) t) ∧ ∀n h t. DROP (NUMERAL (BIT2 n)) (h::t) = DROP (NUMERAL (BIT1 n)) t.
Failed.
Rewards: [-1, -1, -1, -1, 1, 1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'simp', 'simp', 'simp', 'strip_tac', 'strip_tac', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'simp', 'fs', 'simp', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs']
Total: -45
Time: 20.010086069999943  
Induct args: ['@']
Preferences: tensor([0.1480, 0.7922, 0.0179, 0.0100, 0.0320])
Proved so far: 47

Game: 219
Initialization done. Main goal is:
LENGTH ∘ REVERSE = LENGTH ∧ LENGTH ∘ REVERSE ∘ f = LENGTH ∘ f.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.734652059999462  
Induct args: []
Preferences: tensor([5.3129e-03, 9.8798e-01, 3.6168e-03, 8.9973e-04, 2.1883e-03])
Proved so far: 47

Game: 220
Initialization done. Main goal is:
∀f1 f2 l. MAP f1 l = MAP f2 l ⇔ ∀e. MEM e l ⇒ f1 e = f2 e.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.706821771999785  
Induct args: []
Preferences: tensor([0.0088, 0.9834, 0.0033, 0.0013, 0.0032])
Proved so far: 47

Game: 221
Initialization done. Main goal is:
∀P l h lr. FILTER P l = h::lr ⇔ ∃l1 l2. l = l1 ++ [h] ++ l2 ∧ FILTER P l1 = [] ∧ FILTER P l2 = lr ∧ P h.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.75360833600007  
Induct args: ['|']
Preferences: tensor([0.0755, 0.8523, 0.0338, 0.0036, 0.0347])
Proved so far: 47

Game: 222
Initialization done. Main goal is:
∀n f g. GENLIST f n = GENLIST g n ⇔ ∀x. x < n ⇒ f x = g x.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.69883801800006  
Induct args: []
Preferences: tensor([0.0103, 0.9809, 0.0036, 0.0010, 0.0042])
Proved so far: 47

Game: 223
Initialization done. Main goal is:
∀l1 l2. LENGTH l1 = LENGTH l2 ⇒ (ZIP (l1,l2) = [] ⇔ l1 = [] ∧ l2 = []).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'metis_tac', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'simp']
Total: -31
Time: 21.6323265230003  
Induct args: ['Vl1', 'Cbool$F']
Preferences: tensor([0.2005, 0.7237, 0.0200, 0.0092, 0.0466])
Proved so far: 47

Game: 224
Importing theories...
Removing simp lemmas...
Loading modules...
Configuration done.
Initialization done. Main goal is:
∀P Q l. EVERY (λx. P x ∧ Q x) l ⇔ EVERY P l ∧ EVERY Q l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs']
Total: -47
Time: 25.44010724600048  
Induct args: []
Preferences: tensor([0.0771, 0.9003, 0.0090, 0.0035, 0.0101])
Proved so far: 47

Game: 225
Initialization done. Main goal is:
∀f l1 l2. INJ f (set l1 ∪ set l2) 𝕌(:β) ⇒ (MAP f l1 = MAP f l2 ⇔ l1 = l2).
Failed.
Rewards: [-1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'strip_tac', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -45
Time: 20.740493319000052  
Induct args: []
Preferences: tensor([3.3458e-02, 9.5866e-01, 3.8338e-03, 9.3974e-04, 3.1042e-03])
Proved so far: 47

Game: 226
Initialization done. Main goal is:
∀l1 l2 P P'. l1 = l2 ∧ (∀x. MEM x l2 ⇒ (P x ⇔ P' x)) ⇒ (EVERY P l1 ⇔ EVERY P' l2).
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs']
Total: -47
Time: 21.307457378000436  
Induct args: []
Preferences: tensor([0.0499, 0.9190, 0.0150, 0.0060, 0.0100])
Proved so far: 47

Game: 227
Initialization done. Main goal is:
TAKE 0 l = [].
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[EVERYi_def, LIST_IGNORE_BIND_def, SUM, LAST_DEF, isPREFIX]', 'TAKE 0 l = []')]
Time: 0.5401082779999342  
Induct args: []
Preferences: tensor([0.3273, 0.6164, 0.0158, 0.0106, 0.0299])
Proved so far: 48

Game: 228
Initialization done. Main goal is:
SET_TO_LIST {x} = [x].
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'simp', 'fs', 'fs', 'strip_tac', 'simp', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs']
Total: -49
Time: 20.80667738000011  
Induct args: ['@']
Preferences: tensor([0.1629, 0.8110, 0.0086, 0.0029, 0.0146])
Proved so far: 48

Game: 229
Initialization done. Main goal is:
∀n l. LENGTH (DROP n l) = LENGTH l − n.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs']
Total: -49
Time: 20.468003078999573  
Induct args: ['@', 'Carithmetic$-']
Preferences: tensor([0.1832, 0.7979, 0.0054, 0.0020, 0.0116])
Proved so far: 48

Game: 230
Initialization done. Main goal is:
∀R l1 l2. LIST_REL R l1 l2 ⇔ LENGTH l1 = LENGTH l2 ∧ EVERY (UNCURRY R) (ZIP (l1,l2)).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs']
Total: -49
Time: 20.704355253999893  
Induct args: []
Preferences: tensor([0.3149, 0.6106, 0.0152, 0.0100, 0.0492])
Proved so far: 48

Game: 231
Initialization done. Main goal is:
∀xs n y. oEL n xs = SOME y ⇔ n < LENGTH xs ∧ y = EL n xs.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.922671014000116  
Induct args: []
Preferences: tensor([5.3200e-02, 9.4103e-01, 2.2919e-03, 6.2366e-04, 2.8525e-03])
Proved so far: 48

Game: 232
Initialization done. Main goal is:
(LIST_REL R [] y ⇔ y = []) ∧ (LIST_REL R x [] ⇔ x = []).
Proved in 1 steps.
Rewards: [10]
Tactics: ['simp']
Total: 10
Proof trace: [('simp[LUPDATE_def, isPREFIX, FILTER, LIST_GUARD_def, LIST_GUARD_def]', '(LIST_REL R [] y ⇔ y = []) ∧ (LIST_REL R x [] ⇔ x = [])')]
Time: 0.4804969139995592  
Induct args: []
Preferences: tensor([0.3848, 0.5638, 0.0080, 0.0051, 0.0382])
Proved so far: 49

Game: 233
Initialization done. Main goal is:
∀l1 l1' l2 l2' a a' f f'. l1 = l1' ∧ l2 = l2' ∧ a = a' ∧ (∀z b c. MEM b l1' ∧ MEM c l2' ⇒ f z b c = f' z b c) ⇒ FOLDL2 f a l1 l2 = FOLDL2 f' a' l1' l2'.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'fs', 'fs', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'simp', 'fs', 'Induct_on', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'simp', 'fs', 'simp', 'Induct_on', 'fs', 'simp', 'simp', 'fs', 'simp', 'Induct_on', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp']
Total: -49
Time: 20.446417591999307  
Induct args: ['Cbool$!', "Va'", '|']
Preferences: tensor([0.5169, 0.4697, 0.0034, 0.0023, 0.0077])
Proved so far: 49

Game: 234
Initialization done. Main goal is:
f (splitAtPki P k l) = splitAtPki P ($o f ∘ k) l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'simp', 'Induct_on', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.275045330000466  
Induct args: ['@']
Preferences: tensor([4.5686e-02, 9.4721e-01, 1.1802e-03, 6.3381e-04, 5.2880e-03])
Proved so far: 49

Game: 235
Initialization done. Main goal is:
∀l1 l2 n. EL n (l1 ++ l2) = if n < LENGTH l1 then EL n l1 else EL (n − LENGTH l1) l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'strip_tac', 'fs', 'fs']
Total: -47
Time: 20.554997702000037  
Induct args: ['@']
Preferences: tensor([0.1326, 0.8456, 0.0059, 0.0036, 0.0123])
Proved so far: 49

Game: 236
Initialization done. Main goal is:
∀ls n. ALL_DISTINCT ls ⇒ ALL_DISTINCT (DROP n ls).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.093853369999124  
Induct args: ['Clist$ALL_DISTINCT', '@']
Preferences: tensor([0.1034, 0.8487, 0.0236, 0.0032, 0.0210])
Proved so far: 49

Game: 237
Initialization done. Main goal is:
∀l x. MEM x l ⇔ ∃n. n < LENGTH l ∧ x = EL n l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.742784109999775  
Induct args: []
Preferences: tensor([0.0564, 0.9340, 0.0046, 0.0024, 0.0026])
Proved so far: 49

Game: 238
Initialization done. Main goal is:
EVERY P (FLAT ls) ⇔ EVERY (EVERY P) ls.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'simp', 'simp', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'simp', 'fs', 'simp', 'simp', 'simp', 'Induct_on', 'fs', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'fs', 'simp', 'simp', 'fs', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs']
Total: -51
Time: 20.252731593000135  
Induct args: ['@']
Preferences: tensor([0.4792, 0.4655, 0.0119, 0.0043, 0.0391])
Proved so far: 49

Game: 239
Initialization done. Main goal is:
∀n m l. TAKE (n + m) l = TAKE n l ++ TAKE m (DROP n l).
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.409030328999506  
Induct args: ['@']
Preferences: tensor([0.0582, 0.9264, 0.0063, 0.0035, 0.0057])
Proved so far: 49

Game: 240
Initialization done. Main goal is:
∀f x ls. MEM x ls ⇒ f x ≤ SUM (MAP f ls).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.735235060999912  
Induct args: []
Preferences: tensor([0.0660, 0.9237, 0.0049, 0.0019, 0.0035])
Proved so far: 49

Game: 241
Initialization done. Main goal is:
GENLIST f (SUC n) = f 0::GENLIST (f ∘ SUC) n.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.80134198199994  
Induct args: []
Preferences: tensor([7.5200e-03, 9.8979e-01, 5.3047e-04, 2.1718e-04, 1.9430e-03])
Proved so far: 49

Game: 242
Initialization done. Main goal is:
∀l1 l2. ALL_DISTINCT (ZIP (l1,l2)) ∧ LENGTH l1 = LENGTH l2 ⇒ ALL_DISTINCT (ZIP (l2,l1)).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.706522495000172  
Induct args: []
Preferences: tensor([0.0296, 0.9455, 0.0064, 0.0023, 0.0161])
Proved so far: 49

Game: 243
Initialization done. Main goal is:
∀x l. LENGTH (SNOC x l) = SUC (LENGTH l).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.781800687000214  
Induct args: []
Preferences: tensor([5.5117e-03, 9.9090e-01, 1.2409e-03, 3.7681e-04, 1.9698e-03])
Proved so far: 49

Game: 244
Initialization done. Main goal is:
∀l1 l2 l3. l1 ++ (l2 ++ l3) = l1 ++ l2 ++ l3.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[EVERYi_def, splitAtPki_def, LIST_GUARD_def, oHD_def, LIST_BIND_def]', '∀l1 l2 l3. l1 ++ (l2 ++ l3) = l1 ++ l2 ++ l3')]
Time: 0.5015672370000175  
Induct args: []
Preferences: tensor([1.2100e-02, 9.8435e-01, 1.4206e-03, 7.5936e-04, 1.3743e-03])
Proved so far: 50

Game: 245
Initialization done. Main goal is:
GENLIST f (SUC n) = f 0::GENLIST (f ∘ SUC) n.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.638051574999736  
Induct args: []
Preferences: tensor([1.5576e-02, 9.8088e-01, 6.9823e-04, 2.5036e-04, 2.5988e-03])
Proved so far: 50

Game: 246
Initialization done. Main goal is:
∀f n. set (GENLIST f n) = IMAGE f (count n).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.356907923999643  
Induct args: []
Preferences: tensor([5.2889e-03, 9.8962e-01, 3.3318e-03, 4.9453e-04, 1.2645e-03])
Proved so far: 50

Game: 247
Initialization done. Main goal is:
∀l1 l2 f1 f2. LENGTH l1 = LENGTH l2 ⇒ ZIP (MAP f1 l1,l2) = MAP (λp. (f1 (FST p),SND p)) (ZIP (l1,l2)) ∧ ZIP (l1,MAP f2 l2) = MAP (λp. (FST p,f2 (SND p))) (ZIP (l1,l2)).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'fs', 'fs']
Total: -51
Time: 21.03566741100076  
Induct args: []
Preferences: tensor([0.2779, 0.6937, 0.0073, 0.0033, 0.0178])
Proved so far: 50

Game: 248
Initialization done. Main goal is:
REVERSE l = [e] ⇔ l = [e].
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.059893980999732  
Induct args: ['@']
Preferences: tensor([5.2858e-02, 9.4089e-01, 2.1462e-03, 5.6340e-04, 3.5460e-03])
Proved so far: 50

Game: 249
Importing theories...
Removing simp lemmas...
Loading modules...
Configuration done.
Initialization done. Main goal is:
0 < n ⇒ TAKE n (x::xs) = x::TAKE (n − 1) xs.
Proved in 2 steps.
Rewards: [-1, 10]
Tactics: ['fs', 'fs']
Total: 9
Proof trace: [('fs[SHORTLEX_def, TAKE_def, FOLDR, nub_def, INDEX_OF_def]', '0 < n ⇒ TAKE n (x::xs) = x::TAKE (n − 1) xs')]
Time: 5.546125300999847  
Induct args: []
Preferences: tensor([9.2345e-02, 9.0274e-01, 1.5119e-03, 7.9436e-04, 2.6043e-03])
Proved so far: 51

Game: 250
Initialization done. Main goal is:
∀l1 l2 P. LENGTH l1 = LENGTH l2 ⇒ (EVERY (λx. P (FST x)) (ZIP (l1,l2)) ⇔ EVERY P l1).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.85415508599999  
Induct args: []
Preferences: tensor([0.0333, 0.9626, 0.0013, 0.0011, 0.0017])
Proved so far: 51

Game: 251
Initialization done. Main goal is:
∀l P. EVERY P l ⇔ ∀n. n < LENGTH l ⇒ P (EL n l).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.39779605500007  
Induct args: ['@']
Preferences: tensor([0.1319, 0.8323, 0.0069, 0.0049, 0.0239])
Proved so far: 51

Game: 252
Initialization done. Main goal is:
∀P l1 l2. EVERY P l1 ⇒ dropWhile P (l1 ++ l2) = dropWhile P l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.99397763900015  
Induct args: []
Preferences: tensor([0.1441, 0.8265, 0.0143, 0.0072, 0.0079])
Proved so far: 51

Game: 253
Initialization done. Main goal is:
∀l. 0 < LENGTH l ⇒ LENGTH (TL l) = LENGTH l − 1.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.886684852000144  
Induct args: []
Preferences: tensor([2.7558e-02, 9.6590e-01, 2.8106e-03, 6.8283e-04, 3.0465e-03])
Proved so far: 51

Game: 254
Initialization done. Main goal is:
(∀f. MAP2 f [] [] = []) ∧ ∀f h1 t1 h2 t2. MAP2 f (h1::t1) (h2::t2) = f h1 h2::MAP2 f t1 t2.
Proved in 1 steps.
Rewards: [10]
Tactics: ['simp']
Total: 10
Proof trace: [('simp[LUPDATE_def, HD, ALL_DISTINCT, LUPDATE_def, LEN_DEF]', '(∀f. MAP2 f [] [] = []) ∧ ∀f h1 t1 h2 t2. MAP2 f (h1::t1) (h2::t2) = f h1 h2::MAP2 f t1 t2')]
Time: 0.5189180819998  
Induct args: []
Preferences: tensor([0.5562, 0.3978, 0.0193, 0.0064, 0.0204])
Proved so far: 52

Game: 255
Initialization done. Main goal is:
∀n l. n < LENGTH l ⇒ ∀x. EL n (SNOC x l) = EL n l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.604265633999603  
Induct args: []
Preferences: tensor([3.7576e-03, 9.9390e-01, 1.1040e-03, 3.8591e-04, 8.5560e-04])
Proved so far: 52

Game: 256
Initialization done. Main goal is:
set [] = ∅ ∧ set (h::t) = h INSERT set t.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[MAP, PAD_RIGHT, FOLDR, dropWhile_def, LEN_DEF]', 'set [] = ∅ ∧ set (h::t) = h INSERT set t')]
Time: 0.52005149300021  
Induct args: []
Preferences: tensor([4.5526e-03, 9.9235e-01, 5.9547e-04, 5.6585e-04, 1.9344e-03])
Proved so far: 53

Game: 257
Initialization done. Main goal is:
EL (NUMERAL (BIT1 n)) (l::ls) = EL (PRE (NUMERAL (BIT1 n))) ls ∧ EL (NUMERAL (BIT2 n)) (l::ls) = EL (NUMERAL (BIT1 n)) ls.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.005253472999357  
Induct args: []
Preferences: tensor([7.1361e-03, 9.9123e-01, 9.2931e-04, 3.0695e-04, 3.9355e-04])
Proved so far: 53

Game: 258
Initialization done. Main goal is:
splitAtPki P k (MAP f l) = splitAtPki (combin$C ($o ∘ P) f) (combin$C ($o ∘ k ∘ MAP f) (MAP f)) l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.784312609000153  
Induct args: []
Preferences: tensor([3.0733e-03, 9.9612e-01, 4.2327e-04, 8.4052e-05, 2.9551e-04])
Proved so far: 53

Game: 259
Initialization done. Main goal is:
∀x l. LAST (SNOC x l) = x.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.363637464999556  
Induct args: ['@']
Preferences: tensor([0.0220, 0.9483, 0.0101, 0.0015, 0.0181])
Proved so far: 53

Game: 260
Initialization done. Main goal is:
∀s. FINITE s ⇒ LENGTH (SET_TO_LIST s) = CARD s.
Failed.
Rewards: [-1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'Induct_on', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'simp', 'simp', 'fs', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'simp', 'strip_tac', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp']
Total: -47
Time: 21.442407874999844  
Induct args: ['@']
Preferences: tensor([0.2501, 0.7364, 0.0067, 0.0014, 0.0052])
Proved so far: 53

Game: 261
Initialization done. Main goal is:
(∀x. LAST [x] = x) ∧ ∀x y z. LAST (x::y::z) = LAST (y::z).
Proved in 2 steps.
Rewards: [-1, 10]
Tactics: ['fs', 'fs']
Total: 9
Proof trace: [('fs[NULL_DEF, LAST_DEF, list_case_def, SUM_ACC_DEF, TAKE_def]', '(∀x. LAST [x] = x) ∧ ∀x y z. LAST (x::y::z) = LAST (y::z)')]
Time: 0.9228638799995679  
Induct args: []
Preferences: tensor([0.0474, 0.9425, 0.0051, 0.0020, 0.0031])
Proved so far: 54

Game: 262
Initialization done. Main goal is:
∀ls n. ALL_DISTINCT ls ⇒ ALL_DISTINCT (DROP n ls).
Failed.
Rewards: [-1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'Induct_on', 'simp', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'strip_tac', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs']
Total: -35
Time: 20.37761543200031  
Induct args: ['Vls', '@', 'Vn']
Preferences: tensor([0.0621, 0.9210, 0.0067, 0.0019, 0.0082])
Proved so far: 54

Game: 263
Initialization done. Main goal is:
(∀i. i < LENGTH l ⇒ (P1 i (EL i l) ⇔ P2 i (EL i l))) ⇒ splitAtPki P1 k l = splitAtPki P2 k l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.42246350700043  
Induct args: []
Preferences: tensor([1.1694e-02, 9.8662e-01, 7.9205e-04, 1.5966e-04, 7.3021e-04])
Proved so far: 54

Game: 264
Initialization done. Main goal is:
l1 ++ l2 = h::t ⇔ l1 = [] ∧ l2 = h::t ∨ ∃lt. l1 = h::lt ∧ t = lt ++ l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'simp', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'strip_tac', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 19.795038644999295  
Induct args: ['@']
Preferences: tensor([0.2221, 0.7325, 0.0367, 0.0052, 0.0035])
Proved so far: 54

Game: 265
Initialization done. Main goal is:
(∀i. i < LENGTH l ⇒ (P1 i (EL i l) ⇔ P2 i (EL i l))) ⇒ splitAtPki P1 k l = splitAtPki P2 k l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.825748602000203  
Induct args: []
Preferences: tensor([1.4179e-02, 9.8452e-01, 5.9117e-04, 1.4210e-04, 5.6514e-04])
Proved so far: 54

Game: 266
Initialization done. Main goal is:
∀l1 l2. REVERSE l1 = REVERSE l2 ⇔ l1 = l2.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs']
Total: -47
Time: 20.37143790600021  
Induct args: []
Preferences: tensor([0.1281, 0.8469, 0.0096, 0.0037, 0.0118])
Proved so far: 54

Game: 267
Initialization done. Main goal is:
(∀x y. R1 x y ⇒ R2 y x) ⇒ ∀x y. LIST_REL R1 x y ⇒ LIST_REL R2 y x.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.197792816999936  
Induct args: []
Preferences: tensor([9.5615e-03, 9.8837e-01, 1.2729e-03, 3.3391e-04, 4.6392e-04])
Proved so far: 54

Game: 268
Initialization done. Main goal is:
∀P. (∀s. (FINITE s ∧ s ≠ ∅ ⇒ P (REST s)) ⇒ P s) ⇒ ∀v. P v.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.82095769099942  
Induct args: []
Preferences: tensor([1.9226e-02, 9.7824e-01, 1.7978e-03, 3.8459e-04, 3.4668e-04])
Proved so far: 54

Game: 269
Initialization done. Main goal is:
∀f l1 l2. INJ f (set l1 ∪ set l2) 𝕌(:β) ⇒ (MAP f l1 = MAP f l2 ⇔ l1 = l2).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'strip_tac', 'fs']
Total: -47
Time: 20.925142590999712  
Induct args: []
Preferences: tensor([0.0209, 0.9707, 0.0049, 0.0014, 0.0021])
Proved so far: 54

Game: 270
Initialization done. Main goal is:
LRC R (h::t) x y ∧ MEM e t ⇒ ∃z p. R z e ∧ LRC R p x z.
Failed.
Rewards: [-1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.722163256000385  
Induct args: []
Preferences: tensor([6.4097e-02, 9.2856e-01, 5.5017e-03, 1.1723e-03, 6.6952e-04])
Proved so far: 54

Game: 271
Initialization done. Main goal is:
x ≼ [] ⇔ x = [].
Proved in 1 steps.
Rewards: [10]
Tactics: ['simp']
Total: 10
Proof trace: [('simp[LAST_DEF, DROP_def, list_TY_DEF, ZIP_def, isPREFIX]', 'x ≼ [] ⇔ x = []')]
Time: 0.4949445559996093  
Induct args: []
Preferences: tensor([0.5429, 0.4019, 0.0236, 0.0091, 0.0226])
Proved so far: 55

Game: 272
Initialization done. Main goal is:
LIST_BIND l (λx. [x]) = l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'simp', 'simp', 'fs', 'simp', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'simp', 'fs', 'strip_tac', 'fs', 'simp', 'simp', 'fs', 'fs', 'simp', 'strip_tac', 'fs', 'fs', 'fs', 'simp', 'Induct_on', 'simp', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'simp', 'fs', 'Induct_on', 'fs', 'fs', 'fs']
Total: -49
Time: 20.04118318900055  
Induct args: ['Clist$CONS', '@']
Preferences: tensor([0.3111, 0.6178, 0.0310, 0.0073, 0.0327])
Proved so far: 55

Game: 273
Initialization done. Main goal is:
∀L1 L2. REV L1 L2 = REVERSE L1 ++ L2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs']
Total: -47
Time: 22.418846534000295  
Induct args: []
Preferences: tensor([0.2299, 0.7139, 0.0314, 0.0069, 0.0178])
Proved so far: 55

Game: 274
Importing theories...
Removing simp lemmas...
Loading modules...
Configuration done.
Initialization done. Main goal is:
∀l. TAKE (LENGTH l) l = l.
Proved in 27 steps.
Rewards: [-1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 10]
Tactics: ['fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -8
Proof trace: [('Induct_on `l`', '∀l. TAKE (LENGTH l) l = l'), ('fs[LRC_def, SET_TO_LIST_primitive_def, DROP_def, INDEX_FIND_def, SNOC]', 'TAKE (LENGTH []) [] = []'), ('rpt strip_tac >> fs[splitAtPki_def, splitAtPki_def, UNIQUE_DEF, list_size_def, NULL_DEF]', '(TAKE (LENGTH l) l = l) ==> (∀h. TAKE (LENGTH (h::l)) (h::l) = h::l)'), ('rpt strip_tac >> fs[OPT_MMAP_def, TAKE_def, GENLIST_AUX, ZIP_def, nub_def]', '(TAKE (LENGTH l) l = l) ==> (TAKE (LENGTH (h::l)) (h::l) = h::l)'), ('rpt strip_tac >> fs[LENGTH, FLAT, dropWhile_def, FILTER, FOLDL]', '(TAKE (LENGTH l) l = l) ==> (TAKE (LENGTH (h::l) − 1) l = l)')]
Time: 15.291136431000268  
Induct args: ['Vl']
Preferences: tensor([0.0426, 0.9500, 0.0042, 0.0010, 0.0022])
Proved so far: 56

Game: 275
Initialization done. Main goal is:
∀P ls x. MEM x (dropWhile P ls) ⇒ MEM x ls.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs']
Total: -49
Time: 20.84712012900036  
Induct args: []
Preferences: tensor([0.0114, 0.9758, 0.0094, 0.0017, 0.0017])
Proved so far: 56

Game: 276
Initialization done. Main goal is:
∀l. ALL_DISTINCT l ⇔ ∀n1 n2. n1 < LENGTH l ∧ n2 < LENGTH l ⇒ (EL n1 l = EL n2 l ⇔ n1 = n2).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'strip_tac', 'fs', 'simp', 'simp', 'fs', 'fs', 'simp', 'Induct_on', 'Induct_on', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs']
Total: -49
Time: 21.338759215999744  
Induct args: ['Cmin$=', 'Cbool$/\\']
Preferences: tensor([0.3248, 0.6143, 0.0223, 0.0111, 0.0276])
Proved so far: 56

Game: 277
Initialization done. Main goal is:
∀l1 l2 P. LENGTH l1 = LENGTH l2 ⇒ (EVERY (λx. P (SND x)) (ZIP (l1,l2)) ⇔ EVERY P l2).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.559756812999694  
Induct args: []
Preferences: tensor([4.8449e-03, 9.9162e-01, 1.6933e-03, 9.3886e-04, 8.9858e-04])
Proved so far: 56

Game: 278
Initialization done. Main goal is:
∀l1 l2. LENGTH l1 = LENGTH l2 ∧ (∀x. x < LENGTH l1 ⇒ EL x l1 = EL x l2) ⇒ l1 = l2.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'Induct_on', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'metis_tac', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp']
Total: -51
Time: 22.663273756999843  
Induct args: ['Cbool$!', '@', '@']
Preferences: tensor([0.1015, 0.8277, 0.0199, 0.0368, 0.0141])
Proved so far: 56

Game: 279
Initialization done. Main goal is:
∀P Q. (∀x. P x ⇒ Q x) ⇒ ∀ls. LENGTH (FILTER P ls) ≤ LENGTH (FILTER Q ls).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.553256834999956  
Induct args: []
Preferences: tensor([1.5013e-02, 9.7366e-01, 9.5700e-03, 1.1075e-03, 6.5231e-04])
Proved so far: 56

Game: 280
Initialization done. Main goal is:
list_CASE x v f = v' ⇔ x = [] ∧ v = v' ∨ ∃a l. x = a::l ∧ f a l = v'.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'simp', 'fs', 'simp', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'simp', 'fs', 'fs', 'simp', 'simp', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs']
Total: -51
Time: 21.016267915000753  
Induct args: []
Preferences: tensor([0.3801, 0.5782, 0.0268, 0.0072, 0.0078])
Proved so far: 56

Game: 281
Initialization done. Main goal is:
LIST_BIND l (λx. [x]) = l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'simp', 'fs', 'simp', 'Induct_on', 'fs', 'simp', 'fs', 'simp', 'fs', 'Induct_on', 'fs', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'simp', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs']
Total: -49
Time: 19.684961447000205  
Induct args: ['@', '@', 'Clist$FLAT', '@']
Preferences: tensor([0.2297, 0.5997, 0.0678, 0.0141, 0.0887])
Proved so far: 56

Game: 282
Initialization done. Main goal is:
∀ll. ll = [] ∨ ∃x l. ll = SNOC x l.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -47
Time: 20.840484338999886  
Induct args: []
Preferences: tensor([0.0722, 0.9058, 0.0128, 0.0043, 0.0050])
Proved so far: 56

Game: 283
Initialization done. Main goal is:
∀n l. n < LENGTH l ⇒ TAKE 1 (DROP n l) = [EL n l].
Failed.
Rewards: [-1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -47
Time: 20.575425616000757  
Induct args: []
Preferences: tensor([2.8259e-03, 9.9454e-01, 2.3722e-03, 1.6181e-04, 9.6277e-05])
Proved so far: 56

Game: 284
Initialization done. Main goal is:
¬SHORTLEX R l [].
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[FRONT_DEF, LAST_DEF, LIST_BIND_def, EVERYi_def, LIST_APPLY_def]', '¬SHORTLEX R l []')]
Time: 0.5224372739994578  
Induct args: []
Preferences: tensor([0.4724, 0.4612, 0.0322, 0.0187, 0.0156])
Proved so far: 57

Game: 285
Initialization done. Main goal is:
NULL [] ∧ ∀h t. ¬NULL (h::t).
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[LAST_DEF, HD, INDEX_FIND_def, SNOC, UNIQUE_DEF]', 'NULL [] ∧ ∀h t. ¬NULL (h::t)')]
Time: 0.4939267979998476  
Induct args: []
Preferences: tensor([9.4346e-03, 9.8328e-01, 4.3190e-03, 9.5824e-04, 2.0093e-03])
Proved so far: 58

Game: 286
Initialization done. Main goal is:
∀l1 l2 f f'. l1 = l2 ∧ (∀x. MEM x l2 ⇒ f x = f' x) ⇒ MAP f l1 = MAP f' l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.492208071000277  
Induct args: []
Preferences: tensor([0.1079, 0.8667, 0.0192, 0.0031, 0.0031])
Proved so far: 58

Game: 287
Initialization done. Main goal is:
∀l1 l2 l3. l1 ++ (l2 ++ l3) = l1 ++ l2 ++ l3.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[UNIQUE_DEF, FLAT, UNIQUE_DEF, SHORTLEX_def, LIST_APPLY_def]', '∀l1 l2 l3. l1 ++ (l2 ++ l3) = l1 ++ l2 ++ l3')]
Time: 0.5221679839996796  
Induct args: []
Preferences: tensor([3.3640e-03, 9.9163e-01, 3.7045e-03, 8.4288e-04, 4.6232e-04])
Proved so far: 59

Game: 288
Initialization done. Main goal is:
∀l. REVERSE (REVERSE l) = l.
Failed.
Rewards: [-1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'metis_tac', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'strip_tac', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'simp', 'fs', 'fs', 'strip_tac', 'fs']
Total: -49
Time: 20.652581041000303  
Induct args: ['@']
Preferences: tensor([0.2089, 0.7178, 0.0345, 0.0127, 0.0261])
Proved so far: 59

Game: 289
Initialization done. Main goal is:
∀xs n. oEL n xs = if n < LENGTH xs then SOME (EL n xs) else NONE.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.66693856999973  
Induct args: []
Preferences: tensor([0.0109, 0.9656, 0.0178, 0.0020, 0.0036])
Proved so far: 59

Game: 290
Initialization done. Main goal is:
∀l1 l1' l2 l2' a a' f f'. l1 = l1' ∧ l2 = l2' ∧ a = a' ∧ (∀z b c. MEM b l1' ∧ MEM c l2' ⇒ f z b c = f' z b c) ⇒ FOLDL2 f a l1 l2 = FOLDL2 f' a' l1' l2'.
Failed.
Rewards: [1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'simp', 'simp', 'simp', 'simp', 'strip_tac', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'simp', 'fs', 'fs', 'simp', 'simp', 'fs', 'simp', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp']
Total: -47
Time: 20.69792076199974  
Induct args: []
Preferences: tensor([0.3728, 0.5719, 0.0486, 0.0027, 0.0040])
Proved so far: 59

Game: 291
Initialization done. Main goal is:
(∀f. MAP2 f [] [] = []) ∧ ∀f h1 t1 h2 t2. MAP2 f (h1::t1) (h2::t2) = f h1 h2::MAP2 f t1 t2.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[NULL_DEF, LIST_GUARD_def, LIST_APPLY_def, ALL_DISTINCT, LIST_APPLY_def]', '(∀f. MAP2 f [] [] = []) ∧ ∀f h1 t1 h2 t2. MAP2 f (h1::t1) (h2::t2) = f h1 h2::MAP2 f t1 t2')]
Time: 0.48686441100016964  
Induct args: []
Preferences: tensor([0.5993, 0.3424, 0.0378, 0.0096, 0.0109])
Proved so far: 60

Game: 292
Initialization done. Main goal is:
x ≼ [] ⇔ x = [].
Proved in 1 steps.
Rewards: [10]
Tactics: ['simp']
Total: 10
Proof trace: [('simp[LIST_IGNORE_BIND_def, APPEND, LEN_DEF, EVERY_DEF, SUM]', 'x ≼ [] ⇔ x = []')]
Time: 0.48637881300055597  
Induct args: []
Preferences: tensor([0.5728, 0.3532, 0.0367, 0.0125, 0.0248])
Proved so far: 61

Game: 293
Initialization done. Main goal is:
fs <*> [x] = [(λf. f x)] <*> fs.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -43
Time: 20.771171924000555  
Induct args: []
Preferences: tensor([2.4708e-02, 9.6453e-01, 7.9860e-03, 8.4833e-04, 1.9241e-03])
Proved so far: 61

Game: 294
Initialization done. Main goal is:
LIST_REL R l1 l2 ∧ LIST_REL R l3 l4 ⇔ LIST_REL R (l1 ++ l3) (l2 ++ l4) ∧ LENGTH l1 = LENGTH l2 ∧ LENGTH l3 = LENGTH l4.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'simp', 'fs', 'simp', 'metis_tac', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.914915886000017  
Induct args: []
Preferences: tensor([0.1876, 0.7851, 0.0203, 0.0043, 0.0028])
Proved so far: 61

Game: 295
Initialization done. Main goal is:
∀P l. ¬EXISTS P l ⇔ EVERY ($~ ∘ P) l.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[GENLIST_AUX, GENLIST, HD, DROP_def, INDEX_FIND_def]', '∀P l. ¬EXISTS P l ⇔ EVERY ($~ ∘ P) l')]
Time: 0.5182651260001876  
Induct args: []
Preferences: tensor([5.1402e-03, 9.8188e-01, 1.0774e-02, 9.3808e-04, 1.2713e-03])
Proved so far: 62

Game: 296
Initialization done. Main goal is:
∀l1 l2. LENGTH l1 = LENGTH l2 ⇒ (ZIP (l1,l2) = [] ⇔ l1 = [] ∧ l2 = []).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.80207326099935  
Induct args: []
Preferences: tensor([0.0206, 0.9625, 0.0134, 0.0017, 0.0018])
Proved so far: 62

Game: 297
Initialization done. Main goal is:
∀P Q l. (∀x. MEM x l ∧ P x ⇒ Q x) ∧ EVERY P l ⇒ EVERY Q l.
Failed.
Rewards: [-1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'simp']
Total: -49
Time: 21.168881464999686  
Induct args: []
Preferences: tensor([0.1620, 0.8238, 0.0103, 0.0022, 0.0017])
Proved so far: 62

Game: 298
Initialization done. Main goal is:
[$o] <*> fs <*> gs <*> xs = fs <*> (gs <*> xs).
Failed.
Rewards: [-1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -47
Time: 20.70726789299988  
Induct args: []
Preferences: tensor([2.7592e-02, 9.6944e-01, 2.5696e-03, 2.1404e-04, 1.8277e-04])
Proved so far: 62

Game: 299
Importing theories...
Removing simp lemmas...
Loading modules...
Configuration done.
Initialization done. Main goal is:
(∀f. MAP2 f [] [] = []) ∧ ∀f h1 t1 h2 t2. MAP2 f (h1::t1) (h2::t2) = f h1 h2::MAP2 f t1 t2.
Proved in 2 steps.
Rewards: [-1, 10]
Tactics: ['Induct_on', 'fs']
Total: 9
Proof trace: [('fs[FILTER, ALL_DISTINCT, FILTER, SHORTLEX_def, LUPDATE_def]', '(∀f. MAP2 f [] [] = []) ∧ ∀f h1 t1 h2 t2. MAP2 f (h1::t1) (h2::t2) = f h1 h2::MAP2 f t1 t2')]
Time: 5.309498841000277  
Induct args: ['Clist$CONS']
Preferences: tensor([0.4667, 0.4852, 0.0288, 0.0087, 0.0106])
Proved so far: 63

Game: 300
Initialization done. Main goal is:
∀R LIST_REL'. LIST_REL' [] [] ∧ (∀h1 h2 t1 t2. R h1 h2 ∧ LIST_REL R t1 t2 ∧ LIST_REL' t1 t2 ⇒ LIST_REL' (h1::t1) (h2::t2)) ⇒ ∀a0 a1. LIST_REL R a0 a1 ⇒ LIST_REL' a0 a1.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'simp', 'simp', 'fs', 'simp', 'simp', 'fs', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'simp', 'simp', 'fs', 'simp', 'fs', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs']
Total: -51
Time: 21.181212239999695  
Induct args: []
Preferences: tensor([0.5464, 0.4434, 0.0071, 0.0018, 0.0014])
Proved so far: 63

Game: 301
Initialization done. Main goal is:
∀l. REVERSE (REVERSE l) = l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp']
Total: -51
Time: 20.23046092000004  
Induct args: []
Preferences: tensor([0.2706, 0.7009, 0.0146, 0.0040, 0.0098])
Proved so far: 63

Game: 302
Initialization done. Main goal is:
∀x. x ≠ [] ⇒ HD (REVERSE x) = LAST x.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.804557849000048  
Induct args: []
Preferences: tensor([0.0436, 0.9392, 0.0117, 0.0027, 0.0029])
Proved so far: 63

Game: 303
Initialization done. Main goal is:
∀x. x ≠ [] ⇒ HD (REVERSE x) = LAST x.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs']
Total: -49
Time: 20.420398894000755  
Induct args: []
Preferences: tensor([0.0236, 0.9647, 0.0079, 0.0018, 0.0020])
Proved so far: 63

Game: 304
Initialization done. Main goal is:
∀n l. TAKE n l ++ DROP n l = l.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'simp', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -47
Time: 20.541913905  
Induct args: []
Preferences: tensor([0.0401, 0.9322, 0.0206, 0.0043, 0.0028])
Proved so far: 63

Game: 305
Initialization done. Main goal is:
∀l1 l2. SUM (l1 ++ l2) = SUM l1 + SUM l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -47
Time: 20.97317067199947  
Induct args: []
Preferences: tensor([0.0060, 0.9856, 0.0060, 0.0012, 0.0011])
Proved so far: 63

Game: 306
Initialization done. Main goal is:
∀f1 f2 l. MAP f1 l = MAP f2 l ⇔ ∀e. MEM e l ⇒ f1 e = f2 e.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.56538885700047  
Induct args: []
Preferences: tensor([0.0194, 0.9720, 0.0057, 0.0016, 0.0013])
Proved so far: 63

Game: 307
Initialization done. Main goal is:
∀f n. TL (GENLIST f (SUC n)) = GENLIST (f ∘ SUC) n.
Failed.
Rewards: [-1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.558461596000598  
Induct args: []
Preferences: tensor([0.0895, 0.8861, 0.0190, 0.0021, 0.0033])
Proved so far: 63

Game: 308
Initialization done. Main goal is:
∀P l1 l2. LIST_REL P l1 l2 ⇒ LENGTH l1 = LENGTH l2.
Proved in 47 steps.
Rewards: [-1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 10]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'strip_tac', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -26
Proof trace: [('strip_tac', '∀P l1 l2. LIST_REL P l1 l2 ⇒ LENGTH l1 = LENGTH l2'), ('Induct_on `l1`', '∀l1 l2. LIST_REL P l1 l2 ⇒ LENGTH l1 = LENGTH l2'), ('fs[FRONT_DEF, PAD_LEFT, LIST_BIND_def, LRC_def, UNIQUE_DEF]', '∀l2. LIST_REL P [] l2 ⇒ LENGTH [] = LENGTH l2'), ('rpt strip_tac >> fs[LIST_TO_SET_DEF, SUM_ACC_DEF, SHORTLEX_def, splitAtPki_def, LLEX_def]', '(∀l2. LIST_REL P l1 l2 ⇒ LENGTH l1 = LENGTH l2) ==> (∀h l2. LIST_REL P (h::l1) l2 ⇒ LENGTH (h::l1) = LENGTH l2)'), ('fs[FILTER, OPT_MMAP_def, FIND_def, LENGTH, LRC_def]', 'LENGTH [] = LENGTH []'), ('rpt strip_tac >> fs[SHORTLEX_def, list_TY_DEF, LLEX_def, LENGTH, LIST_IGNORE_BIND_def]', '(∀l2. LIST_REL P l1 l2 ⇒ LENGTH l1 = LENGTH l2) ==> ((l2 = y::ys) ==> ((P h y) ==> ((LIST_REL P l1 ys) ==> (LENGTH (h::l1) = LENGTH (y::ys)))))')]
Time: 18.601582932999918  
Induct args: ['Vl1', '@']
Preferences: tensor([0.1426, 0.8206, 0.0179, 0.0035, 0.0153])
Proved so far: 64

Game: 309
Initialization done. Main goal is:
(∀x y. R1 x y ⇒ R2 y x) ⇒ ∀x y. LIST_REL R1 x y ⇒ LIST_REL R2 y x.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.973851286000354  
Induct args: []
Preferences: tensor([4.6085e-03, 9.9415e-01, 8.2640e-04, 2.3127e-04, 1.8438e-04])
Proved so far: 64

Game: 310
Initialization done. Main goal is:
∀P l n1 n2. ALL_DISTINCT (FILTER P l) ∧ n1 < LENGTH l ∧ n2 < LENGTH l ∧ P (EL n1 l) ∧ EL n1 l = EL n2 l ⇒ n1 = n2.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs']
Total: -51
Time: 20.981134720999762  
Induct args: []
Preferences: tensor([1.1268e-01, 8.8208e-01, 3.4278e-03, 1.3894e-03, 4.2595e-04])
Proved so far: 64

Game: 311
Initialization done. Main goal is:
∀l n1 n2. ALL_DISTINCT l ∧ n1 < LENGTH l ∧ n2 < LENGTH l ⇒ (EL n1 l = EL n2 l ⇔ n1 = n2).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'fs', 'simp']
Total: -51
Time: 20.965612977999626  
Induct args: []
Preferences: tensor([2.0060e-01, 7.9532e-01, 3.0127e-03, 7.8957e-04, 2.7963e-04])
Proved so far: 64

Game: 312
Initialization done. Main goal is:
∀P. (∀f h1 t1 h2 t2. P f t1 t2 ⇒ P f (h1::t1) (h2::t2)) ∧ (∀f y. P f [] y) ∧ (∀f v4 v5. P f (v4::v5) []) ⇒ ∀v v1 v2. P v v1 v2.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'strip_tac', 'simp', 'simp', 'simp', 'fs', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'Induct_on', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs']
Total: -49
Time: 21.08541948400034  
Induct args: ['|']
Preferences: tensor([0.8469, 0.1412, 0.0043, 0.0048, 0.0029])
Proved so far: 64

Game: 313
Initialization done. Main goal is:
∀x n l f. MAP f (LUPDATE x n l) = LUPDATE (f x) n (MAP f l).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.8369733870004  
Induct args: []
Preferences: tensor([1.3389e-02, 9.8087e-01, 3.6293e-03, 8.0208e-04, 1.3119e-03])
Proved so far: 64

Game: 314
Initialization done. Main goal is:
∀e l1 l2. MEM e (l1 ++ l2) ⇔ MEM e l1 ∨ MEM e l2.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[FLAT, EL, LIST_BIND_def, FILTER, UNIQUE_DEF]', '∀e l1 l2. MEM e (l1 ++ l2) ⇔ MEM e l1 ∨ MEM e l2')]
Time: 0.48891372900015995  
Induct args: []
Preferences: tensor([6.0151e-03, 9.8847e-01, 4.7983e-03, 4.6783e-04, 2.4505e-04])
Proved so far: 65

Game: 315
Initialization done. Main goal is:
∀n x l. x < n ⇒ EL x (TAKE n l) = EL x l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.58583822899982  
Induct args: []
Preferences: tensor([0.0071, 0.9729, 0.0104, 0.0033, 0.0062])
Proved so far: 65

Game: 316
Initialization done. Main goal is:
(¬LLEX R [] [] ∧ ¬LLEX R (h1::t1) []) ∧ LLEX R [] (h2::t2) ∧ (LLEX R (h1::t1) (h2::t2) ⇔ R h1 h2 ∨ h1 = h2 ∧ LLEX R t1 t2).
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[LUPDATE_def, FOLDL, LIST_LIFT2_def, list_case_def, list_case_def]', '(¬LLEX R [] [] ∧ ¬LLEX R (h1::t1) []) ∧ LLEX R [] (h2::t2) ∧ (LLEX R (h1::t1) (h2::t2) ⇔ R h1 h2 ∨ h1 = h2 ∧ LLEX R t1 t2)')]
Time: 0.4975974890003272  
Induct args: []
Preferences: tensor([0.9309, 0.0624, 0.0033, 0.0021, 0.0012])
Proved so far: 66

Game: 317
Initialization done. Main goal is:
∀v l1 x l2 l3. LUPDATE v (LENGTH l1) (l1 ++ [x] ++ l2) = l1 ++ [v] ++ l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'simp', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -47
Time: 20.508708487999684  
Induct args: ['|']
Preferences: tensor([0.0163, 0.9765, 0.0042, 0.0017, 0.0013])
Proved so far: 66

Game: 318
Initialization done. Main goal is:
(∀l1 l2 l1' l2'. LENGTH l1 = LENGTH l1' ⇒ (l1 ++ l2 = l1' ++ l2' ⇔ l1 = l1' ∧ l2 = l2')) ∧ ∀l1 l2 l1' l2'. LENGTH l2 = LENGTH l2' ⇒ (l1 ++ l2 = l1' ++ l2' ⇔ l1 = l1' ∧ l2 = l2').
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'strip_tac', 'simp', 'fs', 'fs', 'fs', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -45
Time: 20.870017221000126  
Induct args: []
Preferences: tensor([0.2965, 0.6830, 0.0131, 0.0040, 0.0034])
Proved so far: 66

Game: 319
Initialization done. Main goal is:
∀f l1 l2. MAP f (l1 ++ l2) = MAP f l1 ++ MAP f l2.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[LLEX_def, OPT_MMAP_def, LIST_BIND_def, splitAtPki_def, list_size_def]', '∀f l1 l2. MAP f (l1 ++ l2) = MAP f l1 ++ MAP f l2')]
Time: 0.5308664940002927  
Induct args: []
Preferences: tensor([2.3745e-02, 9.7024e-01, 4.0057e-03, 1.7201e-03, 2.8410e-04])
Proved so far: 67

Game: 320
Initialization done. Main goal is:
∀f ls s. FOLDL (λs x. s ∪ f x) s ls = s ∪ BIGUNION (IMAGE f (set ls)).
Failed.
Rewards: [-1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'simp', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.744485129999703  
Induct args: []
Preferences: tensor([2.4757e-02, 9.6568e-01, 7.8124e-03, 8.2796e-04, 9.1749e-04])
Proved so far: 67

Game: 321
Initialization done. Main goal is:
x ≼ [] ⇔ x = [].
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[EVERY_DEF, SHORTLEX_def, FOLDR, EVERYi_def, INDEX_OF_def]', 'x ≼ [] ⇔ x = []')]
Time: 0.5197551860001113  
Induct args: []
Preferences: tensor([0.5645, 0.3819, 0.0247, 0.0104, 0.0186])
Proved so far: 68

Game: 322
Initialization done. Main goal is:
∀f l1 l2. MAP f (l1 ++ l2) = MAP f l1 ++ MAP f l2.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[PAD_LEFT, list_size_def, LENGTH, SNOC, list_size_def]', '∀f l1 l2. MAP f (l1 ++ l2) = MAP f l1 ++ MAP f l2')]
Time: 0.4877253370004837  
Induct args: []
Preferences: tensor([1.8573e-02, 9.7722e-01, 2.5463e-03, 1.4379e-03, 2.2251e-04])
Proved so far: 69

Game: 323
Initialization done. Main goal is:
∀s. FINITE s ⇒ LENGTH (SET_TO_LIST s) = CARD s.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp']
Total: -49
Time: 21.519234758000493  
Induct args: []
Preferences: tensor([9.8554e-01, 1.0289e-02, 2.5220e-03, 1.3518e-03, 3.0074e-04])
Proved so far: 69

Game: 324
Importing theories...
Removing simp lemmas...
Loading modules...
Configuration done.
Initialization done. Main goal is:
∀P l. EVERY P l ⇔ ∀e. MEM e l ⇒ P e.
Failed.
Rewards: [-1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 26.06936422400031  
Induct args: []
Preferences: tensor([0.0229, 0.9684, 0.0035, 0.0019, 0.0033])
Proved so far: 69

Game: 325
Initialization done. Main goal is:
∀f1 f2 x1 x2. x1 = x2 ∧ (∀a. MEM a x2 ⇒ f1 a = f2 a) ⇒ OPT_MMAP f1 x1 = OPT_MMAP f2 x2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'simp', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'Induct_on', 'simp', 'simp', 'fs', 'fs', 'metis_tac', 'simp', 'fs', 'simp']
Total: -49
Time: 21.277109282999845  
Induct args: ['@']
Preferences: tensor([0.5896, 0.3992, 0.0075, 0.0021, 0.0016])
Proved so far: 69

Game: 326
Initialization done. Main goal is:
∀P. (∀f h1 t1 h2 t2. P f t1 t2 ⇒ P f (h1::t1) (h2::t2)) ∧ (∀f y. P f [] y) ∧ (∀f v4 v5. P f (v4::v5) []) ⇒ ∀v v1 v2. P v v1 v2.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'Induct_on', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp']
Total: -51
Time: 21.361586054000327  
Induct args: ['Cbool$!']
Preferences: tensor([0.9008, 0.0811, 0.0041, 0.0065, 0.0075])
Proved so far: 69

Game: 327
Initialization done. Main goal is:
∀n. DROP n [] = [].
Proved in 10 steps.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, 10]
Tactics: ['fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs']
Total: 1
Proof trace: [('fs[GENLIST_AUX, LIST_IGNORE_BIND_def, EL, nub_def, DROP_def]', '∀n. DROP n [] = []')]
Time: 4.115852655999333  
Induct args: []
Preferences: tensor([0.2335, 0.7241, 0.0116, 0.0119, 0.0189])
Proved so far: 70

Game: 328
Initialization done. Main goal is:
∀f l. set (MAP f l) = IMAGE f (set l).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.22474271900046  
Induct args: []
Preferences: tensor([1.3144e-02, 9.7719e-01, 7.0579e-03, 6.9779e-04, 1.9110e-03])
Proved so far: 70

Game: 329
Initialization done. Main goal is:
∀l n. LENGTH l = SUC n ⇔ ∃h l'. LENGTH l' = n ∧ l = h::l'.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.066199931000483  
Induct args: []
Preferences: tensor([2.3114e-03, 9.9460e-01, 2.2773e-03, 6.2796e-04, 1.8047e-04])
Proved so far: 70

Game: 330
Initialization done. Main goal is:
∀P l. FILTER P l = [] ⇔ EVERY (λx. ¬P x) l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.85764203799954  
Induct args: []
Preferences: tensor([2.0461e-03, 9.9591e-01, 1.2155e-03, 2.1834e-04, 6.0565e-04])
Proved so far: 70

Game: 331
Initialization done. Main goal is:
(∀l. TAKE 0 l = []) ∧ (∀n. TAKE (NUMERAL (BIT1 n)) [] = []) ∧ (∀n. TAKE (NUMERAL (BIT2 n)) [] = []) ∧ (∀n h t. TAKE (NUMERAL (BIT1 n)) (h::t) = h::TAKE (NUMERAL (BIT1 n) − 1) t) ∧ ∀n h t. TAKE (NUMERAL (BIT2 n)) (h::t) = h::TAKE (NUMERAL (BIT1 n)) t.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'simp', 'simp', 'simp', 'simp', 'fs', 'fs', 'metis_tac', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs']
Total: -47
Time: 22.008769298000516  
Induct args: []
Preferences: tensor([0.0711, 0.9177, 0.0035, 0.0030, 0.0047])
Proved so far: 70

Game: 332
Initialization done. Main goal is:
∀l1 l2. LENGTH l1 = LENGTH l2 ⇒ UNZIP (ZIP (l1,l2)) = (l1,l2).
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[EL, LLEX_def, GENLIST_AUX, ZIP_def, OPT_MMAP_def]', '∀l1 l2. LENGTH l1 = LENGTH l2 ⇒ UNZIP (ZIP (l1,l2)) = (l1,l2)')]
Time: 0.4914307680001002  
Induct args: []
Preferences: tensor([0.0218, 0.9514, 0.0179, 0.0028, 0.0061])
Proved so far: 71

Game: 333
Initialization done. Main goal is:
∀P l. EXISTS P l ⇔ ∃e. MEM e l ∧ P e.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.5907832339999  
Induct args: []
Preferences: tensor([1.6990e-02, 9.7679e-01, 3.3811e-03, 4.2388e-04, 2.4110e-03])
Proved so far: 71

Game: 334
Initialization done. Main goal is:
∀l. ¬NULL l ⇔ ∃e. MEM e l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.95871106300001  
Induct args: []
Preferences: tensor([0.1010, 0.8873, 0.0052, 0.0015, 0.0051])
Proved so far: 71

Game: 335
Initialization done. Main goal is:
∀n x l. x < n ⇒ EL x (TAKE n l) = EL x l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.834322084000632  
Induct args: []
Preferences: tensor([0.0225, 0.9679, 0.0054, 0.0022, 0.0020])
Proved so far: 71

Game: 336
Initialization done. Main goal is:
LIST_REL (λa b. R a b) l1 (MAP f l2) ⇔ LIST_REL (λa b. R a (f b)) l1 l2.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.50071578100051  
Induct args: []
Preferences: tensor([1.5734e-02, 9.8233e-01, 1.0003e-03, 2.7132e-04, 6.6366e-04])
Proved so far: 71

Game: 337
Initialization done. Main goal is:
∀P l. EXISTS P l ⇔ ¬EVERY (λx. ¬P x) l.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.656229449999955  
Induct args: []
Preferences: tensor([6.5585e-03, 9.8837e-01, 2.6089e-03, 7.3378e-04, 1.7247e-03])
Proved so far: 71

Game: 338
Initialization done. Main goal is:
(∀l. P l) ⇔ P [] ∧ ∀h t. P (h::t).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.727133256000343  
Induct args: []
Preferences: tensor([5.7040e-03, 9.9257e-01, 1.0283e-03, 4.0525e-04, 2.9404e-04])
Proved so far: 71

Game: 339
Initialization done. Main goal is:
∀l1 l2. LENGTH l1 = LENGTH l2 ⇒ ∀f. MAP2 f l1 l2 = MAP (UNCURRY f) (ZIP (l1,l2)).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.403924850000294  
Induct args: []
Preferences: tensor([3.1024e-02, 9.6581e-01, 1.6982e-03, 8.0433e-04, 6.6265e-04])
Proved so far: 71

Game: 340
Initialization done. Main goal is:
∀f x ls. MEM x ls ⇒ f x ≤ SUM (MAP f ls).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.809801123999932  
Induct args: []
Preferences: tensor([1.0928e-02, 9.8651e-01, 1.5509e-03, 5.7011e-04, 4.4386e-04])
Proved so far: 71

Game: 341
Initialization done. Main goal is:
∀l n1 n2. LENGTH l = n1 + n2 ⇔ ∃l1 l2. LENGTH l1 = n1 ∧ LENGTH l2 = n2 ∧ l = l1 ++ l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'fs']
Total: -49
Time: 21.108396237000306  
Induct args: []
Preferences: tensor([0.5926, 0.3850, 0.0143, 0.0026, 0.0054])
Proved so far: 71

Game: 342
Initialization done. Main goal is:
(∀x. MEM x ls ⇒ R x x) ⇒ LIST_REL R ls ls.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'simp', 'fs', 'simp', 'fs', 'simp', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.654443919000187  
Induct args: []
Preferences: tensor([0.3917, 0.5668, 0.0189, 0.0067, 0.0159])
Proved so far: 71

Game: 343
Initialization done. Main goal is:
∀R l1 l2. LIST_REL R l1 l2 ⇒ LIST_REL R (REVERSE l1) (REVERSE l2).
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[PAD_LEFT, SHORTLEX_def, list_case_def, LEN_DEF, oHD_def]', '∀R l1 l2. LIST_REL R l1 l2 ⇒ LIST_REL R (REVERSE l1) (REVERSE l2)')]
Time: 0.49391016400022636  
Induct args: []
Preferences: tensor([0.0271, 0.9358, 0.0248, 0.0055, 0.0068])
Proved so far: 72

Game: 344
Initialization done. Main goal is:
∀x. ALL_DISTINCT [x].
Proved in 3 steps.
Rewards: [-1, -1, 10]
Tactics: ['simp', 'simp', 'simp']
Total: 8
Proof trace: [('simp[EVERYi_def, list_TY_DEF, LENGTH, ALL_DISTINCT, FLAT]', '∀x. ALL_DISTINCT [x]')]
Time: 1.3396770039998955  
Induct args: []
Preferences: tensor([0.6493, 0.3161, 0.0137, 0.0088, 0.0122])
Proved so far: 73

Game: 345
Initialization done. Main goal is:
∀R l1 l2 R' l1' l2'. l1 = l1' ∧ l2 = l2' ∧ (∀a b. MEM a l1' ∧ MEM b l2' ⇒ (R a b ⇔ R' a b)) ⇒ (LLEX R l1 l2 ⇔ LLEX R' l1' l2').
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'fs', 'simp']
Total: -49
Time: 21.734850011000162  
Induct args: []
Preferences: tensor([0.8804, 0.1148, 0.0025, 0.0009, 0.0014])
Proved so far: 73

Game: 346
Initialization done. Main goal is:
MAP f l = l1 ++ l2 ⇔ ∃l10 l20. l = l10 ++ l20 ∧ l1 = MAP f l10 ∧ l2 = MAP f l20.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.359368389999872  
Induct args: []
Preferences: tensor([4.2206e-02, 9.5543e-01, 9.0564e-04, 1.2074e-03, 2.5296e-04])
Proved so far: 73

Game: 347
Initialization done. Main goal is:
∀a1 a0. [] ≠ a0::a1.
Proved in 1 steps.
Rewards: [10]
Tactics: ['simp']
Total: 10
Proof trace: [('simp[ZIP_def, EVERY_DEF, splitAtPki_def, EVERYi_def, PAD_RIGHT]', '∀a1 a0. [] ≠ a0::a1')]
Time: 0.5665610489995743  
Induct args: []
Preferences: tensor([0.1316, 0.8375, 0.0184, 0.0064, 0.0062])
Proved so far: 74

Game: 348
Initialization done. Main goal is:
0 < n ⇒ DROP n (x::xs) = DROP (n − 1) xs.
Proved in 30 steps.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 10]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -19
Proof trace: [('fs[isPREFIX, DROP_def, list_case_def, isPREFIX, SNOC]', '0 < n ⇒ DROP n (x::xs) = DROP (n − 1) xs')]
Time: 13.110623428000508  
Induct args: []
Preferences: tensor([0.1225, 0.8583, 0.0063, 0.0024, 0.0106])
Proved so far: 75

Game: 349
Importing theories...
Removing simp lemmas...
Loading modules...
Configuration done.
Initialization done. Main goal is:
∀n l. n < LENGTH l ⇒ EL n (REVERSE l) = EL (PRE (LENGTH l − n)) l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 25.684849723000298  
Induct args: []
Preferences: tensor([1.5782e-02, 9.7766e-01, 4.6099e-03, 9.7347e-04, 9.7769e-04])
Proved so far: 75

Game: 350
Initialization done. Main goal is:
∀R l1 l2. LIST_REL R l1 l2 ⇔ LENGTH l1 = LENGTH l2 ∧ EVERY (UNCURRY R) (ZIP (l1,l2)).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.497246615000222  
Induct args: []
Preferences: tensor([0.0533, 0.9209, 0.0155, 0.0041, 0.0062])
Proved so far: 75

Game: 351
Initialization done. Main goal is:
∀l1 l2. LENGTH l1 = LENGTH l2 ⇒ ∀f a. FOLDL2 f a l1 l2 = FOLDL (λa. UNCURRY (f a)) a (ZIP (l1,l2)).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'simp', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'simp', 'fs', 'fs', 'simp', 'simp', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'fs', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp']
Total: -51
Time: 20.90982022499975  
Induct args: []
Preferences: tensor([0.4428, 0.5396, 0.0090, 0.0069, 0.0018])
Proved so far: 75

Game: 352
Initialization done. Main goal is:
(∀l. LENGTH l = 0 ⇔ l = []) ∧ (∀l n. LENGTH l = NUMERAL (BIT1 n) ⇔ ∃h l'. LENGTH l' = NUMERAL (BIT1 n) − 1 ∧ l = h::l') ∧ (∀l n. LENGTH l = NUMERAL (BIT2 n) ⇔ ∃h l'. LENGTH l' = NUMERAL (BIT1 n) ∧ l = h::l') ∧ ∀l n1 n2. LENGTH l = n1 + n2 ⇔ ∃l1 l2. LENGTH l1 = n1 ∧ LENGTH l2 = n2 ∧ l = l1 ++ l2.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp']
Total: -49
Time: 21.17974229599986  
Induct args: []
Preferences: tensor([0.9697, 0.0238, 0.0026, 0.0022, 0.0018])
Proved so far: 75

Game: 353
Initialization done. Main goal is:
∀x ls n. MEM x (DROP n ls) ⇔ ∃m. m + n < LENGTH ls ∧ x = EL (m + n) ls.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'fs', 'simp', 'simp', 'fs', 'simp', 'fs', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'fs', 'simp', 'simp', 'Induct_on', 'simp', 'simp', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs']
Total: -45
Time: 20.815987277000204  
Induct args: ['Vn']
Preferences: tensor([0.1737, 0.8119, 0.0080, 0.0035, 0.0029])
Proved so far: 75

Game: 354
Initialization done. Main goal is:
(LIST_REL R [] y ⇔ y = []) ∧ (LIST_REL R x [] ⇔ x = []).
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[HD, EVERY_DEF, LIST_GUARD_def, UNZIP, nub_def]', '(LIST_REL R [] y ⇔ y = []) ∧ (LIST_REL R x [] ⇔ x = [])')]
Time: 0.4803395550006826  
Induct args: []
Preferences: tensor([0.2752, 0.7007, 0.0075, 0.0041, 0.0125])
Proved so far: 76

Game: 355
Initialization done. Main goal is:
∀l n. n < LENGTH l ⇒ LAST (DROP n l) = LAST l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.438186405000124  
Induct args: ['Cprim_rec$<']
Preferences: tensor([0.0142, 0.9724, 0.0070, 0.0014, 0.0050])
Proved so far: 76

Game: 356
Initialization done. Main goal is:
REVERSE l = [e] ⇔ l = [e].
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs']
Total: -51
Time: 20.58915510800034  
Induct args: []
Preferences: tensor([0.0623, 0.9272, 0.0056, 0.0011, 0.0039])
Proved so far: 76

Game: 357
Initialization done. Main goal is:
∀n l. n < LENGTH l ⇒ EL n (REVERSE l) = EL (PRE (LENGTH l − n)) l.
Failed.
Rewards: [-1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.57032864299981  
Induct args: []
Preferences: tensor([3.1295e-02, 9.6548e-01, 1.5222e-03, 5.9178e-04, 1.1117e-03])
Proved so far: 76

Game: 358
Initialization done. Main goal is:
∀y x l. MEM y (SNOC x l) ⇔ y = x ∨ MEM y l.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[OPT_MMAP_def, INDEX_OF_def, SUM_ACC_DEF, list_size_def, EL]', '∀y x l. MEM y (SNOC x l) ⇔ y = x ∨ MEM y l')]
Time: 0.49244402600015746  
Induct args: []
Preferences: tensor([0.0841, 0.8924, 0.0194, 0.0021, 0.0019])
Proved so far: 77

Game: 359
Initialization done. Main goal is:
TAKE n (GENLIST f m) = GENLIST f (MIN n m).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'strip_tac', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs']
Total: -51
Time: 19.86713683400012  
Induct args: []
Preferences: tensor([0.2026, 0.7715, 0.0130, 0.0046, 0.0083])
Proved so far: 77

Game: 360
Initialization done. Main goal is:
∀s. FINITE s ⇒ ∀x. x ∈ s ⇔ MEM x (SET_TO_LIST s).
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[LIST_LIFT2_def, LUPDATE_def, LIST_GUARD_def, nub_def, SUM]', '∀s. FINITE s ⇒ ∀x. x ∈ s ⇔ MEM x (SET_TO_LIST s)')]
Time: 0.49211742999978014  
Induct args: []
Preferences: tensor([0.0508, 0.9405, 0.0041, 0.0022, 0.0024])
Proved so far: 78

Game: 361
Initialization done. Main goal is:
∀P l. ALL_DISTINCT l ⇒ ALL_DISTINCT (FILTER P l).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1]
Tactics: ['fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'simp', 'strip_tac', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'Induct_on', 'fs', 'fs', 'fs', 'metis_tac', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp']
Total: -35
Time: 21.21363940899937  
Induct args: ['Vl', 'Clist$NIL']
Preferences: tensor([0.6262, 0.3389, 0.0112, 0.0055, 0.0181])
Proved so far: 78

Game: 362
Initialization done. Main goal is:
(∀t2 t1 h2 h1 f. MAP2 f (h1::t1) (h2::t2) = f h1 h2::MAP2 f t1 t2) ∧ (∀y f. MAP2 f [] y = []) ∧ ∀v5 v4 f. MAP2 f (v4::v5) [] = [].
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'simp', 'simp', 'simp', 'fs', 'simp', 'Induct_on', 'simp', 'simp', 'fs', 'fs', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'simp', 'Induct_on', 'fs', 'fs']
Total: -47
Time: 20.34665158200005  
Induct args: ['Cbool$!', 'Clist$MAP2']
Preferences: tensor([0.5769, 0.3495, 0.0253, 0.0109, 0.0374])
Proved so far: 78

Game: 363
Initialization done. Main goal is:
(∃a b. R a b) ⇒ ¬WF (LLEX R).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.218505843999992  
Induct args: []
Preferences: tensor([7.9277e-03, 9.8823e-01, 1.1958e-03, 3.6181e-04, 2.2851e-03])
Proved so far: 78

Game: 364
Initialization done. Main goal is:
∀f l1 l2. INJ f (set l1 ∪ set l2) 𝕌(:β) ⇒ (MAP f l1 = MAP f l2 ⇔ l1 = l2).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 21.577643153999816  
Induct args: ['Cmin$=']
Preferences: tensor([0.0204, 0.9714, 0.0053, 0.0017, 0.0012])
Proved so far: 78

Game: 365
Initialization done. Main goal is:
∀l n. LENGTH l ≤ n ⇒ DROP n l = [].
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.48244971299937  
Induct args: ['Cbool$!', '@', '@']
Preferences: tensor([0.0373, 0.8831, 0.0271, 0.0072, 0.0453])
Proved so far: 78

Game: 366
Initialization done. Main goal is:
∀P f l. EVERY P (MAP f l) ⇔ EVERY (λx. P (f x)) l.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'strip_tac', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -47
Time: 21.46956898099961  
Induct args: []
Preferences: tensor([0.1314, 0.8062, 0.0241, 0.0108, 0.0275])
Proved so far: 78

Game: 367
Initialization done. Main goal is:
DROP n l = splitAtPki (K ∘ $= n) (K I) l.
Failed.
Rewards: [-1, -1, -1, -1, 1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'Induct_on', 'strip_tac', 'simp', 'fs', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'simp', 'simp', 'fs', 'simp', 'strip_tac', 'simp', 'simp', 'fs', 'fs', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp']
Total: -39
Time: 20.100299820000146  
Induct args: ['Vl']
Preferences: tensor([0.6554, 0.3307, 0.0079, 0.0028, 0.0032])
Proved so far: 78

Game: 368
Initialization done. Main goal is:
∀ls. ls ≠ [] ⇒ MAP f (FRONT ls) = FRONT (MAP f ls).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 21.375664150000375  
Induct args: []
Preferences: tensor([5.6894e-03, 9.8979e-01, 2.3155e-03, 7.5517e-04, 1.4484e-03])
Proved so far: 78

Game: 369
Initialization done. Main goal is:
DATATYPE (list [] CONS).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'fs', 'simp', 'fs', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'fs', 'Induct_on', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'simp', 'simp', 'Induct_on', 'simp', 'simp', 'fs', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'metis_tac', 'simp', 'strip_tac']
Total: -51
Time: 20.791206322000107  
Induct args: ['@', 'Cbool$DATATYPE']
Preferences: tensor([0.7010, 0.1960, 0.0262, 0.0359, 0.0408])
Proved so far: 78

Game: 370
Initialization done. Main goal is:
x ≠ [] ⇔ 0 < LENGTH x.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 19.622656415000165  
Induct args: ['@', '@', '@', '@']
Preferences: tensor([0.1165, 0.8119, 0.0168, 0.0057, 0.0490])
Proved so far: 78

Game: 371
Initialization done. Main goal is:
fs <*> [x] = [(λf. f x)] <*> fs.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -43
Time: 20.69227025300006  
Induct args: []
Preferences: tensor([0.0439, 0.9457, 0.0060, 0.0017, 0.0027])
Proved so far: 78

Game: 372
Initialization done. Main goal is:
∀ll. ll = [] ∨ ∃x l. ll = SNOC x l.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.133871914999872  
Induct args: []
Preferences: tensor([0.0598, 0.9249, 0.0098, 0.0035, 0.0021])
Proved so far: 78

Game: 373
Initialization done. Main goal is:
∀ls. ls ≠ [] ⇒ MAP f (FRONT ls) = FRONT (MAP f ls).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.219799737999892  
Induct args: []
Preferences: tensor([0.0169, 0.9714, 0.0066, 0.0025, 0.0025])
Proved so far: 78

Game: 374
Importing theories...
Removing simp lemmas...
Loading modules...
Configuration done.
Initialization done. Main goal is:
∀ls. FLAT ls = [] ⇔ EVERY ($= []) ls.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 24.833181521999904  
Induct args: []
Preferences: tensor([5.9186e-02, 9.3333e-01, 3.5396e-03, 9.0598e-04, 3.0415e-03])
Proved so far: 78

Game: 375
Initialization done. Main goal is:
∀ts tt n. n < MIN (LENGTH ts) (LENGTH tt) ⇒ EL n (MAP2 f ts tt) = f (EL n ts) (EL n tt).
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'metis_tac', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp']
Total: -49
Time: 21.46935003499948  
Induct args: []
Preferences: tensor([9.5879e-01, 3.2830e-02, 5.7546e-03, 1.7799e-03, 8.4095e-04])
Proved so far: 78

Game: 376
Initialization done. Main goal is:
∀M N f f'. M = N ∧ (∀x. MEM x N ⇒ f x = f' x) ⇒ list_size f M = list_size f' N.
Failed.
Rewards: [1, -1, 1, -1, 1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'strip_tac', 'simp', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'simp', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -43
Time: 20.798141684000257  
Induct args: []
Preferences: tensor([2.0494e-02, 9.7506e-01, 2.6968e-03, 6.4657e-04, 1.0984e-03])
Proved so far: 78

Game: 377
Initialization done. Main goal is:
∀M N f f'. M = N ∧ (∀x. MEM x N ⇒ f x = f' x) ⇒ list_size f M = list_size f' N.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'fs', 'fs', 'fs', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'simp', 'simp', 'simp', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'simp', 'simp', 'fs', 'fs', 'simp', 'simp', 'fs']
Total: -49
Time: 21.04788416000065  
Induct args: []
Preferences: tensor([0.6214, 0.3726, 0.0025, 0.0018, 0.0017])
Proved so far: 78

Game: 378
Initialization done. Main goal is:
∀x y. LIST_REL R x y ⇒ LENGTH x = LENGTH y.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.548289130999365  
Induct args: []
Preferences: tensor([0.0090, 0.9817, 0.0055, 0.0012, 0.0025])
Proved so far: 78

Game: 379
Initialization done. Main goal is:
∀ls. CARD (set ls) = LENGTH ls ⇒ ALL_DISTINCT ls.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.708385791000183  
Induct args: []
Preferences: tensor([1.1292e-02, 9.8663e-01, 1.2284e-03, 3.9525e-04, 4.5245e-04])
Proved so far: 78

Game: 380
Initialization done. Main goal is:
[f] <*> [x] = [f x].
Proved in 21 steps.
Rewards: [-1, -1, -1, -1, -1, -1, 1, -1, 1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, 10]
Tactics: ['fs', 'fs', 'simp', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -4
Proof trace: [('fs[SHORTLEX_def, isPREFIX, oEL_def, LIST_APPLY_def, LLEX_def]', '[f] <*> [x] = [f x]'), ('fs[REVERSE_DEF, LIST_LIFT2_def, REVERSE_DEF, FOLDR, LIST_BIND_def]', 'LIST_BIND [f] (combin$C MAP [x]) = [f x]'), ('fs[MAP, PAD_RIGHT, INDEX_OF_def, splitAtPki_def, SET_TO_LIST_primitive_def]', 'FLAT (MAP (combin$C MAP [x]) [f]) = [f x]'), ('fs[FLAT, PAD_LEFT, HD, FOLDR, TAKE_def]', 'FLAT [[f x]] = [f x]')]
Time: 8.514325864999591  
Induct args: []
Preferences: tensor([0.0775, 0.9089, 0.0053, 0.0018, 0.0066])
Proved so far: 79

Game: 381
Initialization done. Main goal is:
∀L n. SUM_ACC L n = SUM L + n.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.54773020599987  
Induct args: []
Preferences: tensor([7.5881e-03, 9.8608e-01, 3.4999e-03, 9.7513e-04, 1.8572e-03])
Proved so far: 79

Game: 382
Initialization done. Main goal is:
∀l. ¬NULL l ⇒ HD l::TL l = l.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[list_TY_DEF, UNZIP, EXISTS_DEF, splitAtPki_def, FOLDR]', '∀l. ¬NULL l ⇒ HD l::TL l = l')]
Time: 0.4871672649996981  
Induct args: []
Preferences: tensor([1.6704e-02, 9.8067e-01, 1.3760e-03, 7.6684e-04, 4.8662e-04])
Proved so far: 80

Game: 383
Initialization done. Main goal is:
∀xs. FILTER (λx. F) xs = [].
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[OPT_MMAP_def, FIND_def, LIST_APPLY_def, MAP, SUM_ACC_DEF]', '∀xs. FILTER (λx. F) xs = []')]
Time: 0.49043893799989746  
Induct args: []
Preferences: tensor([0.0875, 0.8822, 0.0067, 0.0081, 0.0155])
Proved so far: 81

Game: 384
Initialization done. Main goal is:
∀ys x i k. EL i (LUPDATE x k ys) = if i = k ∧ k < LENGTH ys then x else EL i ys.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.806638447000296  
Induct args: []
Preferences: tensor([5.9747e-02, 9.3794e-01, 7.6386e-04, 6.7159e-04, 8.7927e-04])
Proved so far: 81

Game: 385
Initialization done. Main goal is:
∀n m l. TAKE (n + m) l = TAKE n l ++ TAKE m (DROP n l).
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.48527839000053  
Induct args: []
Preferences: tensor([3.6055e-02, 9.5992e-01, 1.7565e-03, 1.5262e-03, 7.4260e-04])
Proved so far: 81

Game: 386
Initialization done. Main goal is:
∀l. ¬NULL l ⇒ HD l::TL l = l.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[isPREFIX, dropWhile_def, INDEX_OF_def, LIST_TO_SET_DEF, LIST_IGNORE_BIND_def]', '∀l. ¬NULL l ⇒ HD l::TL l = l')]
Time: 0.5174838379998619  
Induct args: []
Preferences: tensor([1.8553e-02, 9.7868e-01, 1.4434e-03, 8.0792e-04, 5.1316e-04])
Proved so far: 82

Game: 387
Initialization done. Main goal is:
∀h1 h2. h1 = h2 ⇒ ∀l1 l2. l1 = l2 ⇒ h1::l1 = h2::l2.
Proved in 1 steps.
Rewards: [10]
Tactics: ['fs']
Total: 10
Proof trace: [('fs[REVERSE_DEF, LIST_APPLY_def, list_case_def, FILTER, ALL_DISTINCT]', '∀h1 h2. h1 = h2 ⇒ ∀l1 l2. l1 = l2 ⇒ h1::l1 = h2::l2')]
Time: 0.49295748500026093  
Induct args: []
Preferences: tensor([0.1583, 0.8266, 0.0087, 0.0026, 0.0038])
Proved so far: 83

Game: 388
Initialization done. Main goal is:
∀l. l ≠ [] ⇒ FRONT l ++ [LAST l] = l.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.69407639900055  
Induct args: []
Preferences: tensor([5.0390e-03, 9.9003e-01, 2.4128e-03, 9.0374e-04, 1.6189e-03])
Proved so far: 83

Game: 389
Initialization done. Main goal is:
∀l1 l2. REVERSE l1 = REVERSE l2 ⇔ l1 = l2.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'simp', 'fs', 'simp', 'simp']
Total: -47
Time: 20.412502897000195  
Induct args: []
Preferences: tensor([0.3703, 0.5858, 0.0141, 0.0089, 0.0210])
Proved so far: 83

Game: 390
Initialization done. Main goal is:
∀l1 l2 P. LENGTH l1 = LENGTH l2 ⇒ (EVERY (λx. P (FST x)) (ZIP (l1,l2)) ⇔ EVERY P l1).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp']
Total: -51
Time: 20.869832160999977  
Induct args: []
Preferences: tensor([0.0567, 0.9378, 0.0015, 0.0019, 0.0021])
Proved so far: 83

Game: 391
Initialization done. Main goal is:
∀R LIST_REL'. LIST_REL' [] [] ∧ (∀h1 h2 t1 t2. R h1 h2 ∧ LIST_REL' t1 t2 ⇒ LIST_REL' (h1::t1) (h2::t2)) ⇒ ∀a0 a1. LIST_REL R a0 a1 ⇒ LIST_REL' a0 a1.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp']
Total: -51
Time: 20.764353350999954  
Induct args: []
Preferences: tensor([9.9200e-01, 4.9489e-03, 1.1562e-03, 8.9552e-04, 1.0044e-03])
Proved so far: 83

Game: 392
Initialization done. Main goal is:
REVERSE l = [e] ⇔ l = [e].
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs']
Total: -51
Time: 20.312535371000195  
Induct args: []
Preferences: tensor([0.1347, 0.8559, 0.0045, 0.0016, 0.0033])
Proved so far: 83

Game: 393
Initialization done. Main goal is:
∀f g n. MAP f (GENLIST g n) = GENLIST (f ∘ g) n.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -47
Time: 20.524797449999824  
Induct args: ['@']
Preferences: tensor([0.0124, 0.9727, 0.0090, 0.0039, 0.0020])
Proved so far: 83

Game: 394
Initialization done. Main goal is:
MAP f (FLAT l) = FLAT (MAP (MAP f) l).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'metis_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'simp', 'fs', 'simp', 'fs']
Total: -51
Time: 21.4064791539995  
Induct args: []
Preferences: tensor([0.0548, 0.9391, 0.0027, 0.0012, 0.0022])
Proved so far: 83

Game: 395
Initialization done. Main goal is:
∀f a b. GENLIST f (a + b) = GENLIST f b ++ GENLIST (λt. f (t + b)) a.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -49
Time: 20.629441235999366  
Induct args: []
Preferences: tensor([4.3716e-02, 9.5479e-01, 6.7186e-04, 5.9661e-04, 2.2445e-04])
Proved so far: 83

Game: 396
Initialization done. Main goal is:
∀P l. ALL_DISTINCT l ⇒ ALL_DISTINCT (FILTER P l).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'fs', 'fs', 'Induct_on', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'fs', 'Induct_on', 'fs', 'fs', 'fs', 'strip_tac', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'simp', 'fs', 'fs']
Total: -49
Time: 19.998189091999848  
Induct args: ['@', '@', '@', '@']
Preferences: tensor([0.2105, 0.7597, 0.0123, 0.0066, 0.0109])
Proved so far: 83

Game: 397
Initialization done. Main goal is:
∀M M' v f. M = M' ∧ (M' = [] ⇒ v = v') ∧ (∀a0 a1. M' = a0::a1 ⇒ f a0 a1 = f' a0 a1) ⇒ list_CASE M v f = list_CASE M' v' f'.
Failed.
Rewards: [1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'fs', 'simp', 'simp', 'fs', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp', 'simp']
Total: -49
Time: 21.085061408999536  
Induct args: []
Preferences: tensor([9.3068e-01, 6.7165e-02, 6.2425e-04, 1.0326e-03, 4.9866e-04])
Proved so far: 83

Game: 398
Initialization done. Main goal is:
∀n f. 0 < n ⇒ HD (GENLIST f n) = f 0.
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'simp', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 20.73580601499998  
Induct args: []
Preferences: tensor([0.0270, 0.9628, 0.0071, 0.0012, 0.0018])
Proved so far: 83

Game: 399
Importing theories...
Removing simp lemmas...
Loading modules...
Configuration done.
Initialization done. Main goal is:
∀f n l. MAP f (TAKE n l) = TAKE n (MAP f l).
Failed.
Rewards: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]
Tactics: ['fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs', 'fs']
Total: -51
Time: 25.584251807999863  
Induct args: []
Preferences: tensor([6.2588e-03, 9.9174e-01, 1.1999e-03, 5.8811e-04, 2.1074e-04])
Proved so far: 83

Models saved.
Dictionary saved.
>>> 
